{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e980e71b-ef78-409e-a6e2-352f3b2f4614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['default_assoc', 1.0]\n",
      "[(0, {'struct': <networkx.classes.graph.Graph object at 0x0000025B528226D8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (1, {'struct': <networkx.classes.graph.Graph object at 0x0000025B5A99E860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (2, {'struct': <networkx.classes.graph.Graph object at 0x0000025B5A33F978>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})]\n",
      "New node added - Node index: 3 ; Node label: AB \n",
      "New node added - Node index: 4 ; Node label: AC \n",
      "New node added - Node index: 5 ; Node label: BC \n",
      "New node added - Node index: 6 ; Node label: ABC \n",
      "Reaction Network Completed\n",
      "Largest Complex node index:  6\n",
      "Reaction rates:  tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64, grad_fn=<CopySlices>)\n",
      "dGs:  tensor([-20., -20., -20., -40., -40., -40.], dtype=torch.float64)\n",
      "Species Concentrations:  tensor([100., 100., 100.,   0.,   0.,   0.,   0.], dtype=torch.float64)\n",
      "Shifting to device:  cpu\n",
      "Reaction Parameters before optimization: \n",
      "[Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64, requires_grad=True)]\n",
      "Optimizer State: <bound method Optimizer.state_dict of Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    weight_decay: 0\n",
      ")>\n",
      "Using CPU\n",
      "Yield on sim. iteration 0 was 67.4%.\n",
      "current params: tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor(0.6742, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 1 was 67.9%.\n",
      "current params: tensor([0.9900, 0.9900, 0.9900, 1.0100, 1.0100, 1.0100], dtype=torch.float64)\n",
      "tensor(0.6797, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 2 was 68.4%.\n",
      "current params: tensor([0.9800, 0.9800, 0.9800, 1.0200, 1.0200, 1.0200], dtype=torch.float64)\n",
      "tensor(0.6844, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 3 was 68.9%.\n",
      "current params: tensor([0.9700, 0.9700, 0.9700, 1.0300, 1.0300, 1.0300], dtype=torch.float64)\n",
      "tensor(0.6899, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 4 was 69.6%.\n",
      "current params: tensor([0.9600, 0.9600, 0.9600, 1.0400, 1.0400, 1.0400], dtype=torch.float64)\n",
      "tensor(0.6960, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 5 was 70.0%.\n",
      "current params: tensor([0.9499, 0.9499, 0.9499, 1.0500, 1.0500, 1.0500], dtype=torch.float64)\n",
      "tensor(0.7002, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 6 was 70.5%.\n",
      "current params: tensor([0.9399, 0.9399, 0.9399, 1.0600, 1.0600, 1.0600], dtype=torch.float64)\n",
      "tensor(0.7056, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 7 was 71.0%.\n",
      "current params: tensor([0.9298, 0.9298, 0.9298, 1.0699, 1.0699, 1.0699], dtype=torch.float64)\n",
      "tensor(0.7104, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 8 was 71.5%.\n",
      "current params: tensor([0.9197, 0.9197, 0.9197, 1.0799, 1.0799, 1.0799], dtype=torch.float64)\n",
      "tensor(0.7159, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 9 was 72.0%.\n",
      "optimization complete\n",
      "Final params: tensor([0.9197, 0.9197, 0.9197, 1.0799, 1.0799, 1.0799], dtype=torch.float64)\n",
      "Iterations: 10 Peak Memory Usage: 250.13671875 MiB\n",
      "Reaction rates:  tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64, grad_fn=<CopySlices>)\n",
      "dGs:  tensor([-20., -20., -20., -40., -40., -40.], dtype=torch.float64)\n",
      "Species Concentrations:  tensor([100., 100., 100.,   0.,   0.,   0.,   0.], dtype=torch.float64)\n",
      "Shifting to device:  cpu\n",
      "Reaction Parameters before optimization: \n",
      "[Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64, requires_grad=True)]\n",
      "Optimizer State: <bound method Optimizer.state_dict of Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    weight_decay: 0\n",
      ")>\n",
      "Using CPU\n",
      "Yield on sim. iteration 0 was 67.4%.\n",
      "current params: tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor(0.6742, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 1 was 67.9%.\n",
      "current params: tensor([0.9900, 0.9900, 0.9900, 1.0100, 1.0100, 1.0100], dtype=torch.float64)\n",
      "tensor(0.6797, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 2 was 68.4%.\n",
      "current params: tensor([0.9800, 0.9800, 0.9800, 1.0200, 1.0200, 1.0200], dtype=torch.float64)\n",
      "tensor(0.6844, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 3 was 68.9%.\n",
      "current params: tensor([0.9700, 0.9700, 0.9700, 1.0300, 1.0300, 1.0300], dtype=torch.float64)\n",
      "tensor(0.6899, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 4 was 69.6%.\n",
      "current params: tensor([0.9600, 0.9600, 0.9600, 1.0400, 1.0400, 1.0400], dtype=torch.float64)\n",
      "tensor(0.6960, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 5 was 70.0%.\n",
      "current params: tensor([0.9499, 0.9499, 0.9499, 1.0500, 1.0500, 1.0500], dtype=torch.float64)\n",
      "tensor(0.7002, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 6 was 70.5%.\n",
      "current params: tensor([0.9399, 0.9399, 0.9399, 1.0600, 1.0600, 1.0600], dtype=torch.float64)\n",
      "tensor(0.7056, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 7 was 71.0%.\n",
      "current params: tensor([0.9298, 0.9298, 0.9298, 1.0699, 1.0699, 1.0699], dtype=torch.float64)\n",
      "tensor(0.7104, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 8 was 71.5%.\n",
      "current params: tensor([0.9197, 0.9197, 0.9197, 1.0799, 1.0799, 1.0799], dtype=torch.float64)\n",
      "tensor(0.7159, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 9 was 72.0%.\n",
      "current params: tensor([0.9096, 0.9096, 0.9096, 1.0899, 1.0899, 1.0899], dtype=torch.float64)\n",
      "tensor(0.7206, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 10 was 72.6%.\n",
      "current params: tensor([0.8994, 0.8994, 0.8994, 1.0999, 1.0999, 1.0999], dtype=torch.float64)\n",
      "tensor(0.7261, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 11 was 73.2%.\n",
      "current params: tensor([0.8893, 0.8893, 0.8893, 1.1098, 1.1098, 1.1098], dtype=torch.float64)\n",
      "tensor(0.7321, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 12 was 73.6%.\n",
      "current params: tensor([0.8790, 0.8790, 0.8790, 1.1198, 1.1198, 1.1198], dtype=torch.float64)\n",
      "tensor(0.7364, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 13 was 74.1%.\n",
      "current params: tensor([0.8688, 0.8688, 0.8688, 1.1297, 1.1297, 1.1297], dtype=torch.float64)\n",
      "tensor(0.7420, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 14 was 74.6%.\n",
      "current params: tensor([0.8585, 0.8585, 0.8585, 1.1396, 1.1396, 1.1396], dtype=torch.float64)\n",
      "tensor(0.7467, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 15 was 75.2%.\n",
      "current params: tensor([0.8482, 0.8482, 0.8482, 1.1495, 1.1495, 1.1495], dtype=torch.float64)\n",
      "tensor(0.7523, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 16 was 75.7%.\n",
      "current params: tensor([0.8378, 0.8378, 0.8378, 1.1594, 1.1594, 1.1594], dtype=torch.float64)\n",
      "tensor(0.7578, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 17 was 76.2%.\n",
      "current params: tensor([0.8274, 0.8274, 0.8274, 1.1693, 1.1693, 1.1693], dtype=torch.float64)\n",
      "tensor(0.7626, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 18 was 76.8%.\n",
      "current params: tensor([0.8169, 0.8169, 0.8169, 1.1792, 1.1792, 1.1792], dtype=torch.float64)\n",
      "tensor(0.7683, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 19 was 77.4%.\n",
      "current params: tensor([0.8064, 0.8064, 0.8064, 1.1891, 1.1891, 1.1891], dtype=torch.float64)\n",
      "tensor(0.7743, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 20 was 77.8%.\n",
      "current params: tensor([0.7958, 0.7958, 0.7958, 1.1990, 1.1990, 1.1990], dtype=torch.float64)\n",
      "tensor(0.7787, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 21 was 78.4%.\n",
      "current params: tensor([0.7852, 0.7852, 0.7852, 1.2088, 1.2088, 1.2088], dtype=torch.float64)\n",
      "tensor(0.7843, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 22 was 78.9%.\n",
      "current params: tensor([0.7745, 0.7745, 0.7745, 1.2187, 1.2187, 1.2187], dtype=torch.float64)\n",
      "tensor(0.7898, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 23 was 79.4%.\n",
      "current params: tensor([0.7637, 0.7637, 0.7637, 1.2285, 1.2285, 1.2285], dtype=torch.float64)\n",
      "tensor(0.7948, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 24 was 80.0%.\n",
      "current params: tensor([0.7529, 0.7529, 0.7529, 1.2383, 1.2383, 1.2383], dtype=torch.float64)\n",
      "tensor(0.8005, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 25 was 80.6%.\n",
      "current params: tensor([0.7420, 0.7420, 0.7420, 1.2481, 1.2481, 1.2481], dtype=torch.float64)\n",
      "tensor(0.8062, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 26 was 81.1%.\n",
      "current params: tensor([0.7311, 0.7311, 0.7311, 1.2579, 1.2579, 1.2579], dtype=torch.float64)\n",
      "tensor(0.8111, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 27 was 81.6%.\n",
      "current params: tensor([0.7200, 0.7200, 0.7200, 1.2677, 1.2677, 1.2677], dtype=torch.float64)\n",
      "tensor(0.8168, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 28 was 82.2%.\n",
      "current params: tensor([0.7089, 0.7089, 0.7089, 1.2775, 1.2775, 1.2775], dtype=torch.float64)\n",
      "tensor(0.8226, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 29 was 82.8%.\n",
      "current params: tensor([0.6978, 0.6978, 0.6978, 1.2872, 1.2872, 1.2872], dtype=torch.float64)\n",
      "tensor(0.8283, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 30 was 83.3%.\n",
      "current params: tensor([0.6865, 0.6865, 0.6865, 1.2970, 1.2970, 1.2970], dtype=torch.float64)\n",
      "tensor(0.8339, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 31 was 83.9%.\n",
      "current params: tensor([0.6752, 0.6752, 0.6752, 1.3067, 1.3067, 1.3067], dtype=torch.float64)\n",
      "tensor(0.8391, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 32 was 84.4%.\n",
      "current params: tensor([0.6637, 0.6637, 0.6637, 1.3164, 1.3164, 1.3164], dtype=torch.float64)\n",
      "tensor(0.8449, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 33 was 85.0%.\n",
      "current params: tensor([0.6522, 0.6522, 0.6522, 1.3261, 1.3261, 1.3261], dtype=torch.float64)\n",
      "tensor(0.8507, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 34 was 85.6%.\n",
      "current params: tensor([0.6406, 0.6406, 0.6406, 1.3358, 1.3358, 1.3358], dtype=torch.float64)\n",
      "tensor(0.8566, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 35 was 86.2%.\n",
      "current params: tensor([0.6289, 0.6289, 0.6289, 1.3455, 1.3455, 1.3455], dtype=torch.float64)\n",
      "tensor(0.8625, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 36 was 86.8%.\n",
      "current params: tensor([0.6171, 0.6171, 0.6171, 1.3552, 1.3552, 1.3552], dtype=torch.float64)\n",
      "tensor(0.8683, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 37 was 87.4%.\n",
      "current params: tensor([0.6052, 0.6052, 0.6052, 1.3649, 1.3649, 1.3649], dtype=torch.float64)\n",
      "tensor(0.8741, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 38 was 87.9%.\n",
      "current params: tensor([0.5933, 0.5933, 0.5933, 1.3745, 1.3745, 1.3745], dtype=torch.float64)\n",
      "tensor(0.8795, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 39 was 88.5%.\n",
      "current params: tensor([0.5812, 0.5812, 0.5812, 1.3842, 1.3842, 1.3842], dtype=torch.float64)\n",
      "tensor(0.8853, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 40 was 89.1%.\n",
      "current params: tensor([0.5690, 0.5690, 0.5690, 1.3938, 1.3938, 1.3938], dtype=torch.float64)\n",
      "tensor(0.8912, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 41 was 89.7%.\n",
      "current params: tensor([0.5567, 0.5567, 0.5567, 1.4035, 1.4035, 1.4035], dtype=torch.float64)\n",
      "tensor(0.8972, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 42 was 90.3%.\n",
      "current params: tensor([0.5443, 0.5443, 0.5443, 1.4131, 1.4131, 1.4131], dtype=torch.float64)\n",
      "tensor(0.9032, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 43 was 90.9%.\n",
      "current params: tensor([0.5317, 0.5317, 0.5317, 1.4227, 1.4227, 1.4227], dtype=torch.float64)\n",
      "tensor(0.9092, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 44 was 91.5%.\n",
      "current params: tensor([0.5191, 0.5191, 0.5191, 1.4323, 1.4323, 1.4323], dtype=torch.float64)\n",
      "tensor(0.9151, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 45 was 92.1%.\n",
      "current params: tensor([0.5063, 0.5063, 0.5063, 1.4419, 1.4419, 1.4419], dtype=torch.float64)\n",
      "tensor(0.9211, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 46 was 92.7%.\n",
      "current params: tensor([0.4934, 0.4934, 0.4934, 1.4515, 1.4515, 1.4515], dtype=torch.float64)\n",
      "tensor(0.9271, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 47 was 93.3%.\n",
      "current params: tensor([0.4804, 0.4804, 0.4804, 1.4611, 1.4611, 1.4611], dtype=torch.float64)\n",
      "tensor(0.9331, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 48 was 93.9%.\n",
      "current params: tensor([0.4672, 0.4672, 0.4672, 1.4707, 1.4707, 1.4707], dtype=torch.float64)\n",
      "tensor(0.9391, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 49 was 94.4%.\n",
      "current params: tensor([0.4539, 0.4539, 0.4539, 1.4803, 1.4803, 1.4803], dtype=torch.float64)\n",
      "tensor(0.9440, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 50 was 94.9%.\n",
      "current params: tensor([0.4405, 0.4405, 0.4405, 1.4899, 1.4899, 1.4899], dtype=torch.float64)\n",
      "tensor(0.9500, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 51 was 95.4%.\n",
      "current params: tensor([0.4269, 0.4269, 0.4269, 1.4995, 1.4995, 1.4995], dtype=torch.float64)\n",
      "tensor(0.9548, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 52 was 95.9%.\n",
      "current params: tensor([0.4131, 0.4131, 0.4131, 1.5091, 1.5091, 1.5091], dtype=torch.float64)\n",
      "tensor(0.9597, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 53 was 96.4%.\n",
      "current params: tensor([0.3992, 0.3992, 0.3992, 1.5187, 1.5187, 1.5187], dtype=torch.float64)\n",
      "tensor(0.9644, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 54 was 96.9%.\n",
      "current params: tensor([0.3851, 0.3851, 0.3851, 1.5283, 1.5283, 1.5283], dtype=torch.float64)\n",
      "tensor(0.9691, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 55 was 97.2%.\n",
      "current params: tensor([0.3709, 0.3709, 0.3709, 1.5379, 1.5379, 1.5379], dtype=torch.float64)\n",
      "tensor(0.9726, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 56 was 97.6%.\n",
      "current params: tensor([0.3564, 0.3564, 0.3564, 1.5474, 1.5474, 1.5474], dtype=torch.float64)\n",
      "tensor(0.9761, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 57 was 97.8%.\n",
      "current params: tensor([0.3418, 0.3418, 0.3418, 1.5570, 1.5570, 1.5570], dtype=torch.float64)\n",
      "tensor(0.9784, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 58 was 98.0%.\n",
      "current params: tensor([0.3270, 0.3270, 0.3270, 1.5667, 1.5667, 1.5667], dtype=torch.float64)\n",
      "tensor(0.9806, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 59 was 98.2%.\n",
      "current params: tensor([0.3120, 0.3120, 0.3120, 1.5763, 1.5763, 1.5763], dtype=torch.float64)\n",
      "tensor(0.9826, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 60 was 98.3%.\n",
      "current params: tensor([0.2968, 0.2968, 0.2968, 1.5859, 1.5859, 1.5859], dtype=torch.float64)\n",
      "tensor(0.9835, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 61 was 98.4%.\n",
      "current params: tensor([0.2814, 0.2814, 0.2814, 1.5955, 1.5955, 1.5955], dtype=torch.float64)\n",
      "tensor(0.9842, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 62 was 98.4%.\n",
      "current params: tensor([0.2657, 0.2657, 0.2657, 1.6052, 1.6052, 1.6052], dtype=torch.float64)\n",
      "tensor(0.9841, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 63 was 98.3%.\n",
      "current params: tensor([0.2498, 0.2498, 0.2498, 1.6149, 1.6149, 1.6149], dtype=torch.float64)\n",
      "tensor(0.9838, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 64 was 98.3%.\n",
      "current params: tensor([0.2337, 0.2337, 0.2337, 1.6245, 1.6245, 1.6245], dtype=torch.float64)\n",
      "tensor(0.9834, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 65 was 98.2%.\n",
      "current params: tensor([0.2173, 0.2173, 0.2173, 1.6342, 1.6342, 1.6342], dtype=torch.float64)\n",
      "tensor(0.9829, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 66 was 98.1%.\n",
      "current params: tensor([0.2007, 0.2007, 0.2007, 1.6439, 1.6439, 1.6439], dtype=torch.float64)\n",
      "tensor(0.9817, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 67 was 98.0%.\n",
      "current params: tensor([0.1838, 0.1838, 0.1838, 1.6537, 1.6537, 1.6537], dtype=torch.float64)\n",
      "tensor(0.9805, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 68 was 97.8%.\n",
      "current params: tensor([0.1666, 0.1666, 0.1666, 1.6634, 1.6634, 1.6634], dtype=torch.float64)\n",
      "tensor(0.9787, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 69 was 97.6%.\n",
      "current params: tensor([0.1491, 0.1491, 0.1491, 1.6731, 1.6731, 1.6731], dtype=torch.float64)\n",
      "tensor(0.9764, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 70 was 97.3%.\n",
      "current params: tensor([0.1313, 0.1313, 0.1313, 1.6829, 1.6829, 1.6829], dtype=torch.float64)\n",
      "tensor(0.9735, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 71 was 96.9%.\n",
      "current params: tensor([0.1133, 0.1133, 0.1133, 1.6927, 1.6927, 1.6927], dtype=torch.float64)\n",
      "tensor(0.9697, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 72 was 96.4%.\n",
      "current params: tensor([0.0949, 0.0949, 0.0949, 1.7024, 1.7024, 1.7024], dtype=torch.float64)\n",
      "tensor(0.9643, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 73 was 96.4%.\n",
      "current params: tensor([0.0967, 0.0967, 0.0967, 1.7122, 1.7122, 1.7122], dtype=torch.float64)\n",
      "tensor(0.9648, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 74 was 96.7%.\n",
      "current params: tensor([0.1038, 0.1038, 0.1038, 1.7219, 1.7219, 1.7219], dtype=torch.float64)\n",
      "tensor(0.9673, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 75 was 96.8%.\n",
      "current params: tensor([0.1091, 0.1091, 0.1091, 1.7317, 1.7317, 1.7317], dtype=torch.float64)\n",
      "tensor(0.9688, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 76 was 96.9%.\n",
      "current params: tensor([0.1129, 0.1129, 0.1129, 1.7414, 1.7414, 1.7414], dtype=torch.float64)\n",
      "tensor(0.9698, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 77 was 97.0%.\n",
      "current params: tensor([0.1154, 0.1154, 0.1154, 1.7512, 1.7512, 1.7512], dtype=torch.float64)\n",
      "tensor(0.9703, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 78 was 97.0%.\n",
      "current params: tensor([0.1167, 0.1167, 0.1167, 1.7609, 1.7609, 1.7609], dtype=torch.float64)\n",
      "tensor(0.9708, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 79 was 97.0%.\n",
      "current params: tensor([0.1170, 0.1170, 0.1170, 1.7706, 1.7706, 1.7706], dtype=torch.float64)\n",
      "tensor(0.9708, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 80 was 97.0%.\n",
      "current params: tensor([0.1164, 0.1164, 0.1164, 1.7802, 1.7802, 1.7802], dtype=torch.float64)\n",
      "tensor(0.9709, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 81 was 97.0%.\n",
      "current params: tensor([0.1150, 0.1150, 0.1150, 1.7899, 1.7899, 1.7899], dtype=torch.float64)\n",
      "tensor(0.9704, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 82 was 96.9%.\n",
      "current params: tensor([0.1128, 0.1128, 0.1128, 1.7995, 1.7995, 1.7995], dtype=torch.float64)\n",
      "tensor(0.9699, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 83 was 96.8%.\n",
      "current params: tensor([0.1098, 0.1098, 0.1098, 1.8091, 1.8091, 1.8091], dtype=torch.float64)\n",
      "tensor(0.9689, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 84 was 96.7%.\n",
      "current params: tensor([0.1062, 0.1062, 0.1062, 1.8187, 1.8187, 1.8187], dtype=torch.float64)\n",
      "tensor(0.9680, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 85 was 96.7%.\n",
      "current params: tensor([0.1020, 0.1020, 0.1020, 1.8282, 1.8282, 1.8282], dtype=torch.float64)\n",
      "tensor(0.9670, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 86 was 96.5%.\n",
      "current params: tensor([0.0971, 0.0971, 0.0971, 1.8377, 1.8377, 1.8377], dtype=torch.float64)\n",
      "tensor(0.9656, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 87 was 96.5%.\n",
      "current params: tensor([0.0984, 0.0984, 0.0984, 1.8472, 1.8472, 1.8472], dtype=torch.float64)\n",
      "tensor(0.9656, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 88 was 96.7%.\n",
      "current params: tensor([0.1037, 0.1037, 0.1037, 1.8566, 1.8566, 1.8566], dtype=torch.float64)\n",
      "tensor(0.9676, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 89 was 96.8%.\n",
      "current params: tensor([0.1078, 0.1078, 0.1078, 1.8661, 1.8661, 1.8661], dtype=torch.float64)\n",
      "tensor(0.9686, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 90 was 96.9%.\n",
      "current params: tensor([0.1107, 0.1107, 0.1107, 1.8754, 1.8754, 1.8754], dtype=torch.float64)\n",
      "tensor(0.9696, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 91 was 97.0%.\n",
      "current params: tensor([0.1126, 0.1126, 0.1126, 1.8848, 1.8848, 1.8848], dtype=torch.float64)\n",
      "tensor(0.9701, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 92 was 97.0%.\n",
      "current params: tensor([0.1137, 0.1137, 0.1137, 1.8941, 1.8941, 1.8941], dtype=torch.float64)\n",
      "tensor(0.9701, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 93 was 97.0%.\n",
      "current params: tensor([0.1139, 0.1139, 0.1139, 1.9034, 1.9034, 1.9034], dtype=torch.float64)\n",
      "tensor(0.9701, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 94 was 97.0%.\n",
      "current params: tensor([0.1134, 0.1134, 0.1134, 1.9127, 1.9127, 1.9127], dtype=torch.float64)\n",
      "tensor(0.9701, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 95 was 96.9%.\n",
      "current params: tensor([0.1122, 0.1122, 0.1122, 1.9219, 1.9219, 1.9219], dtype=torch.float64)\n",
      "tensor(0.9696, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 96 was 96.9%.\n",
      "current params: tensor([0.1105, 0.1105, 0.1105, 1.9312, 1.9312, 1.9312], dtype=torch.float64)\n",
      "tensor(0.9691, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 97 was 96.8%.\n",
      "current params: tensor([0.1081, 0.1081, 0.1081, 1.9403, 1.9403, 1.9403], dtype=torch.float64)\n",
      "tensor(0.9687, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 98 was 96.7%.\n",
      "current params: tensor([0.1053, 0.1053, 0.1053, 1.9495, 1.9495, 1.9495], dtype=torch.float64)\n",
      "tensor(0.9677, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 99 was 96.6%.\n",
      "optimization complete\n",
      "Final params: tensor([0.1053, 0.1053, 0.1053, 1.9495, 1.9495, 1.9495], dtype=torch.float64)\n",
      "Iterations: 100 Peak Memory Usage: 262.765625 MiB\n"
     ]
    }
   ],
   "source": [
    "#memory usage\n",
    "\n",
    "import sys\n",
    "# path to steric_simulator module relative to notebook\n",
    "sys.path.append(\"C:\\\\Users\\\\denys\\\\AMGEN\\\\\")\n",
    "import copy\n",
    "from KineticAssembly_AD import ReactionNetwork, VectorizedRxnNet, VecSim, Optimizer, EquilibriumSolver\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import DoubleTensor as Tensor\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "from memory_profiler import memory_usage\n",
    "sys.path.append(\"KineticAssembly_AD/\")\n",
    "\n",
    "\n",
    "base_input = 'trimer.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()\n",
    "\n",
    "rn.reset()\n",
    "\n",
    "print(\"Largest Complex node index: \", rn.largest_complex)\n",
    "\n",
    "def run_optimization(optimizer, verbose=False, conc_scale=1e-1):\n",
    "    \"\"\"\n",
    "    Wrapper function to run the optimizer's optimize method.\n",
    "    \n",
    "    Parameters:\n",
    "    - optimizer: Optimizer object\n",
    "    - verbose: Bool, verbosity flag\n",
    "    - conc_scale: Float, concentration scale\n",
    "    \"\"\"\n",
    "    optimizer.optimize(verbose=verbose, conc_scale=conc_scale)\n",
    "\n",
    "\n",
    "for i in [10,100]:\n",
    "    optim = Optimizer(reaction_network=rn,\n",
    "                    sim_runtime=1,\n",
    "                    optim_iterations=i,\n",
    "                    learning_rate=0.01,\n",
    "                      \n",
    "                    device='cpu')\n",
    "    peak_mem = memory_usage((run_optimization, (optim,)), max_usage=True)\n",
    "    rn.reset()\n",
    "    del optim\n",
    "    print(f\"Iterations: {i} Peak Memory Usage: {peak_mem} MiB\")\n",
    "    sys.stdout.flush()\n",
    "# final_rn = copy.deepcopy(rn)\n",
    "# optim.rn.update_reaction_net(final_rn)\n",
    "# optim.plot_yield().savefig('yield.png', format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de8a00dc-2796-4c89-bce8-6dedc4c92dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['default_assoc', 1.0]\n",
      "[(0, {'struct': <networkx.classes.graph.Graph object at 0x000002C8F2D77E48>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (1, {'struct': <networkx.classes.graph.Graph object at 0x000002C8F2D77EB8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (2, {'struct': <networkx.classes.graph.Graph object at 0x000002C8F2D77DD8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})]\n",
      "New node added - Node index: 3 ; Node label: AB \n",
      "New node added - Node index: 4 ; Node label: AC \n",
      "New node added - Node index: 5 ; Node label: BC \n",
      "New node added - Node index: 6 ; Node label: ABC \n",
      "Reaction Network Completed\n",
      "Reaction rates:  tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64, grad_fn=<CopySlices>)\n",
      "dGs:  tensor([-20., -20., -20., -40., -40., -40.], dtype=torch.float64)\n",
      "Species Concentrations:  tensor([100., 100., 100.,   0.,   0.,   0.,   0.], dtype=torch.float64)\n",
      "Shifting to device:  cpu\n",
      "Reaction Parameters before optimization: \n",
      "[Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64, requires_grad=True)]\n",
      "Optimizer State: <bound method Optimizer.state_dict of Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    weight_decay: 0\n",
      ")>\n",
      "Using CPU\n",
      "Yield on sim. iteration 0 was 67.4%.\n",
      "current params: tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor(0.6742, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 1 was 67.9%.\n",
      "current params: tensor([0.9900, 0.9900, 0.9900, 1.0100, 1.0100, 1.0100], dtype=torch.float64)\n",
      "tensor(0.6797, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 2 was 68.4%.\n",
      "current params: tensor([0.9800, 0.9800, 0.9800, 1.0200, 1.0200, 1.0200], dtype=torch.float64)\n",
      "tensor(0.6844, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 3 was 68.9%.\n",
      "current params: tensor([0.9700, 0.9700, 0.9700, 1.0300, 1.0300, 1.0300], dtype=torch.float64)\n",
      "tensor(0.6899, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 4 was 69.6%.\n",
      "current params: tensor([0.9600, 0.9600, 0.9600, 1.0400, 1.0400, 1.0400], dtype=torch.float64)\n",
      "tensor(0.6960, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 5 was 70.0%.\n",
      "current params: tensor([0.9499, 0.9499, 0.9499, 1.0500, 1.0500, 1.0500], dtype=torch.float64)\n",
      "tensor(0.7002, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 6 was 70.5%.\n",
      "current params: tensor([0.9399, 0.9399, 0.9399, 1.0600, 1.0600, 1.0600], dtype=torch.float64)\n",
      "tensor(0.7056, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 7 was 71.0%.\n",
      "current params: tensor([0.9298, 0.9298, 0.9298, 1.0699, 1.0699, 1.0699], dtype=torch.float64)\n",
      "tensor(0.7104, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 8 was 71.5%.\n",
      "current params: tensor([0.9197, 0.9197, 0.9197, 1.0799, 1.0799, 1.0799], dtype=torch.float64)\n",
      "tensor(0.7159, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 9 was 72.0%.\n",
      "optimization complete\n",
      "Final params: tensor([0.9197, 0.9197, 0.9197, 1.0799, 1.0799, 1.0799], dtype=torch.float64)\n",
      "Time: 10 iterations: 8.587785243988037\n"
     ]
    }
   ],
   "source": [
    "#computational power usage\n",
    "import sys\n",
    "# path to steric_simulator module relative to notebook\n",
    "sys.path.append(\"C:\\\\Users\\\\denys\\\\AMGEN\\\\\")\n",
    "import copy\n",
    "from KineticAssembly_AD import ReactionNetwork, VectorizedRxnNet, VecSim, Optimizer, EquilibriumSolver\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import DoubleTensor as Tensor\n",
    "import numpy as np\n",
    "sys.path.append(\"KineticAssembly_AD/\")\n",
    "from reaction_network import gtostr\n",
    "import time\n",
    "\n",
    "base_input = './trimer.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()\n",
    "\n",
    "rn.reset()\n",
    "\n",
    "for i in [10]:\n",
    "    optim = Optimizer(reaction_network=rn,\n",
    "                    sim_runtime=1,\n",
    "                    optim_iterations=i,\n",
    "                    learning_rate=.01,\n",
    "                    device='cpu')\n",
    "    t1 = time.time()\n",
    "    optim.optimize(verbose=False,conc_scale=1e-1)\n",
    "    t2 = time.time()\n",
    "    rn.reset()\n",
    "    del optim\n",
    "    print(f\"Time: {i} iterations: {t2-t1}\")\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0115ebcd-f0bb-4fa2-9151-b4afefb1b92e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
