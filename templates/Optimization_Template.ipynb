{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Framework using auto-diff to optimize binding rates\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules\n",
    "\n",
    "Every Jupyter Notebook requires the path to the KineticAssembly_AD modules (.py files in the root directory) to be mentioned. This can be done by adding the path to the 'PATH' variable of the system environment. \n",
    "\n",
    "Additonal modules are also imported which are required to run any analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make sure jupyter path is correct for loading local moudules\n",
    "import sys\n",
    "path_to_repo=\"C:\\\\Users\\\\denys\\\\AMGEN\\\\\"   \n",
    "#Insert your path here\n",
    "# path_to_repo=\"\"\n",
    "sys.path.append(path_to_repo)\n",
    "\n",
    "import copy\n",
    "from KineticAssembly_AD import ReactionNetwork, VectorizedRxnNet, VecSim, Optimizer, EquilibriumSolver\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import DoubleTensor as Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Reaction Network\n",
    "Before we begin to run the optimization routine, we need to create a Reaction Network that stores all the parameters required to run a simulation and other routines. The Reaction Network can be created by reading an input file. More information on how to create an input file can be found in the User Guide. \n",
    "\n",
    "Here a simple trimer model is used to run a simulation.\n",
    "#### Read the corresponding input file and call the ReactionNetwork class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['default_assoc', 1.0]\n",
      "['homo_rates', True]\n",
      "[(0, {'struct': <networkx.classes.graph.Graph object at 0x0000022D8C8A5C88>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (1, {'struct': <networkx.classes.graph.Graph object at 0x0000022D8C884828>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (2, {'struct': <networkx.classes.graph.Graph object at 0x0000022D8C27CC18>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (3, {'struct': <networkx.classes.graph.Graph object at 0x0000022D846C6550>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (4, {'struct': <networkx.classes.graph.Graph object at 0x0000022D846C68D0>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})]\n",
      "New node added - Node index: 5 ; Node label: AB \n",
      "New node added - Node index: 6 ; Node label: AE \n",
      "New node added - Node index: 7 ; Node label: BC \n",
      "New node added - Node index: 8 ; Node label: ABE \n",
      "New node added - Node index: 9 ; Node label: CD \n",
      "New node added - Node index: 10 ; Node label: ABC \n",
      "New node added - Node index: 11 ; Node label: ABCE \n",
      "New node added - Node index: 12 ; Node label: DE \n",
      "New node added - Node index: 13 ; Node label: ADE \n",
      "New node added - Node index: 14 ; Node label: BCD \n",
      "New node added - Node index: 15 ; Node label: ABDE \n",
      "New node added - Node index: 16 ; Node label: ABCD \n",
      "New node added - Node index: 17 ; Node label: ABCDE \n",
      "New node added - Node index: 18 ; Node label: CDE \n",
      "New node added - Node index: 19 ; Node label: BCDE \n",
      "New node added - Node index: 20 ; Node label: ACDE \n",
      "Reaction Network Completed\n"
     ]
    }
   ],
   "source": [
    "base_input = './fivemer_homorates.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking reaction network\n",
    "\n",
    "The ReactionNetwork is a networkx object which creates a graph network with each node as species that can be present in the system according to the binding rules given in the input file. Each node has a unique index number that can be used to access attributes stored for that species. Each edge represents a reaction and is associated with a unique reaction_id, on and off rates and the dG value for that reaction.\n",
    "\n",
    "\n",
    "After creating a Reaction Network we can looping over all network nodes to check if all species are created\n",
    "Creating a dictionary for later reference. This dictionary holds the reactants as keys and values as the reaction index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species present in the Reaction Network: \n",
      "Index  --  Species\n",
      "  0    --  A     \n",
      "  1    --  B     \n",
      "  2    --  C     \n",
      "  3    --  D     \n",
      "  4    --  E     \n",
      "  5    --  AB    \n",
      "  6    --  AE    \n",
      "  7    --  BC    \n",
      "  8    --  ABE   \n",
      "  9    --  CD    \n",
      " 10    --  ABC   \n",
      " 11    --  ABCE  \n",
      " 12    --  DE    \n",
      " 13    --  ADE   \n",
      " 14    --  BCD   \n",
      " 15    --  ABDE  \n",
      " 16    --  ABCD  \n",
      " 17    --  ABCDE \n",
      " 18    --  CDE   \n",
      " 19    --  BCDE  \n",
      " 20    --  ACDE  \n",
      "\n",
      "Total Number of Reactions:  40\n",
      "Total Number of Species:  21\n",
      "\n",
      "{(0, 5): 0, (0, 6): 1, (0, 10): 24, (0, 13): 30, (0, 16): 34, (0, 20): 36, (0, 17): 38, (1, 5): 0, (1, 7): 2, (1, 8): 3, (1, 14): 28, (1, 15): 32, (1, 19): 37, (1, 17): 39, (2, 7): 2, (2, 9): 4, (2, 10): 5, (2, 11): 6, (2, 18): 31, (2, 20): 33, (2, 17): 35, (3, 9): 4, (3, 12): 7, (3, 13): 8, (3, 14): 9, (3, 15): 10, (3, 16): 11, (3, 17): 12, (4, 6): 1, (4, 12): 7, (4, 8): 13, (4, 18): 14, (4, 11): 15, (4, 19): 16, (4, 17): 17, (5, 10): 5, (5, 8): 13, (5, 16): 18, (5, 15): 19, (5, 17): 20, (6, 8): 3, (6, 13): 8, (6, 11): 21, (6, 20): 22, (6, 17): 23, (7, 14): 9, (7, 11): 21, (7, 10): 24, (7, 19): 25, (7, 17): 26, (8, 11): 6, (8, 15): 10, (8, 17): 27, (9, 18): 14, (9, 16): 18, (9, 20): 22, (9, 17): 27, (9, 14): 28, (10, 16): 11, (10, 11): 15, (10, 17): 29, (11, 17): 12, (12, 15): 19, (12, 19): 25, (12, 17): 29, (12, 13): 30, (12, 18): 31, (13, 17): 26, (13, 15): 32, (13, 20): 33, (14, 19): 16, (14, 17): 23, (14, 16): 34, (15, 17): 35, (16, 17): 17, (18, 17): 20, (18, 20): 36, (18, 19): 37, (19, 17): 38, (20, 17): 39}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "\n",
    "print(\"Species present in the Reaction Network: \")\n",
    "print(\"%3s  %2s  %2s\" %(\"Index\",\"--\",'Species'))\n",
    "for n in rn.network.nodes():\n",
    "    print(\"%3d  %4s  %-6s\" %(n,\"--\",gtostr(rn.network.nodes[n]['struct'])))\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_dict[(n,k)] = uid\n",
    "\n",
    "print()\n",
    "print(\"Total Number of Reactions: \",rn._rxn_count)\n",
    "print(\"Total Number of Species: \",len(rn.network.nodes()))\n",
    "        \n",
    "# Dictionary that stores source,destination of an edge and maps it to its unique id\n",
    "#Key : (First Reactant, Product)\n",
    "#Value : (Reaction_id)\n",
    "print()\n",
    "print(uid_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the initial parameter values \n",
    "The next step is to define the initial conditions for the simulation. The initial concentrations are specified from the input file. However, the initial value of the association rates can be specified either through the input file \n",
    "\n",
    "From the user_input file, currently the code only allows 1 value to be read (from default_assoc parameter).\n",
    "\n",
    "To set starting rates to different values the next code block takes in a list/array of all rxn rates and updates them in the reaction network object.\n",
    "\n",
    "For a hetero-trimer there are 6 reaction rates.\n",
    "Also defines the Vectorized Rxn Net class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of new_kon 40\n",
      "{'k_on': tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': tensor(0.1659, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': tensor(1.4385, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 24}\n",
      "{'k_on': tensor(0.2833, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 30}\n",
      "{'k_on': tensor(0.6973, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 34}\n",
      "{'k_on': tensor(0.4393, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 36}\n",
      "{'k_on': tensor(2.2715, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 38}\n",
      "{'k_on': tensor(0.1000, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': tensor(0.1759, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': tensor(0.1957, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': tensor(1.7023, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 28}\n",
      "{'k_on': tensor(1.1309, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 32}\n",
      "{'k_on': tensor(2.7781, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 37}\n",
      "{'k_on': tensor(1.8975, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 39}\n",
      "{'k_on': tensor(0.1759, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': tensor(0.2916, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': tensor(0.2749, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': tensor(0.5285, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 6}\n",
      "{'k_on': tensor(1.1117, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 31}\n",
      "{'k_on': tensor(2.4661, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 33}\n",
      "{'k_on': tensor(1.2320, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 35}\n",
      "{'k_on': tensor(0.2916, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': tensor(0.4895, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 7}\n",
      "{'k_on': tensor(0.2621, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 8}\n",
      "{'k_on': tensor(0.5433, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 9}\n",
      "{'k_on': tensor(0.1934, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 10}\n",
      "{'k_on': tensor(0.1619, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 11}\n",
      "{'k_on': tensor(0.2635, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 12}\n",
      "{'k_on': tensor(0.1659, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': tensor(0.4895, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 7}\n",
      "{'k_on': tensor(0.1062, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 13}\n",
      "{'k_on': tensor(0.8314, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 14}\n",
      "{'k_on': tensor(0.8033, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 15}\n",
      "{'k_on': tensor(0.8828, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 16}\n",
      "{'k_on': tensor(0.5243, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 17}\n",
      "{'k_on': tensor(0.2749, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': tensor(0.1062, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 13}\n",
      "{'k_on': tensor(0.3346, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 18}\n",
      "{'k_on': tensor(1.0957, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 19}\n",
      "{'k_on': tensor(0.4478, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 20}\n",
      "{'k_on': tensor(0.1957, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': tensor(0.2621, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 8}\n",
      "{'k_on': tensor(0.9870, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 21}\n",
      "{'k_on': tensor(0.1838, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 22}\n",
      "{'k_on': tensor(0.3705, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 23}\n",
      "{'k_on': tensor(0.5433, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 9}\n",
      "{'k_on': tensor(0.9870, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 21}\n",
      "{'k_on': tensor(1.4385, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 24}\n",
      "{'k_on': tensor(1.1755, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 25}\n",
      "{'k_on': tensor(1.3269, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 26}\n",
      "{'k_on': tensor(0.5285, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 6}\n",
      "{'k_on': tensor(0.1934, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 10}\n",
      "{'k_on': tensor(0.5962, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 27}\n",
      "{'k_on': tensor(0.8314, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 14}\n",
      "{'k_on': tensor(0.3346, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 18}\n",
      "{'k_on': tensor(0.1838, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 22}\n",
      "{'k_on': tensor(0.5962, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 27}\n",
      "{'k_on': tensor(1.7023, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 28}\n",
      "{'k_on': tensor(0.1619, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 11}\n",
      "{'k_on': tensor(0.8033, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 15}\n",
      "{'k_on': tensor(1.8771, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 29}\n",
      "{'k_on': tensor(0.2635, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 12}\n",
      "{'k_on': tensor(1.0957, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 19}\n",
      "{'k_on': tensor(1.1755, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 25}\n",
      "{'k_on': tensor(1.8771, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 29}\n",
      "{'k_on': tensor(0.2833, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 30}\n",
      "{'k_on': tensor(1.1117, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 31}\n",
      "{'k_on': tensor(1.3269, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 26}\n",
      "{'k_on': tensor(1.1309, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 32}\n",
      "{'k_on': tensor(2.4661, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 33}\n",
      "{'k_on': tensor(0.8828, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 16}\n",
      "{'k_on': tensor(0.3705, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 23}\n",
      "{'k_on': tensor(0.6973, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 34}\n",
      "{'k_on': tensor(1.2320, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 35}\n",
      "{'k_on': tensor(0.5243, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 17}\n",
      "{'k_on': tensor(0.4478, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 20}\n",
      "{'k_on': tensor(0.4393, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 36}\n",
      "{'k_on': tensor(2.7781, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 37}\n",
      "{'k_on': tensor(2.2715, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 38}\n",
      "{'k_on': tensor(1.8975, dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 39}\n",
      "Reaction rates:  tensor([0.1000, 0.1659, 0.1759, 0.1957, 0.2916, 0.2749, 0.5285, 0.4895, 0.2621,\n",
      "        0.5433, 0.1934, 0.1619, 0.2635, 0.1062, 0.8314, 0.8033, 0.8828, 0.5243,\n",
      "        0.3346, 1.0957, 0.4478, 0.9870, 0.1838, 0.3705, 1.4385, 1.1755, 1.3269,\n",
      "        0.5962, 1.7023, 1.8771, 0.2833, 1.1117, 1.1309, 2.4661, 0.6973, 1.2320,\n",
      "        0.4393, 2.7781, 2.2715, 1.8975], dtype=torch.float64,\n",
      "       grad_fn=<CopySlices>)\n",
      "dGs:  tensor([-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
      "        -40., -20., -20., -20., -20., -40., -20., -20., -40., -20., -20., -40.,\n",
      "        -20., -20., -40., -40., -20., -40., -20., -20., -20., -20., -20., -40.,\n",
      "        -20., -20., -40., -40.], dtype=torch.float64)\n",
      "Species Concentrations:  tensor([100., 100., 100., 100., 100.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "       dtype=torch.float64)\n",
      "Shifting to device:  cpu\n",
      "tensor([0.1000, 0.1659, 0.1759, 0.1957, 0.2916, 0.2749, 0.5285, 0.4895, 0.2621,\n",
      "        0.5433, 0.1934, 0.1619, 0.2635, 0.1062, 0.8314, 0.8033, 0.8828, 0.5243,\n",
      "        0.3346, 1.0957, 0.4478, 0.9870, 0.1838, 0.3705, 1.4385, 1.1755, 1.3269,\n",
      "        0.5962, 1.7023, 1.8771, 0.2833, 1.1117, 1.1309, 2.4661, 0.6973, 1.2320,\n",
      "        0.4393, 2.7781, 2.2715, 1.8975], dtype=torch.float64,\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "#Define an empty torch tensor with length equal to number of reactions\n",
    "new_kon = torch.zeros([rn._rxn_count], requires_grad=True).double()\n",
    "\n",
    "#Set the initial value of the association rates\n",
    "#Note that this code sets all association rates at the same value\n",
    "\n",
    "#To set individual rates to different values, we need to create an list/array with different values.\n",
    "length = 40\n",
    "min_val = 0.1\n",
    "max_val = 3.0\n",
    "init_val = []\n",
    "\n",
    "for i in range(length):\n",
    "    # Linearly interpolate the current maximum from min_val up to max_val\n",
    "    current_max = min_val + (i / (length - 1)) * (max_val - min_val)\n",
    "    # Draw a random float uniformly between min_val and current_max\n",
    "    val = np.random.uniform(min_val, current_max)\n",
    "    init_val.append(val)\n",
    "\n",
    "#Else we could assign all initial values to be equal to 1; performs bad for lower indeces\n",
    "#init_val = 1\n",
    "\n",
    "\n",
    "new_kon = new_kon + Tensor(init_val)\n",
    "print(\"Len of new_kon\", len(new_kon))\n",
    "update_kon_dict = {}\n",
    "for edge in rn.network.edges:\n",
    "    update_kon_dict[edge] = new_kon[uid_dict[edge]]\n",
    "\n",
    "nx.set_edge_attributes(rn.network,update_kon_dict,'k_on')\n",
    "for edge in rn.network.edges:\n",
    "    print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "\n",
    "vec_rn = VectorizedRxnNet(rn, dev='cpu')\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species present in the Reaction Network: \n",
      "Index  --  Species\n",
      "  0    --  A     \n",
      "  1    --  B     \n",
      "  2    --  C     \n",
      "  3    --  D     \n",
      "  4    --  E     \n",
      "  5    --  AB    \n",
      "  6    --  AE    \n",
      "  7    --  BC    \n",
      "  8    --  ABE   \n",
      "  9    --  CD    \n",
      " 10    --  ABC   \n",
      " 11    --  ABCE  \n",
      " 12    --  DE    \n",
      " 13    --  ADE   \n",
      " 14    --  BCD   \n",
      " 15    --  ABDE  \n",
      " 16    --  ABCD  \n",
      " 17    --  ABCDE \n",
      " 18    --  CDE   \n",
      " 19    --  BCDE  \n",
      " 20    --  ACDE  \n",
      "\n",
      "Initial Binding Rates: \n",
      "Reaction        Id           kon\n",
      "\n",
      "A   +   B       0 \t    0.10\n",
      "E   +  BA      13 \t    0.11\n",
      "D   + BAC      11 \t    0.16\n",
      "A   +   E       1 \t    0.17\n",
      "B   +   C       2 \t    0.18\n",
      "EA  +  CD      22 \t    0.18\n",
      "D   + BAE      10 \t    0.19\n",
      "B   +  EA       3 \t    0.20\n",
      "D   +  EA       8 \t    0.26\n",
      "D   +EBAC      12 \t    0.26\n",
      "C   +  BA       5 \t    0.27\n",
      "A   +  ED      30 \t    0.28\n",
      "C   +   D       4 \t    0.29\n",
      "BA  +  CD      18 \t    0.33\n",
      "EA  + BCD      23 \t    0.37\n",
      "A   + ECD      36 \t    0.44\n",
      "BA  + ECD      20 \t    0.45\n",
      "D   +   E       7 \t    0.49\n",
      "E   +BACD      17 \t    0.52\n",
      "C   + BAE       6 \t    0.53\n",
      "D   +  BC       9 \t    0.54\n",
      "BAE +  CD      27 \t    0.60\n",
      "A   + BCD      34 \t    0.70\n",
      "E   + BAC      15 \t    0.80\n",
      "E   +  CD      14 \t    0.83\n",
      "E   + BCD      16 \t    0.88\n",
      "EA  +  BC      21 \t    0.99\n",
      "BA  +  ED      19 \t    1.10\n",
      "C   +  ED      31 \t    1.11\n",
      "B   + EAD      32 \t    1.13\n",
      "BC  +  ED      25 \t    1.18\n",
      "C   +EBAD      35 \t    1.23\n",
      "BC  + EAD      26 \t    1.33\n",
      "A   +  BC      24 \t    1.44\n",
      "B   +  CD      28 \t    1.70\n",
      "BAC +  ED      29 \t    1.88\n",
      "B   +EACD      39 \t    1.90\n",
      "A   +EBCD      38 \t    2.27\n",
      "C   + EAD      33 \t    2.47\n",
      "B   + ECD      37 \t    2.78\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "\n",
    "print(\"Species present in the Reaction Network: \")\n",
    "print(\"%3s  %2s  %2s\" %(\"Index\",\"--\",'Species'))\n",
    "\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    print(\"%3d  %4s  %-6s\" %(n,\"--\",gtostr(rn.network.nodes[n]['struct'])))\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (\"\".join(list(r1)),\"\".join(list(r2)))\n",
    "        uid_val = {'reactants':reactants,'kon':v['k_on'],'score':v['rxn_score'],'koff':v['k_off'],'uid':uid}\n",
    "        if uid not in uid_dict.keys():\n",
    "            uid_dict[uid] = uid_val\n",
    "\n",
    "print()\n",
    "print(\"Initial Binding Rates: \")\n",
    "\n",
    "ind_sort = np.argsort(vec_rn.kon.detach().numpy())\n",
    "print(\"%-16s%-3s %12s\" %(\"Reaction\",\"Id\",\"kon\"))\n",
    "print()\n",
    "for i in ind_sort:\n",
    "    print(\"%-4s%1s%4s %7d \\t%8.2f\" %(uid_dict[i]['reactants'][0],\"+\",uid_dict[i]['reactants'][1],uid_dict[i]['uid'],vec_rn.kon[i].item()))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using the optimizer ##\n",
    "\n",
    "### Define an instance of the optimizer class\n",
    "#### Input Arguments:\n",
    "\n",
    "reaction_network : Input the vectorized rxn network\n",
    "\n",
    "sim_runtime: The runtime of the kinetic simulation. Needs to be same as the time over the experimental reaction data.\n",
    "\n",
    "optim_iterations: No. of iterations to run the optimization. Can start at low values(100) and increase depending upon memory usage.\n",
    "\n",
    "learning_rate = The size of the gradient descent step for updating parameter values. Needs to be atleast (1e-3-1e-1)* min{parameter value}. If learning rate is too high, it can take a longer step and sometimes lead to negative value of parameters which is unphysical. Requires some trial runs to find the best value. \n",
    "\n",
    "device: cpu or gpu\n",
    "\n",
    "method: Choose which pytorch based optimized to use for gradient descent - Adam or RMSprop\n",
    "\n",
    "mom: Only for RMSprop method. Use momentum term during gradient descent. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.utils.benchmark as benchmark\n",
    "import time as time_mod\n",
    "\n",
    "t1 = time_mod.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vec_rn.reset(reset_params=True)\n",
    "optim = Optimizer(reaction_network=vec_rn,\n",
    "                  sim_runtime=1,\n",
    "                  optim_iterations=100,\n",
    "                  learning_rate=1e-2,\n",
    "                  device='cpu',method=\"RMSprop\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the optimization method\n",
    "\n",
    "#### Input arguments\n",
    "\n",
    "conc_scale: Controls the conc step at each iteration. Since the numerical integration is not performed over fixed time steps but over fixed conc. steps. For e.g. for a value of 1uM, at each iteration step a total of app. 1uM is reacted (includes all species). Can be run using the default value. A general rule is use conc_scale = 0.01 * Max_yield\n",
    "\n",
    "conc_thresh: This can be used to periodically decrease the conc_scale parameter. After each iteration if the conc_scale is greater than the conc_thresh, then the conc_scale is decreased by mod_factor. Can be run using the default value. \n",
    "\n",
    "mod_bool: This argument is necessary to fix the mass balance criteria. Sometimes if the conc_scale is large, then the simulation can lead to a higher consumption of a particular species which is very low in conc, and create more of this species out of nothing. Default value:True\n",
    "\n",
    "max_thresh: Max. allowed values of parameters being updated. Beyond this maximum a penalty is imposed on the cost function. (Regularization)\n",
    "\n",
    "max_yield: It is a control variable that is used to store the updated parameter values over all iterations for further analysis. The parameter values are stored only if the current yield exceed this max_yield. \n",
    "\n",
    "yield_species: Yield of the species being optimized(node index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reaction Parameters before optimization: \n",
      "[Parameter containing:\n",
      "tensor([0.1000, 0.1957, 0.5285, 0.2635, 0.3346, 0.4478], dtype=torch.float64,\n",
      "       requires_grad=True)]\n",
      "Optimizer State: <bound method Optimizer.state_dict of RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")>\n",
      "Using CPU\n",
      "Yield on sim. iteration 0 was 63.5%.\n",
      "current params: tensor([0.1000, 0.1957, 0.5285, 0.2635, 0.3346, 0.4478], dtype=torch.float64)\n",
      "tensor(0.6356, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 1 was 0.0%.\n",
      "current params: tensor([8.8336e-09, 9.5719e-02, 4.2848e-01, 3.6352e-01, 2.3460e-01, 5.4782e-01],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 2 was 71.9%.\n",
      "current params: tensor([0.0994, 0.1955, 0.4363, 0.3635, 0.2526, 0.5478], dtype=torch.float64)\n",
      "tensor(0.7198, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 3 was 69.8%.\n",
      "current params: tensor([0.1649, 0.1877, 0.3562, 0.4240, 0.1751, 0.6240], dtype=torch.float64)\n",
      "tensor(0.6986, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 4 was 75.8%.\n",
      "current params: tensor([0.1593, 0.1799, 0.2951, 0.4582, 0.0904, 0.7017], dtype=torch.float64)\n",
      "tensor(0.7587, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 5 was 79.2%.\n",
      "current params: tensor([0.1528, 0.1703, 0.2353, 0.4854, 0.1903, 0.7682], dtype=torch.float64)\n",
      "tensor(0.7924, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 6 was 83.1%.\n",
      "current params: tensor([0.1451, 0.1607, 0.1768, 0.5128, 0.1876, 0.8195], dtype=torch.float64)\n",
      "tensor(0.8315, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 7 was 86.2%.\n",
      "current params: tensor([0.1358, 0.1501, 0.1174, 0.5369, 0.1850, 0.8674], dtype=torch.float64)\n",
      "tensor(0.8625, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 8 was 87.8%.\n",
      "current params: tensor([0.1246, 0.1382, 0.0557, 0.5576, 0.1824, 0.9136], dtype=torch.float64)\n",
      "tensor(0.8790, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 9 was 88.6%.\n",
      "current params: tensor([0.1099, 0.1247, 0.1546, 0.5738, 0.1799, 0.9600], dtype=torch.float64)\n",
      "tensor(0.8869, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 10 was 89.7%.\n",
      "current params: tensor([0.0954, 0.1103, 0.1471, 0.5970, 0.1769, 0.9922], dtype=torch.float64)\n",
      "tensor(0.8979, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 11 was 88.0%.\n",
      "current params: tensor([0.1452, 0.0940, 0.1395, 0.6200, 0.1736, 1.0219], dtype=torch.float64)\n",
      "tensor(0.8804, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 12 was 89.3%.\n",
      "current params: tensor([0.1353, 0.1573, 0.1345, 0.6389, 0.1677, 1.0511], dtype=torch.float64)\n",
      "tensor(0.8931, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 13 was 90.2%.\n",
      "current params: tensor([0.1250, 0.1480, 0.1263, 0.6556, 0.1652, 1.0809], dtype=torch.float64)\n",
      "tensor(0.9021, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 14 was 90.8%.\n",
      "current params: tensor([0.1133, 0.1380, 0.1178, 0.6721, 0.1626, 1.1093], dtype=torch.float64)\n",
      "tensor(0.9086, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 15 was 91.2%.\n",
      "current params: tensor([0.0999, 0.1272, 0.1087, 0.6883, 0.1599, 1.1365], dtype=torch.float64)\n",
      "tensor(0.9128, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 16 was 91.2%.\n",
      "current params: tensor([0.1440, 0.1154, 0.0992, 0.7045, 0.1572, 1.1625], dtype=torch.float64)\n",
      "tensor(0.9124, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 17 was 90.1%.\n",
      "current params: tensor([0.1341, 0.1030, 0.1723, 0.7178, 0.1527, 1.1887], dtype=torch.float64)\n",
      "tensor(0.9011, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 18 was 90.2%.\n",
      "current params: tensor([0.1242, 0.0899, 0.1690, 0.7340, 0.1471, 1.2101], dtype=torch.float64)\n",
      "tensor(0.9022, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 19 was 91.7%.\n",
      "current params: tensor([0.1130, 0.1421, 0.1659, 0.7504, 0.1408, 1.2304], dtype=torch.float64)\n",
      "tensor(0.9180, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 20 was 92.1%.\n",
      "current params: tensor([0.1013, 0.1329, 0.1609, 0.7659, 0.1378, 1.2512], dtype=torch.float64)\n",
      "tensor(0.9213, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 21 was 92.2%.\n",
      "current params: tensor([0.0877, 0.1229, 0.1558, 0.7815, 0.1349, 1.2713], dtype=torch.float64)\n",
      "tensor(0.9221, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 22 was 91.8%.\n",
      "current params: tensor([0.1266, 0.1120, 0.1503, 0.7974, 0.1320, 1.2905], dtype=torch.float64)\n",
      "tensor(0.9187, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 23 was 91.8%.\n",
      "current params: tensor([0.1163, 0.1007, 0.1464, 0.8105, 0.1270, 1.3108], dtype=torch.float64)\n",
      "tensor(0.9184, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 24 was 91.5%.\n",
      "current params: tensor([0.1048, 0.0881, 0.1425, 0.8237, 0.1215, 1.3304], dtype=torch.float64)\n",
      "tensor(0.9155, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 25 was 92.6%.\n",
      "current params: tensor([0.0917, 0.1334, 0.1386, 0.8370, 0.1154, 1.3493], dtype=torch.float64)\n",
      "tensor(0.9261, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 26 was 92.6%.\n",
      "current params: tensor([0.1281, 0.1241, 0.1327, 0.8503, 0.1127, 1.3681], dtype=torch.float64)\n",
      "tensor(0.9268, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "optim.rn.update_reaction_net(rn)\n",
    "optim.optimize(conc_scale=1e-1,conc_thresh=1e-1,mod_bool=True,mod_factor=10,max_thresh=1e8,max_yield=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = time_mod.perf_counter()\n",
    "print(\"Time taken for complete analysis: %.4f\" %(t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track the yield over optim iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optim.plot_yield()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the parameter values\n",
    "\n",
    "### This can be stored in a file for later analysis or used to find the best parameter value depending upon a condition. For e.g. the values that give a minimum error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields= []\n",
    "final_params=[]\n",
    "\n",
    "final_t50 = []\n",
    "final_t85 = []\n",
    "final_t95 = []\n",
    "final_t99 = []\n",
    "\n",
    "for i in range(len(optim.final_yields)):\n",
    "    yields.append(optim.final_yields[i])\n",
    "    final_params.append(optim.final_solns[i])\n",
    "    \n",
    "    #Storing the different time points it reaches a particular yield threshold\n",
    "    if optim.final_t85[i] == -1:\n",
    "        final_t85.append(1) \n",
    "    else:\n",
    "        final_t85.append(optim.final_t85[i]) \n",
    "    if optim.final_t95[i] == -1:\n",
    "        final_t95.append(1)\n",
    "    else:\n",
    "        final_t95.append(optim.final_t95[i])\n",
    "\n",
    "\n",
    "final_yield_arr = np.array(yields)\n",
    "final_param_arr = np.array(final_params)\n",
    "final_t85 = np.array(final_t85)\n",
    "final_t95 = np.array(final_t95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the ratio of ktri vs kdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mask_r = final_yield_arr > 0.1\n",
    "\n",
    "#Calculate the ratio\n",
    "ratio = final_param_arr[:,3]/final_param_arr[:,0]\n",
    "\n",
    "#Normalize the time scale (t = t*conc*max_rate)\n",
    "conc=vec_rn.initial_copies[0].item()\n",
    "scale_time = final_t95[mask_r]*conc*np.max(final_param_arr[mask_r],axis=1)\n",
    "#Calculate the y_per_time\n",
    "y_per_time = 0.95/scale_time\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(ratio,y_per_time,linestyle='',marker='o')\n",
    "ax.set_ylabel(\"Efficiency\",fontsize=20)\n",
    "ax.set_xlabel(\"Ratio\",fontsize=20)\n",
    "ax.tick_params(labelsize=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_indx = np.argmax(y_per_time)\n",
    "max_ratio = ratio[max_indx]\n",
    "max_rates = final_param_arr[max_indx]\n",
    "print(\"Ratio with maximum efficiency: \",max_ratio)\n",
    "\n",
    "reaction_rates = np.zeros(rn._rxn_count)\n",
    "counter=0\n",
    "for cls,uids in vec_rn.rxn_class.items():\n",
    "    for rid in uids:\n",
    "        reaction_rates[rid]=max_rates[counter]\n",
    "    counter+=1\n",
    "\n",
    "print(\"Optimal Rates: \",list(reaction_rates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
