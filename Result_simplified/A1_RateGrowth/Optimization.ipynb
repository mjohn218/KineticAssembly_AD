{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Framework using auto-diff to optimize binding rates\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules\n",
    "\n",
    "Every Jupyter Notebook requires the path to the KineticAssembly_AD modules (.py files in the root directory) to be mentioned. This can be done by adding the path to the 'PATH' variable of the system environment. \n",
    "\n",
    "Additonal modules are also imported which are required to run any analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make sure jupyter path is correct for loading local moudules\n",
    "import sys\n",
    "path_to_repo=\"C:\\\\Users\\\\denys\\\\AMGEN\\\\\"   \n",
    "#Insert your path here\n",
    "# path_to_repo=\"\"\n",
    "sys.path.append(path_to_repo)\n",
    "\n",
    "import copy\n",
    "from KineticAssembly_AD import ReactionNetwork, VectorizedRxnNet, VecSim, Optimizer, EquilibriumSolver\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import DoubleTensor as Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Reaction Network\n",
    "Before we begin to run the optimization routine, we need to create a Reaction Network that stores all the parameters required to run a simulation and other routines. The Reaction Network can be created by reading an input file. More information on how to create an input file can be found in the User Guide. \n",
    "\n",
    "Here a simple trimer model is used to run a simulation.\n",
    "#### Read the corresponding input file and call the ReactionNetwork class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['default_assoc', 1.0]\n",
      "['monomer_add_only', True]\n",
      "['homo_rates', True]\n",
      "[(0, {'struct': <networkx.classes.graph.Graph object at 0x0000023425591F60>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (1, {'struct': <networkx.classes.graph.Graph object at 0x0000023425A057B8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (2, {'struct': <networkx.classes.graph.Graph object at 0x0000023425A05C18>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (3, {'struct': <networkx.classes.graph.Graph object at 0x0000023425A05B00>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (4, {'struct': <networkx.classes.graph.Graph object at 0x0000023425B39710>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (5, {'struct': <networkx.classes.graph.Graph object at 0x000002342561C160>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (6, {'struct': <networkx.classes.graph.Graph object at 0x000002342561C198>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})]\n",
      "New node added - Node index: 7 ; Node label: AB \n",
      "New node added - Node index: 8 ; Node label: AH \n",
      "New node added - Node index: 9 ; Node label: BC \n",
      "New node added - Node index: 10 ; Node label: CD \n",
      "New node added - Node index: 11 ; Node label: ABC \n",
      "New node added - Node index: 12 ; Node label: ABH \n",
      "New node added - Node index: 13 ; Node label: BCD \n",
      "New node added - Node index: 14 ; Node label: DE \n",
      "New node added - Node index: 15 ; Node label: ABCD \n",
      "New node added - Node index: 16 ; Node label: EF \n",
      "New node added - Node index: 17 ; Node label: CDE \n",
      "New node added - Node index: 18 ; Node label: BCDE \n",
      "New node added - Node index: 19 ; Node label: ABCDE \n",
      "New node added - Node index: 20 ; Node label: FH \n",
      "New node added - Node index: 21 ; Node label: AFH \n",
      "New node added - Node index: 22 ; Node label: ABFH \n",
      "New node added - Node index: 23 ; Node label: DEF \n",
      "New node added - Node index: 24 ; Node label: CDEF \n",
      "New node added - Node index: 25 ; Node label: BCDEF \n",
      "New node added - Node index: 26 ; Node label: ABCDEF \n",
      "New node added - Node index: 27 ; Node label: ABCH \n",
      "New node added - Node index: 28 ; Node label: ABCDH \n",
      "New node added - Node index: 29 ; Node label: EFH \n",
      "New node added - Node index: 30 ; Node label: ABCDEH \n",
      "New node added - Node index: 31 ; Node label: DEFH \n",
      "New node added - Node index: 32 ; Node label: CDEFH \n",
      "New node added - Node index: 33 ; Node label: BCDEFH \n",
      "New node added - Node index: 34 ; Node label: ABCDEFH \n",
      "New node added - Node index: 35 ; Node label: AEFH \n",
      "New node added - Node index: 36 ; Node label: ABCFH \n",
      "New node added - Node index: 37 ; Node label: ABEFH \n",
      "New node added - Node index: 38 ; Node label: ABCDFH \n",
      "New node added - Node index: 39 ; Node label: ADEFH \n",
      "New node added - Node index: 40 ; Node label: ACDEFH \n",
      "New node added - Node index: 41 ; Node label: ABCEFH \n",
      "New node added - Node index: 42 ; Node label: ABDEFH \n",
      "Reaction Network Completed\n"
     ]
    }
   ],
   "source": [
    "base_input = './heptamer_rategrowth_ring.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking reaction network\n",
    "\n",
    "The ReactionNetwork is a networkx object which creates a graph network with each node as species that can be present in the system according to the binding rules given in the input file. Each node has a unique index number that can be used to access attributes stored for that species. Each edge represents a reaction and is associated with a unique reaction_id, on and off rates and the dG value for that reaction.\n",
    "\n",
    "\n",
    "After creating a Reaction Network we can looping over all network nodes to check if all species are created\n",
    "Creating a dictionary for later reference. This dictionary holds the reactants as keys and values as the reaction index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species present in the Reaction Network: \n",
      "Index  --  Species\n",
      "  0    --  A     \n",
      "  1    --  C     \n",
      "  2    --  B     \n",
      "  3    --  D     \n",
      "  4    --  E     \n",
      "  5    --  F     \n",
      "  6    --  H     \n",
      "  7    --  AB    \n",
      "  8    --  AH    \n",
      "  9    --  BC    \n",
      " 10    --  CD    \n",
      " 11    --  ABC   \n",
      " 12    --  ABH   \n",
      " 13    --  BCD   \n",
      " 14    --  DE    \n",
      " 15    --  ABCD  \n",
      " 16    --  EF    \n",
      " 17    --  CDE   \n",
      " 18    --  BCDE  \n",
      " 19    --  ABCDE \n",
      " 20    --  FH    \n",
      " 21    --  AFH   \n",
      " 22    --  ABFH  \n",
      " 23    --  DEF   \n",
      " 24    --  CDEF  \n",
      " 25    --  BCDEF \n",
      " 26    --  ABCDEF\n",
      " 27    --  ABCH  \n",
      " 28    --  ABCDH \n",
      " 29    --  EFH   \n",
      " 30    --  ABCDEH\n",
      " 31    --  DEFH  \n",
      " 32    --  CDEFH \n",
      " 33    --  BCDEFH\n",
      " 34    --  ABCDEFH\n",
      " 35    --  AEFH  \n",
      " 36    --  ABCFH \n",
      " 37    --  ABEFH \n",
      " 38    --  ABCDFH\n",
      " 39    --  ADEFH \n",
      " 40    --  ACDEFH\n",
      " 41    --  ABCEFH\n",
      " 42    --  ABDEFH\n",
      "\n",
      "Total Number of Reactions:  70\n",
      "Total Number of Species:  43\n",
      "\n",
      "{(0, 7): 0, (0, 8): 1, (0, 11): 30, (0, 15): 32, (0, 19): 36, (0, 21): 37, (0, 26): 45, (0, 35): 50, (0, 39): 53, (0, 40): 55, (0, 34): 57, (1, 9): 2, (1, 10): 3, (1, 11): 4, (1, 27): 31, (1, 17): 33, (1, 36): 41, (1, 24): 43, (1, 32): 54, (1, 41): 62, (1, 40): 65, (1, 34): 69, (2, 7): 0, (2, 9): 2, (2, 12): 5, (2, 13): 6, (2, 18): 35, (2, 22): 39, (2, 25): 44, (2, 33): 56, (2, 37): 58, (2, 42): 66, (2, 34): 67, (3, 10): 3, (3, 14): 7, (3, 13): 8, (3, 15): 9, (3, 23): 34, (3, 28): 46, (3, 31): 51, (3, 39): 59, (3, 38): 60, (3, 42): 63, (3, 34): 68, (4, 14): 7, (4, 16): 10, (4, 17): 11, (4, 18): 12, (4, 19): 13, (4, 29): 38, (4, 35): 40, (4, 37): 42, (4, 30): 48, (4, 41): 61, (4, 34): 64, (5, 16): 10, (5, 20): 14, (5, 21): 15, (5, 22): 16, (5, 23): 17, (5, 24): 18, (5, 25): 19, (5, 26): 20, (5, 36): 47, (5, 38): 49, (5, 34): 52, (6, 8): 1, (6, 20): 14, (6, 12): 21, (6, 27): 22, (6, 28): 23, (6, 29): 24, (6, 30): 25, (6, 31): 26, (6, 32): 27, (6, 33): 28, (6, 34): 29, (7, 11): 4, (7, 12): 21, (8, 12): 5, (8, 21): 15, (9, 13): 8, (9, 11): 30, (10, 13): 6, (10, 17): 11, (11, 15): 9, (11, 27): 22, (12, 22): 16, (12, 27): 31, (13, 18): 12, (13, 15): 32, (14, 23): 17, (14, 17): 33, (15, 19): 13, (15, 28): 23, (16, 29): 24, (16, 23): 34, (17, 24): 18, (17, 18): 35, (18, 25): 19, (18, 19): 36, (19, 26): 20, (19, 30): 25, (20, 21): 37, (20, 29): 38, (21, 22): 39, (21, 35): 40, (22, 36): 41, (22, 37): 42, (23, 31): 26, (23, 24): 43, (24, 32): 27, (24, 25): 44, (25, 33): 28, (25, 26): 45, (26, 34): 29, (27, 28): 46, (27, 36): 47, (28, 30): 48, (28, 38): 49, (29, 35): 50, (29, 31): 51, (30, 34): 52, (31, 39): 53, (31, 32): 54, (32, 40): 55, (32, 33): 56, (33, 34): 57, (35, 37): 58, (35, 39): 59, (36, 38): 60, (36, 41): 61, (37, 41): 62, (37, 42): 63, (38, 34): 64, (39, 40): 65, (39, 42): 66, (40, 34): 67, (41, 34): 68, (42, 34): 69}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "\n",
    "print(\"Species present in the Reaction Network: \")\n",
    "print(\"%3s  %2s  %2s\" %(\"Index\",\"--\",'Species'))\n",
    "for n in rn.network.nodes():\n",
    "    print(\"%3d  %4s  %-6s\" %(n,\"--\",gtostr(rn.network.nodes[n]['struct'])))\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_dict[(n,k)] = uid\n",
    "\n",
    "print()\n",
    "print(\"Total Number of Reactions: \",rn._rxn_count)\n",
    "print(\"Total Number of Species: \",len(rn.network.nodes()))\n",
    "        \n",
    "# Dictionary that stores source,destination of an edge and maps it to its unique id\n",
    "#Key : (First Reactant, Product)\n",
    "#Value : (Reaction_id)\n",
    "print()\n",
    "print(uid_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the initial parameter values \n",
    "The next step is to define the initial conditions for the simulation. The initial concentrations are specified from the input file. However, the initial value of the association rates can be specified either through the input file \n",
    "\n",
    "From the user_input file, currently the code only allows 1 value to be read (from default_assoc parameter).\n",
    "\n",
    "To set starting rates to different values the next code block takes in a list/array of all rxn rates and updates them in the reaction network object.\n",
    "\n",
    "For a hetero-trimer there are 6 reaction rates.\n",
    "Also defines the Vectorized Rxn Net class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 30}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 32}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 36}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 37}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 45}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 50}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 53}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 55}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 57}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 31}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 33}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 41}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 43}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 54}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 62}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 65}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 69}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 6}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 35}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 39}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 44}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 56}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 58}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 66}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 67}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 7}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 8}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 9}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 34}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 46}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 51}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 59}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 60}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 63}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 68}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 7}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 10}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 11}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 12}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 13}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 38}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 40}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 42}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 48}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 61}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 64}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 10}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 14}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 15}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 16}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 17}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 18}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 19}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 20}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 47}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 49}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 52}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 14}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 21}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 22}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 23}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 24}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 25}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 26}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 27}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 28}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 29}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 21}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 15}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 8}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 30}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 6}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 11}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 9}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 22}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 16}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 31}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 12}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 32}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 17}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 33}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 13}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 23}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 24}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 34}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 18}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 35}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 19}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 36}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 20}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 25}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 37}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 38}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 39}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 40}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 41}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 42}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 26}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 43}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 27}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 44}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 28}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 45}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 29}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 46}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 47}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 48}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 49}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 50}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 51}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 52}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 53}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 54}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 55}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 56}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 57}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 58}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 59}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 60}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 61}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 62}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 63}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 64}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 65}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 66}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 67}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 68}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 69}\n",
      "Reaction rates:  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       dtype=torch.float64, grad_fn=<CopySlices>)\n",
      "dGs:  tensor([-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
      "        -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
      "        -20., -20., -20., -20., -20., -40., -20., -20., -20., -20., -20., -20.,\n",
      "        -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
      "        -20., -20., -20., -20., -40., -20., -20., -20., -20., -40., -20., -20.,\n",
      "        -20., -20., -20., -20., -40., -20., -20., -40., -40., -40.],\n",
      "       dtype=torch.float64)\n",
      "Species Concentrations:  tensor([100., 100., 100., 100., 100., 100., 100.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.,   0.,   0.,   0.,   0.], dtype=torch.float64)\n",
      "Shifting to device:  cpu\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "#Define an empty torch tensor with length equal to number of reactions\n",
    "new_kon = torch.zeros([rn._rxn_count], requires_grad=True).double()\n",
    "\n",
    "#Set the initial value of the association rates\n",
    "#Note that this code sets all association rates at the same value\n",
    "\n",
    "#To set individual rates to different values, we need to create an list/array with different values.\n",
    "'''\n",
    "length = rn._rxn_count\n",
    "min_val = 0.1\n",
    "max_val = 3.0\n",
    "init_val = []\n",
    "\n",
    "np.random.seed(42)\n",
    "for i in range(length):\n",
    "    # Linearly interpolate the current maximum from min_val up to max_val\n",
    "    current_max = min_val + (i / (length - 1)) * (max_val - min_val)\n",
    "    # Draw a random float uniformly between min_val and current_max\n",
    "    val = np.random.uniform(min_val, current_max)\n",
    "    init_val.append(val)\n",
    "\n",
    "new_kon = new_kon + Tensor(init_val)\n",
    "    \n",
    "'''\n",
    "#Else we could assign all initial values to be equal to 1; performs bad for lower indeces\n",
    "init_val = 1\n",
    "new_kon = new_kon + Tensor([init_val])\n",
    "\n",
    "\n",
    "\n",
    "update_kon_dict = {}\n",
    "for edge in rn.network.edges:\n",
    "    update_kon_dict[edge] = new_kon[uid_dict[edge]]\n",
    "\n",
    "nx.set_edge_attributes(rn.network,update_kon_dict,'k_on')\n",
    "for edge in rn.network.edges:\n",
    "    print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "\n",
    "vec_rn = VectorizedRxnNet(rn, dev='cpu')\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species present in the Reaction Network: \n",
      "Index  --  Species\n",
      "  0    --  A     \n",
      "  1    --  C     \n",
      "  2    --  B     \n",
      "  3    --  D     \n",
      "  4    --  E     \n",
      "  5    --  F     \n",
      "  6    --  H     \n",
      "  7    --  AB    \n",
      "  8    --  AH    \n",
      "  9    --  BC    \n",
      " 10    --  CD    \n",
      " 11    --  ABC   \n",
      " 12    --  ABH   \n",
      " 13    --  BCD   \n",
      " 14    --  DE    \n",
      " 15    --  ABCD  \n",
      " 16    --  EF    \n",
      " 17    --  CDE   \n",
      " 18    --  BCDE  \n",
      " 19    --  ABCDE \n",
      " 20    --  FH    \n",
      " 21    --  AFH   \n",
      " 22    --  ABFH  \n",
      " 23    --  DEF   \n",
      " 24    --  CDEF  \n",
      " 25    --  BCDEF \n",
      " 26    --  ABCDEF\n",
      " 27    --  ABCH  \n",
      " 28    --  ABCDH \n",
      " 29    --  EFH   \n",
      " 30    --  ABCDEH\n",
      " 31    --  DEFH  \n",
      " 32    --  CDEFH \n",
      " 33    --  BCDEFH\n",
      " 34    --  ABCDEFH\n",
      " 35    --  AEFH  \n",
      " 36    --  ABCFH \n",
      " 37    --  ABEFH \n",
      " 38    --  ABCDFH\n",
      " 39    --  ADEFH \n",
      " 40    --  ACDEFH\n",
      " 41    --  ABCEFH\n",
      " 42    --  ABDEFH\n",
      "\n",
      "Initial Binding Rates: \n",
      "Reaction        Id           kon\n",
      "\n",
      "('A', 'B')+   B       0 \t    1.00\n",
      "('A', 'HF')+  HF      37 \t    1.00\n",
      "('E', 'HF')+  HF      38 \t    1.00\n",
      "('B', 'AHF')+ AHF      39 \t    1.00\n",
      "('E', 'AHF')+ AHF      40 \t    1.00\n",
      "('C', 'BAHF')+BAHF      41 \t    1.00\n",
      "('E', 'BAHF')+BAHF      42 \t    1.00\n",
      "('C', 'EFD')+ EFD      43 \t    1.00\n",
      "('B', 'CFDE')+CFDE      44 \t    1.00\n",
      "('A', 'BCEFD')+BCEFD      45 \t    1.00\n",
      "('D', 'BACH')+BACH      46 \t    1.00\n",
      "('F', 'BACH')+BACH      47 \t    1.00\n",
      "('E', 'BACHD')+BACHD      48 \t    1.00\n",
      "('F', 'BACHD')+BACHD      49 \t    1.00\n",
      "('A', 'HEF')+ HEF      50 \t    1.00\n",
      "('D', 'HEF')+ HEF      51 \t    1.00\n",
      "('F', 'BACHED')+BACHED      52 \t    1.00\n",
      "('A', 'HEFD')+HEFD      53 \t    1.00\n",
      "('B', 'ACHEFD')+ACHEFD      67 \t    1.00\n",
      "('B', 'AHEFD')+AHEFD      66 \t    1.00\n",
      "('C', 'AHEFD')+AHEFD      65 \t    1.00\n",
      "('E', 'BACHFD')+BACHFD      64 \t    1.00\n",
      "('D', 'BAHEF')+BAHEF      63 \t    1.00\n",
      "('C', 'BAHEF')+BAHEF      62 \t    1.00\n",
      "('A', 'BCDE')+BCDE      36 \t    1.00\n",
      "('E', 'BACHF')+BACHF      61 \t    1.00\n",
      "('D', 'HAEF')+HAEF      59 \t    1.00\n",
      "('B', 'HAEF')+HAEF      58 \t    1.00\n",
      "('A', 'BCHEFD')+BCHEFD      57 \t    1.00\n",
      "('B', 'CHEFD')+CHEFD      56 \t    1.00\n",
      "('A', 'CHEFD')+CHEFD      55 \t    1.00\n",
      "('C', 'HEFD')+HEFD      54 \t    1.00\n",
      "('D', 'BACHF')+BACHF      60 \t    1.00\n",
      "('B', 'CDE')+ CDE      35 \t    1.00\n",
      "('D', 'EF')+  EF      34 \t    1.00\n",
      "('C', 'ED')+  ED      33 \t    1.00\n",
      "('F', 'H')+   H      14 \t    1.00\n",
      "('E', 'BACD')+BACD      13 \t    1.00\n",
      "('E', 'BCD')+ BCD      12 \t    1.00\n",
      "('E', 'CD')+  CD      11 \t    1.00\n",
      "('E', 'F')+   F      10 \t    1.00\n",
      "('D', 'BAC')+ BAC       9 \t    1.00\n",
      "('F', 'AH')+  AH      15 \t    1.00\n",
      "('D', 'BC')+  BC       8 \t    1.00\n",
      "('B', 'CD')+  CD       6 \t    1.00\n",
      "('B', 'HA')+  HA       5 \t    1.00\n",
      "('C', 'BA')+  BA       4 \t    1.00\n",
      "('C', 'D')+   D       3 \t    1.00\n",
      "('C', 'B')+   B       2 \t    1.00\n",
      "('A', 'H')+   H       1 \t    1.00\n",
      "('D', 'E')+   E       7 \t    1.00\n",
      "('D', 'BACHEF')+BACHEF      68 \t    1.00\n",
      "('F', 'ABH')+ ABH      16 \t    1.00\n",
      "('F', 'CDE')+ CDE      18 \t    1.00\n",
      "('A', 'BCD')+ BCD      32 \t    1.00\n",
      "('C', 'BAH')+ BAH      31 \t    1.00\n",
      "('A', 'BC')+  BC      30 \t    1.00\n",
      "('H', 'BACEFD')+BACEFD      29 \t    1.00\n",
      "('H', 'BCEFD')+BCEFD      28 \t    1.00\n",
      "('H', 'CFDE')+CFDE      27 \t    1.00\n",
      "('F', 'ED')+  ED      17 \t    1.00\n",
      "('H', 'EFD')+ EFD      26 \t    1.00\n",
      "('H', 'EF')+  EF      24 \t    1.00\n",
      "('H', 'BACD')+BACD      23 \t    1.00\n",
      "('H', 'BAC')+ BAC      22 \t    1.00\n",
      "('H', 'BA')+  BA      21 \t    1.00\n",
      "('F', 'BACED')+BACED      20 \t    1.00\n",
      "('F', 'BCDE')+BCDE      19 \t    1.00\n",
      "('H', 'BACED')+BACED      25 \t    1.00\n",
      "('C', 'BAHEFD')+BAHEFD      69 \t    1.00\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "\n",
    "print(\"Species present in the Reaction Network: \")\n",
    "print(\"%3s  %2s  %2s\" %(\"Index\",\"--\",'Species'))\n",
    "\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    print(\"%3d  %4s  %-6s\" %(n,\"--\",gtostr(rn.network.nodes[n]['struct'])))\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (\"\".join(list(r1)),\"\".join(list(r2)))\n",
    "        uid_val = {'reactants':reactants,'kon':v['k_on'],'score':v['rxn_score'],'koff':v['k_off'],'uid':uid}\n",
    "        if uid not in uid_dict.keys():\n",
    "            uid_dict[uid] = uid_val\n",
    "\n",
    "print()\n",
    "print(\"Initial Binding Rates: \")\n",
    "\n",
    "ind_sort = np.argsort(vec_rn.kon.detach().numpy())\n",
    "print(\"%-16s%-3s %12s\" %(\"Reaction\",\"Id\",\"kon\"))\n",
    "print()\n",
    "   \n",
    "for i in ind_sort:\n",
    "    print(\"%-4s%1s%4s %7d \\t%8.2f\" %(uid_dict[i]['reactants'],\"+\",uid_dict[i]['reactants'][1],uid_dict[i]['uid'],vec_rn.kon[i].item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using the optimizer ##\n",
    "\n",
    "### Define an instance of the optimizer class\n",
    "#### Input Arguments:\n",
    "\n",
    "reaction_network : Input the vectorized rxn network\n",
    "\n",
    "sim_runtime: The runtime of the kinetic simulation. Needs to be same as the time over the experimental reaction data.\n",
    "\n",
    "optim_iterations: No. of iterations to run the optimization. Can start at low values(100) and increase depending upon memory usage.\n",
    "\n",
    "learning_rate = The size of the gradient descent step for updating parameter values. Needs to be atleast (1e-3-1e-1)* min{parameter value}. If learning rate is too high, it can take a longer step and sometimes lead to negative value of parameters which is unphysical. Requires some trial runs to find the best value. \n",
    "\n",
    "device: cpu or gpu\n",
    "\n",
    "method: Choose which pytorch based optimized to use for gradient descent - Adam or RMSprop\n",
    "\n",
    "mom: Only for RMSprop method. Use momentum term during gradient descent. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.utils.benchmark as benchmark\n",
    "import time as time_mod\n",
    "\n",
    "t1 = time_mod.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vec_rn.reset(reset_params=True)\n",
    "optim = Optimizer(reaction_network=vec_rn,\n",
    "                  sim_runtime=1,\n",
    "                  optim_iterations=100,\n",
    "                  learning_rate=1e-2,\n",
    "                  device='cpu',method=\"RMSprop\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the optimization method\n",
    "\n",
    "#### Input arguments\n",
    "\n",
    "conc_scale: Controls the conc step at each iteration. Since the numerical integration is not performed over fixed time steps but over fixed conc. steps. For e.g. for a value of 1uM, at each iteration step a total of app. 1uM is reacted (includes all species). Can be run using the default value. A general rule is use conc_scale = 0.01 * Max_yield\n",
    "\n",
    "conc_thresh: This can be used to periodically decrease the conc_scale parameter. After each iteration if the conc_scale is greater than the conc_thresh, then the conc_scale is decreased by mod_factor. Can be run using the default value. \n",
    "\n",
    "mod_bool: This argument is necessary to fix the mass balance criteria. Sometimes if the conc_scale is large, then the simulation can lead to a higher consumption of a particular species which is very low in conc, and create more of this species out of nothing. Default value:True\n",
    "\n",
    "max_thresh: Max. allowed values of parameters being updated. Beyond this maximum a penalty is imposed on the cost function. (Regularization)\n",
    "\n",
    "max_yield: It is a control variable that is used to store the updated parameter values over all iterations for further analysis. The parameter values are stored only if the current yield exceed this max_yield. \n",
    "\n",
    "yield_species: Yield of the species being optimized(node index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reaction Parameters before optimization: \n",
      "[Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64, requires_grad=True)]\n",
      "Optimizer State: <bound method Optimizer.state_dict of RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")>\n",
      "Using CPU\n",
      "Yield on sim. iteration 0 was 1.08%.\n",
      "current params: tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor(0.0109, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8969, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 1 was 1.08%.\n",
      "current params: tensor([1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000], dtype=torch.float64)\n",
      "tensor(0.0109, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8866, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 2 was 1.03%.\n",
      "current params: tensor([1.1969, 1.1668, 1.1695, 1.1706, 1.1708, 1.1674], dtype=torch.float64)\n",
      "tensor(0.0103, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8789, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 3 was 1.00%.\n",
      "current params: tensor([1.2659, 1.2238, 1.2275, 1.2288, 1.2290, 1.2193], dtype=torch.float64)\n",
      "tensor(0.0101, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8727, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 4 was 1.10%.\n",
      "current params: tensor([1.2669, 1.2802, 1.2809, 1.2802, 1.2796, 1.2633], dtype=torch.float64)\n",
      "tensor(0.0110, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8683, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 5 was 1.05%.\n",
      "current params: tensor([1.3383, 1.3200, 1.3241, 1.3249, 1.3247, 1.3054], dtype=torch.float64)\n",
      "tensor(0.0105, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8633, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 6 was 1.05%.\n",
      "current params: tensor([1.3774, 1.3613, 1.3658, 1.3665, 1.3661, 1.3419], dtype=torch.float64)\n",
      "tensor(0.0105, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8591, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 7 was 1.05%.\n",
      "current params: tensor([1.4141, 1.3997, 1.4046, 1.4051, 1.4046, 1.3755], dtype=torch.float64)\n",
      "tensor(0.0105, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8551, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 8 was 1.15%.\n",
      "current params: tensor([1.3906, 1.4432, 1.4441, 1.4422, 1.4409, 1.4069], dtype=torch.float64)\n",
      "tensor(0.0116, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8524, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 9 was 1.16%.\n",
      "current params: tensor([1.4198, 1.4761, 1.4779, 1.4762, 1.4749, 1.4389], dtype=torch.float64)\n",
      "tensor(0.0117, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8490, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 10 was 1.17%.\n",
      "current params: tensor([1.4478, 1.5076, 1.5101, 1.5086, 1.5072, 1.4692], dtype=torch.float64)\n",
      "tensor(0.0117, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8458, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 11 was 1.22%.\n",
      "current params: tensor([1.4464, 1.5412, 1.5424, 1.5400, 1.5383, 1.4978], dtype=torch.float64)\n",
      "tensor(0.0123, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8432, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 12 was 1.34%.\n",
      "current params: tensor([1.4165, 1.5758, 1.5745, 1.5704, 1.5681, 1.5262], dtype=torch.float64)\n",
      "tensor(0.0134, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8412, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 13 was 1.23%.\n",
      "current params: tensor([1.4965, 1.5908, 1.5972, 1.5971, 1.5962, 1.5553], dtype=torch.float64)\n",
      "tensor(0.0124, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8376, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 14 was 1.23%.\n",
      "current params: tensor([1.5213, 1.6160, 1.6241, 1.6246, 1.6238, 1.5810], dtype=torch.float64)\n",
      "tensor(0.0124, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 15 was 1.24%.\n",
      "current params: tensor([1.5428, 1.6412, 1.6504, 1.6512, 1.6505, 1.6056], dtype=torch.float64)\n",
      "tensor(0.0124, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8323, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 16 was 1.27%.\n",
      "current params: tensor([1.5506, 1.6681, 1.6770, 1.6775, 1.6765, 1.6294], dtype=torch.float64)\n",
      "tensor(0.0127, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8300, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 17 was 1.27%.\n",
      "current params: tensor([1.5755, 1.6911, 1.7015, 1.7025, 1.7017, 1.6529], dtype=torch.float64)\n",
      "tensor(0.0127, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8274, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 18 was 1.26%.\n",
      "current params: tensor([1.6012, 1.7134, 1.7254, 1.7269, 1.7263, 1.6754], dtype=torch.float64)\n",
      "tensor(0.0127, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 19 was 1.27%.\n",
      "current params: tensor([1.6188, 1.7367, 1.7493, 1.7510, 1.7503, 1.6972], dtype=torch.float64)\n",
      "tensor(0.0127, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8226, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 20 was 1.24%.\n",
      "current params: tensor([1.6550, 1.7559, 1.7712, 1.7740, 1.7736, 1.7183], dtype=torch.float64)\n",
      "tensor(0.0125, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8201, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 21 was 1.24%.\n",
      "current params: tensor([1.6781, 1.7773, 1.7937, 1.7969, 1.7965, 1.7385], dtype=torch.float64)\n",
      "tensor(0.0124, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8177, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 22 was 1.27%.\n",
      "current params: tensor([1.6823, 1.8019, 1.8173, 1.8197, 1.8191, 1.7582], dtype=torch.float64)\n",
      "tensor(0.0127, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8157, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 23 was 1.27%.\n",
      "current params: tensor([1.7007, 1.8231, 1.8393, 1.8418, 1.8411, 1.7777], dtype=torch.float64)\n",
      "tensor(0.0127, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8135, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 24 was 1.26%.\n",
      "current params: tensor([1.7238, 1.8431, 1.8604, 1.8633, 1.8627, 1.7968], dtype=torch.float64)\n",
      "tensor(0.0127, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8113, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 25 was 1.26%.\n",
      "current params: tensor([1.7434, 1.8634, 1.8815, 1.8846, 1.8840, 1.8154], dtype=torch.float64)\n",
      "tensor(0.0127, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8092, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 26 was 1.27%.\n",
      "current params: tensor([1.7584, 1.8843, 1.9026, 1.9055, 1.9049, 1.8336], dtype=torch.float64)\n",
      "tensor(0.0127, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8072, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 27 was 1.26%.\n",
      "current params: tensor([1.7810, 1.9034, 1.9227, 1.9260, 1.9254, 1.8515], dtype=torch.float64)\n",
      "tensor(0.0127, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 28 was 1.26%.\n",
      "current params: tensor([1.7977, 1.9233, 1.9430, 1.9463, 1.9456, 1.8689], dtype=torch.float64)\n",
      "tensor(0.0127, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 29 was 1.26%.\n",
      "current params: tensor([1.8153, 1.9427, 1.9630, 1.9663, 1.9655, 1.8860], dtype=torch.float64)\n",
      "tensor(0.0127, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.8010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 30 was 1.26%.\n",
      "current params: tensor([1.8326, 1.9620, 1.9826, 1.9860, 1.9852, 1.9028], dtype=torch.float64)\n",
      "tensor(0.0127, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7991, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 31 was 1.27%.\n",
      "current params: tensor([1.8435, 1.9821, 2.0025, 2.0055, 2.0046, 1.9194], dtype=torch.float64)\n",
      "tensor(0.0128, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7972, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 32 was 1.28%.\n",
      "current params: tensor([1.8568, 2.0015, 2.0219, 2.0248, 2.0237, 1.9357], dtype=torch.float64)\n",
      "tensor(0.0129, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7954, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 33 was 1.27%.\n",
      "current params: tensor([1.8781, 2.0191, 2.0405, 2.0436, 2.0425, 1.9519], dtype=torch.float64)\n",
      "tensor(0.0128, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7934, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 34 was 1.28%.\n",
      "current params: tensor([1.8918, 2.0379, 2.0594, 2.0623, 2.0612, 1.9678], dtype=torch.float64)\n",
      "tensor(0.0128, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7916, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 35 was 1.29%.\n",
      "current params: tensor([1.9022, 2.0571, 2.0783, 2.0809, 2.0796, 1.9834], dtype=torch.float64)\n",
      "tensor(0.0129, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7898, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 36 was 1.29%.\n",
      "current params: tensor([1.9167, 2.0753, 2.0966, 2.0992, 2.0978, 1.9990], dtype=torch.float64)\n",
      "tensor(0.0129, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7880, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 37 was 1.28%.\n",
      "current params: tensor([1.9406, 2.0915, 2.1141, 2.1170, 2.1157, 2.0143], dtype=torch.float64)\n",
      "tensor(0.0128, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7861, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 38 was 1.26%.\n",
      "current params: tensor([1.9677, 2.1070, 2.1311, 2.1346, 2.1334, 2.0292], dtype=torch.float64)\n",
      "tensor(0.0126, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7841, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 39 was 1.25%.\n",
      "current params: tensor([1.9893, 2.1234, 2.1483, 2.1521, 2.1510, 2.0438], dtype=torch.float64)\n",
      "tensor(0.0126, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7823, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 40 was 1.26%.\n",
      "current params: tensor([1.9997, 2.1416, 2.1663, 2.1698, 2.1685, 2.0581], dtype=torch.float64)\n",
      "tensor(0.0126, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7806, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 41 was 1.25%.\n",
      "current params: tensor([2.0224, 2.1574, 2.1831, 2.1869, 2.1857, 2.0723], dtype=torch.float64)\n",
      "tensor(0.0125, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7787, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 42 was 1.24%.\n",
      "current params: tensor([2.0463, 2.1728, 2.1997, 2.2039, 2.2027, 2.0863], dtype=torch.float64)\n",
      "tensor(0.0124, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7769, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 43 was 1.22%.\n",
      "current params: tensor([2.0728, 2.1874, 2.2158, 2.2206, 2.2196, 2.0999], dtype=torch.float64)\n",
      "tensor(0.0123, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7750, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 44 was 1.21%.\n",
      "current params: tensor([2.0960, 2.2025, 2.2321, 2.2373, 2.2363, 2.1132], dtype=torch.float64)\n",
      "tensor(0.0122, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7732, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 45 was 1.19%.\n",
      "current params: tensor([2.1249, 2.2163, 2.2478, 2.2537, 2.2529, 2.1263], dtype=torch.float64)\n",
      "tensor(0.0120, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7713, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 46 was 1.20%.\n",
      "current params: tensor([2.1369, 2.2335, 2.2647, 2.2703, 2.2694, 2.1391], dtype=torch.float64)\n",
      "tensor(0.0120, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7697, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 47 was 1.20%.\n",
      "current params: tensor([2.1466, 2.2510, 2.2818, 2.2869, 2.2858, 2.1518], dtype=torch.float64)\n",
      "tensor(0.0121, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7681, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 48 was 1.19%.\n",
      "current params: tensor([2.1695, 2.2656, 2.2975, 2.3030, 2.3019, 2.1645], dtype=torch.float64)\n",
      "tensor(0.0120, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7663, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 49 was 1.19%.\n",
      "current params: tensor([2.1873, 2.2811, 2.3135, 2.3192, 2.3180, 2.1769], dtype=torch.float64)\n",
      "tensor(0.0119, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7646, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 50 was 1.18%.\n",
      "current params: tensor([2.2053, 2.2965, 2.3294, 2.3351, 2.3340, 2.1892], dtype=torch.float64)\n",
      "tensor(0.0119, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7630, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 51 was 1.17%.\n",
      "current params: tensor([2.2257, 2.3112, 2.3450, 2.3509, 2.3498, 2.2013], dtype=torch.float64)\n",
      "tensor(0.0118, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7613, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 52 was 1.18%.\n",
      "current params: tensor([2.2370, 2.3277, 2.3612, 2.3669, 2.3655, 2.2133], dtype=torch.float64)\n",
      "tensor(0.0118, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7597, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 53 was 1.17%.\n",
      "current params: tensor([2.2577, 2.3421, 2.3765, 2.3824, 2.3811, 2.2252], dtype=torch.float64)\n",
      "tensor(0.0118, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7580, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 54 was 1.16%.\n",
      "current params: tensor([2.2797, 2.3561, 2.3916, 2.3978, 2.3966, 2.2369], dtype=torch.float64)\n",
      "tensor(0.0116, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7563, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 55 was 1.15%.\n",
      "current params: tensor([2.3001, 2.3702, 2.4066, 2.4132, 2.4120, 2.2485], dtype=torch.float64)\n",
      "tensor(0.0116, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7547, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 56 was 1.14%.\n",
      "current params: tensor([2.3211, 2.3842, 2.4216, 2.4284, 2.4272, 2.2599], dtype=torch.float64)\n",
      "tensor(0.0115, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7530, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 57 was 1.14%.\n",
      "current params: tensor([2.3370, 2.3992, 2.4369, 2.4437, 2.4424, 2.2712], dtype=torch.float64)\n",
      "tensor(0.0115, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7514, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 58 was 1.15%.\n",
      "current params: tensor([2.3465, 2.4156, 2.4527, 2.4590, 2.4576, 2.2824], dtype=torch.float64)\n",
      "tensor(0.0115, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7500, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 59 was 1.15%.\n",
      "current params: tensor([2.3581, 2.4313, 2.4681, 2.4742, 2.4726, 2.2935], dtype=torch.float64)\n",
      "tensor(0.0115, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7484, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 60 was 1.14%.\n",
      "current params: tensor([2.3775, 2.4452, 2.4828, 2.4891, 2.4875, 2.3046], dtype=torch.float64)\n",
      "tensor(0.0115, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7468, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 61 was 1.13%.\n",
      "current params: tensor([2.3984, 2.4586, 2.4972, 2.5038, 2.5023, 2.3156], dtype=torch.float64)\n",
      "tensor(0.0114, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7452, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 62 was 1.13%.\n",
      "current params: tensor([2.4199, 2.4717, 2.5115, 2.5184, 2.5170, 2.3264], dtype=torch.float64)\n",
      "tensor(0.0113, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7436, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 63 was 1.12%.\n",
      "current params: tensor([2.4386, 2.4854, 2.5259, 2.5331, 2.5316, 2.3371], dtype=torch.float64)\n",
      "tensor(0.0112, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7421, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 64 was 1.11%.\n",
      "current params: tensor([2.4572, 2.4990, 2.5403, 2.5476, 2.5461, 2.3477], dtype=torch.float64)\n",
      "tensor(0.0112, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7405, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 65 was 1.11%.\n",
      "current params: tensor([2.4758, 2.5126, 2.5546, 2.5621, 2.5606, 2.3582], dtype=torch.float64)\n",
      "tensor(0.0111, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7389, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 66 was 1.10%.\n",
      "current params: tensor([2.4943, 2.5261, 2.5688, 2.5765, 2.5750, 2.3685], dtype=torch.float64)\n",
      "tensor(0.0111, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 67 was 1.09%.\n",
      "current params: tensor([2.5143, 2.5390, 2.5827, 2.5908, 2.5893, 2.3788], dtype=torch.float64)\n",
      "tensor(0.0110, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7358, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 68 was 1.09%.\n",
      "current params: tensor([2.5313, 2.5527, 2.5969, 2.6050, 2.6035, 2.3890], dtype=torch.float64)\n",
      "tensor(0.0110, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7343, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 69 was 1.08%.\n",
      "current params: tensor([2.5500, 2.5658, 2.6109, 2.6192, 2.6177, 2.3990], dtype=torch.float64)\n",
      "tensor(0.0109, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7328, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 70 was 1.08%.\n",
      "current params: tensor([2.5685, 2.5790, 2.6247, 2.6333, 2.6318, 2.4090], dtype=torch.float64)\n",
      "tensor(0.0108, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7313, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 71 was 1.07%.\n",
      "current params: tensor([2.5867, 2.5920, 2.6386, 2.6473, 2.6458, 2.4189], dtype=torch.float64)\n",
      "tensor(0.0108, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7298, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 72 was 1.07%.\n",
      "current params: tensor([2.6054, 2.6049, 2.6523, 2.6613, 2.6598, 2.4287], dtype=torch.float64)\n",
      "tensor(0.0107, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7283, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 73 was 1.06%.\n",
      "current params: tensor([2.6236, 2.6178, 2.6660, 2.6752, 2.6737, 2.4384], dtype=torch.float64)\n",
      "tensor(0.0107, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7268, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 74 was 1.06%.\n",
      "current params: tensor([2.6423, 2.6306, 2.6796, 2.6890, 2.6875, 2.4481], dtype=torch.float64)\n",
      "tensor(0.0106, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7253, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 75 was 1.05%.\n",
      "current params: tensor([2.6623, 2.6428, 2.6929, 2.7027, 2.7013, 2.4576], dtype=torch.float64)\n",
      "tensor(0.0106, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7238, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 76 was 1.05%.\n",
      "current params: tensor([2.6807, 2.6554, 2.7064, 2.7164, 2.7150, 2.4671], dtype=torch.float64)\n",
      "tensor(0.0105, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7223, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 77 was 1.04%.\n",
      "current params: tensor([2.6983, 2.6682, 2.7198, 2.7300, 2.7287, 2.4765], dtype=torch.float64)\n",
      "tensor(0.0105, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7208, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 78 was 1.04%.\n",
      "current params: tensor([2.7143, 2.6813, 2.7334, 2.7437, 2.7423, 2.4858], dtype=torch.float64)\n",
      "tensor(0.0104, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7194, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 79 was 1.03%.\n",
      "current params: tensor([2.7326, 2.6937, 2.7467, 2.7572, 2.7558, 2.4950], dtype=torch.float64)\n",
      "tensor(0.0104, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7179, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 80 was 1.03%.\n",
      "current params: tensor([2.7473, 2.7071, 2.7603, 2.7708, 2.7693, 2.5042], dtype=torch.float64)\n",
      "tensor(0.0104, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7165, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 81 was 1.02%.\n",
      "current params: tensor([2.7659, 2.7192, 2.7734, 2.7841, 2.7827, 2.5134], dtype=torch.float64)\n",
      "tensor(0.0103, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7150, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 82 was 1.02%.\n",
      "current params: tensor([2.7842, 2.7314, 2.7865, 2.7975, 2.7961, 2.5224], dtype=torch.float64)\n",
      "tensor(0.0103, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7136, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 83 was 1.02%.\n",
      "current params: tensor([2.8024, 2.7435, 2.7995, 2.8108, 2.8094, 2.5314], dtype=torch.float64)\n",
      "tensor(0.0102, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7121, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 84 was 1.01%.\n",
      "current params: tensor([2.8243, 2.7544, 2.8120, 2.8239, 2.8226, 2.5404], dtype=torch.float64)\n",
      "tensor(0.0101, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 85 was 1.00%.\n",
      "current params: tensor([2.8419, 2.7665, 2.8250, 2.8371, 2.8359, 2.5492], dtype=torch.float64)\n",
      "tensor(0.0101, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7092, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 86 was 1.00%.\n",
      "current params: tensor([2.8544, 2.7801, 2.8385, 2.8504, 2.8491, 2.5580], dtype=torch.float64)\n",
      "tensor(0.0101, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7079, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 87 was 1.00%.\n",
      "current params: tensor([2.8696, 2.7929, 2.8516, 2.8636, 2.8622, 2.5668], dtype=torch.float64)\n",
      "tensor(0.0100, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7065, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 88 was 1.00%.\n",
      "current params: tensor([2.8865, 2.8050, 2.8645, 2.8767, 2.8753, 2.5755], dtype=torch.float64)\n",
      "tensor(0.0100, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 89 was 1.00%.\n",
      "current params: tensor([2.9003, 2.8181, 2.8777, 2.8898, 2.8883, 2.5842], dtype=torch.float64)\n",
      "tensor(0.0100, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7037, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 90 was 0.99%.\n",
      "current params: tensor([2.9157, 2.8306, 2.8906, 2.9028, 2.9013, 2.5928], dtype=torch.float64)\n",
      "tensor(0.0100, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 91 was 0.99%.\n",
      "current params: tensor([2.9334, 2.8422, 2.9033, 2.9157, 2.9143, 2.6014], dtype=torch.float64)\n",
      "tensor(0.0099, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.7009, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 92 was 0.98%.\n",
      "current params: tensor([2.9511, 2.8539, 2.9158, 2.9286, 2.9272, 2.6099], dtype=torch.float64)\n",
      "tensor(0.0099, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.6996, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 93 was 0.98%.\n",
      "current params: tensor([2.9658, 2.8664, 2.9287, 2.9415, 2.9400, 2.6184], dtype=torch.float64)\n",
      "tensor(0.0099, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.6982, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 94 was 0.98%.\n",
      "current params: tensor([2.9831, 2.8780, 2.9413, 2.9543, 2.9529, 2.6269], dtype=torch.float64)\n",
      "tensor(0.0098, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.6968, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 95 was 0.97%.\n",
      "current params: tensor([3.0019, 2.8891, 2.9535, 2.9670, 2.9656, 2.6353], dtype=torch.float64)\n",
      "tensor(0.0098, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.6954, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 96 was 0.97%.\n",
      "current params: tensor([3.0190, 2.9006, 2.9660, 2.9797, 2.9783, 2.6436], dtype=torch.float64)\n",
      "tensor(0.0097, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.6941, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 97 was 0.97%.\n",
      "current params: tensor([3.0337, 2.9129, 2.9787, 2.9924, 2.9911, 2.6519], dtype=torch.float64)\n",
      "tensor(0.0097, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.6927, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 98 was 0.96%.\n",
      "current params: tensor([3.0542, 2.9232, 2.9906, 3.0049, 3.0037, 2.6602], dtype=torch.float64)\n",
      "tensor(0.0097, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty:  tensor(5.6913, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 99 was 0.96%.\n",
      "optimization complete\n",
      "Final params: tensor([3.0542, 2.9232, 2.9906, 3.0049, 3.0037, 2.6602], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<KineticAssembly_AD.vectorized_rxn_net.VectorizedRxnNet at 0x2341da75c50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim.rn.update_reaction_net(rn)\n",
    "optim.optimize(conc_scale=1e-1,conc_thresh=1e-1,mod_bool=True,mod_factor=10,max_thresh=1e8,max_yield=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for complete analysis: 680.2549\n"
     ]
    }
   ],
   "source": [
    "t2 = time_mod.perf_counter()\n",
    "print(\"Time taken for complete analysis: %.4f\" %(t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track the yield over optim iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.plot_yield()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the parameter values\n",
    "\n",
    "### This can be stored in a file for later analysis or used to find the best parameter value depending upon a condition. For e.g. the values that give a minimum error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields= []\n",
    "final_params=[]\n",
    "\n",
    "final_t50 = []\n",
    "final_t85 = []\n",
    "final_t95 = []\n",
    "final_t99 = []\n",
    "\n",
    "for i in range(len(optim.final_yields)):\n",
    "    yields.append(optim.final_yields[i])\n",
    "    final_params.append(optim.final_solns[i])\n",
    "    \n",
    "    #Storing the different time points it reaches a particular yield threshold\n",
    "    if optim.final_t85[i] == -1:\n",
    "        final_t85.append(1) \n",
    "    else:\n",
    "        final_t85.append(optim.final_t85[i]) \n",
    "    if optim.final_t95[i] == -1:\n",
    "        final_t95.append(1)\n",
    "    else:\n",
    "        final_t95.append(optim.final_t95[i])\n",
    "\n",
    "\n",
    "final_yield_arr = np.array(yields)\n",
    "\n",
    "#final_param_arr = np.array(final_params)\n",
    "param_np_list = [p.detach().cpu().numpy() for p in final_params]\n",
    "final_param_arr = np.stack(param_np_list, axis=0)\n",
    "final_t85 = np.array(final_t85)\n",
    "final_t95 = np.array(final_t95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the ratio of ktri vs kdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (99,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26644\\1909503229.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_per_time\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'o'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Efficiency\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ratio\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jhu\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m         \"\"\"\n\u001b[0;32m   1664\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1665\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1666\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jhu\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jhu\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\jhu\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[1;32m--> 270\u001b[1;33m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (99,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mask_r = final_yield_arr > 0.1\n",
    "\n",
    "#Calculate the ratio\n",
    "ratio = final_param_arr[:,1]/final_param_arr[:,0]\n",
    "\n",
    "#Normalize the time scale (t = t*conc*max_rate)\n",
    "conc=vec_rn.initial_copies[0].item()\n",
    "scale_time = final_t95[mask_r]*conc*np.max(final_param_arr[mask_r],axis=1)\n",
    "#Calculate the y_per_time\n",
    "y_per_time = 0.95/scale_time\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(4,3))\n",
    "ax.plot(ratio,y_per_time,linestyle='',marker='o')\n",
    "ax.set_ylabel(\"Efficiency\",fontsize=20)\n",
    "ax.set_xlabel(\"Ratio\",fontsize=20)\n",
    "ax.tick_params(labelsize=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_indx = np.argmax(y_per_time)\n",
    "max_ratio = ratio[max_indx]\n",
    "max_rates = final_param_arr[max_indx]\n",
    "print(\"Ratio with maximum efficiency: \",max_ratio)\n",
    "\n",
    "reaction_rates = np.zeros(rn._rxn_count)\n",
    "counter=0\n",
    "for cls,uids in vec_rn.rxn_class.items():\n",
    "    for rid in uids:\n",
    "        reaction_rates[rid]=max_rates[counter]\n",
    "    counter+=1\n",
    "\n",
    "print(\"Optimal Rates: \",list(reaction_rates))\n",
    "\n",
    "#THE RATES BELOW ARE THE ONES TO PASTE INTO KINETIC_SIMULATION NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
