{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Framework using auto-diff to optimize binding rates\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules\n",
    "\n",
    "Every Jupyter Notebook requires the path to the KineticAssembly_AD modules (.py files in the root directory) to be mentioned. This can be done by adding the path to the 'PATH' variable of the system environment. \n",
    "\n",
    "Additonal modules are also imported which are required to run any analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make sure jupyter path is correct for loading local moudules\n",
    "import sys\n",
    "path_to_repo=\"C:\\\\Users\\\\denys\\\\AMGEN\\\\\"   \n",
    "#Insert your path here\n",
    "# path_to_repo=\"\"\n",
    "sys.path.append(path_to_repo)\n",
    "\n",
    "import copy\n",
    "from KineticAssembly_AD import ReactionNetwork, VectorizedRxnNet, VecSim, Optimizer, EquilibriumSolver\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import DoubleTensor as Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Reaction Network\n",
    "Before we begin to run the optimization routine, we need to create a Reaction Network that stores all the parameters required to run a simulation and other routines. The Reaction Network can be created by reading an input file. More information on how to create an input file can be found in the User Guide. \n",
    "\n",
    "Here a simple trimer model is used to run a simulation.\n",
    "#### Read the corresponding input file and call the ReactionNetwork class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['default_assoc', 1.0]\n",
      "['rxn_coupling', True]\n",
      "True\n",
      "['monomer_add_only', False]\n",
      "[(0, {'struct': <networkx.classes.graph.Graph object at 0x0000025ED2D16AC8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (1, {'struct': <networkx.classes.graph.Graph object at 0x0000025ED2D16860>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (2, {'struct': <networkx.classes.graph.Graph object at 0x0000025ED2CE7550>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (3, {'struct': <networkx.classes.graph.Graph object at 0x0000025ED2F76940>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})]\n",
      "New node added - Node index: 4 ; Node label: AM \n",
      "New node added - Node index: 5 ; Node label: AB \n",
      "New node added - Node index: 6 ; Node label: AS \n",
      "New node added - Node index: 7 ; Node label: BM \n",
      "New node added - Node index: 8 ; Node label: MS \n",
      "New node added - Node index: 9 ; Node label: ABM \n",
      "New node added - Node index: 10 ; Node label: AMS \n",
      "New node added - Node index: 11 ; Node label: BS \n",
      "New node added - Node index: 12 ; Node label: ABS \n",
      "New node added - Node index: 13 ; Node label: BMS \n",
      "New node added - Node index: 14 ; Node label: ABMS \n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  2 10\n",
      "The common reactant is:  B\n",
      "Edge added between:  2 14\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  3 9\n",
      "The common reactant is:  S\n",
      "Edge added between:  3 14\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  4 11\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  5 8\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  6 7\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  12 1\n",
      "The common reactant is:  M\n",
      "Edge added between:  1 14\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  13 0\n",
      "The common reactant is:  A\n",
      "Edge added between:  0 14\n",
      "Coupling Reaction ID:  {5: [0, 3], 6: [0, 4], 8: [1, 3], 9: [1, 7], 10: [3, 7], 11: [1, 3, 7], 12: [2, 4], 13: [2, 7], 14: [4, 7], 15: [2, 4, 7], 16: [1, 2, 3, 4], 17: [0, 2, 3, 7], 18: [0, 1, 4, 7], 19: [0, 1], 20: [0, 2], 21: [1, 2], 22: [3, 4], 23: [0, 3, 4], 24: [0, 1, 2]}\n",
      "Reaction Network Completed\n"
     ]
    }
   ],
   "source": [
    "base_input = './tetramer_diversification.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking reaction network\n",
    "\n",
    "The ReactionNetwork is a networkx object which creates a graph network with each node as species that can be present in the system according to the binding rules given in the input file. Each node has a unique index number that can be used to access attributes stored for that species. Each edge represents a reaction and is associated with a unique reaction_id, on and off rates and the dG value for that reaction.\n",
    "\n",
    "\n",
    "After creating a Reaction Network we can looping over all network nodes to check if all species are created\n",
    "Creating a dictionary for later reference. This dictionary holds the reactants as keys and values as the reaction index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species present in the Reaction Network: \n",
      "Index  --  Species\n",
      "  0    --  A     \n",
      "  1    --  M     \n",
      "  2    --  B     \n",
      "  3    --  S     \n",
      "  4    --  AM    \n",
      "  5    --  AB    \n",
      "  6    --  AS    \n",
      "  7    --  BM    \n",
      "  8    --  MS    \n",
      "  9    --  ABM   \n",
      " 10    --  AMS   \n",
      " 11    --  BS    \n",
      " 12    --  ABS   \n",
      " 13    --  BMS   \n",
      " 14    --  ABMS  \n",
      "\n",
      "Total Number of Reactions:  25\n",
      "Total Number of Species:  15\n",
      "\n",
      "{(0, 4): 0, (0, 5): 1, (0, 6): 2, (0, 9): 19, (0, 10): 20, (0, 12): 21, (0, 14): 24, (1, 4): 0, (1, 7): 3, (1, 8): 4, (1, 9): 5, (1, 10): 6, (1, 13): 22, (1, 14): 23, (2, 5): 1, (2, 7): 3, (2, 11): 7, (2, 9): 8, (2, 12): 9, (2, 13): 10, (2, 14): 11, (3, 6): 2, (3, 8): 4, (3, 11): 7, (3, 10): 12, (3, 12): 13, (3, 13): 14, (3, 14): 15, (4, 9): 8, (4, 10): 12, (4, 14): 16, (5, 9): 5, (5, 12): 13, (5, 14): 17, (6, 10): 6, (6, 12): 9, (6, 14): 18, (7, 13): 14, (7, 14): 18, (7, 9): 19, (8, 13): 10, (8, 14): 17, (8, 10): 20, (9, 14): 15, (10, 14): 11, (11, 14): 16, (11, 12): 21, (11, 13): 22, (12, 14): 23, (13, 14): 24}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "\n",
    "print(\"Species present in the Reaction Network: \")\n",
    "print(\"%3s  %2s  %2s\" %(\"Index\",\"--\",'Species'))\n",
    "for n in rn.network.nodes():\n",
    "    print(\"%3d  %4s  %-6s\" %(n,\"--\",gtostr(rn.network.nodes[n]['struct'])))\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_dict[(n,k)] = uid\n",
    "\n",
    "print()\n",
    "print(\"Total Number of Reactions: \",rn._rxn_count)\n",
    "print(\"Total Number of Species: \",len(rn.network.nodes()))\n",
    "        \n",
    "# Dictionary that stores source,destination of an edge and maps it to its unique id\n",
    "#Key : (First Reactant, Product)\n",
    "#Value : (Reaction_id)\n",
    "print()\n",
    "print(uid_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the initial parameter values \n",
    "The next step is to define the initial conditions for the simulation. The initial concentrations are specified from the input file. However, the initial value of the association rates can be specified either through the input file \n",
    "\n",
    "From the user_input file, currently the code only allows 1 value to be read (from default_assoc parameter).\n",
    "\n",
    "To set starting rates to different values the next code block takes in a list/array of all rxn rates and updates them in the reaction network object.\n",
    "\n",
    "For a hetero-trimer there are 6 reaction rates.\n",
    "Also defines the Vectorized Rxn Net class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 19}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 20}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 21}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 24}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 6}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 22}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 23}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 7}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 8}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 9}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 10}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 11}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 7}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 12}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 13}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 14}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 15}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 8}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 12}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 16}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 13}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 17}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 6}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 9}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 18}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 14}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 18}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 19}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 10}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 17}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 20}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 15}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 11}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 16}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 21}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 22}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 23}\n",
      "{'k_on': tensor(10., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 24}\n",
      "Reaction rates:  tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
      "        10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.],\n",
      "       dtype=torch.float64, grad_fn=<CopySlices>)\n",
      "dGs:  tensor([-20., -20., -20., -20., -20., -40., -40., -20., -40., -40., -40., -60.,\n",
      "        -40., -40., -40., -60., -80., -80., -80., -40., -40., -40., -40., -60.,\n",
      "        -60.], dtype=torch.float64)\n",
      "Species Concentrations:  tensor([100., 100., 100., 100.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.], dtype=torch.float64)\n",
      "Shifting to device:  cpu\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
      "        10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.],\n",
      "       dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "#Define an empty torch tensor with length equal to number of reactions\n",
    "new_kon = torch.zeros([rn._rxn_count], requires_grad=True).double()\n",
    "\n",
    "#Set the initial value of the association rates\n",
    "#Note that this code sets all association rates at the same value\n",
    "'''\n",
    "#To set individual rates to different values, we need to create an list/array with different values.\n",
    "length = rn._rxn_count\n",
    "min_val = 0.1\n",
    "max_val = 5.0\n",
    "init_val = []\n",
    "\n",
    "#np.random.seed(42)\n",
    "for i in range(length):\n",
    "    # Linearly interpolate the current maximum from min_val up to max_val\n",
    "    current_max = min_val + (i / (length - 1)) * (max_val - min_val)\n",
    "    # Draw a random float uniformly between min_val and current_max\n",
    "    val = np.random.uniform(min_val, current_max)\n",
    "    init_val.append(val)\n",
    "\n",
    "new_kon = new_kon + Tensor(init_val)\n",
    "'''    \n",
    "\n",
    "#Else we could assign all initial values to be equal to 1; performs bad for lower indeces\n",
    "init_val = 10\n",
    "new_kon = new_kon + Tensor([init_val])\n",
    "\n",
    "\n",
    "\n",
    "update_kon_dict = {}\n",
    "for edge in rn.network.edges:\n",
    "    update_kon_dict[edge] = new_kon[uid_dict[edge]]\n",
    "\n",
    "nx.set_edge_attributes(rn.network,update_kon_dict,'k_on')\n",
    "for edge in rn.network.edges:\n",
    "    print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "\n",
    "vec_rn = VectorizedRxnNet(rn, dev='cpu')\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species present in the Reaction Network: \n",
      "Index  --  Species\n",
      "  0    --  A     \n",
      "  1    --  M     \n",
      "  2    --  B     \n",
      "  3    --  S     \n",
      "  4    --  AM    \n",
      "  5    --  AB    \n",
      "  6    --  AS    \n",
      "  7    --  BM    \n",
      "  8    --  MS    \n",
      "  9    --  ABM   \n",
      " 10    --  AMS   \n",
      " 11    --  BS    \n",
      " 12    --  ABS   \n",
      " 13    --  BMS   \n",
      " 14    --  ABMS  \n",
      "\n",
      "Initial Binding Rates: \n",
      "Reaction        Id           kon\n",
      "\n",
      "('A', 'M')+   M       0 \t   10.00\n",
      "('M', 'SB')+  SB      22 \t   10.00\n",
      "('A', 'SB')+  SB      21 \t   10.00\n",
      "('A', 'SM')+  SM      20 \t   10.00\n",
      "('A', 'BM')+  BM      19 \t   10.00\n",
      "('SA', 'BM')+  BM      18 \t   10.00\n",
      "('BA', 'SM')+  SM      17 \t   10.00\n",
      "('MA', 'SB')+  SB      16 \t   10.00\n",
      "('S', 'BAM')+ BAM      15 \t   10.00\n",
      "('S', 'BM')+  BM      14 \t   10.00\n",
      "('S', 'BA')+  BA      13 \t   10.00\n",
      "('M', 'SBA')+ SBA      23 \t   10.00\n",
      "('S', 'AM')+  AM      12 \t   10.00\n",
      "('B', 'SM')+  SM      10 \t   10.00\n",
      "('B', 'SA')+  SA       9 \t   10.00\n",
      "('B', 'AM')+  AM       8 \t   10.00\n",
      "('B', 'S')+   S       7 \t   10.00\n",
      "('M', 'SA')+  SA       6 \t   10.00\n",
      "('M', 'BA')+  BA       5 \t   10.00\n",
      "('M', 'S')+   S       4 \t   10.00\n",
      "('M', 'B')+   B       3 \t   10.00\n",
      "('A', 'S')+   S       2 \t   10.00\n",
      "('A', 'B')+   B       1 \t   10.00\n",
      "('B', 'SAM')+ SAM      11 \t   10.00\n",
      "('A', 'SBM')+ SBM      24 \t   10.00\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "\n",
    "print(\"Species present in the Reaction Network: \")\n",
    "print(\"%3s  %2s  %2s\" %(\"Index\",\"--\",'Species'))\n",
    "\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    print(\"%3d  %4s  %-6s\" %(n,\"--\",gtostr(rn.network.nodes[n]['struct'])))\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (\"\".join(list(r1)),\"\".join(list(r2)))\n",
    "        uid_val = {'reactants':reactants,'kon':v['k_on'],'score':v['rxn_score'],'koff':v['k_off'],'uid':uid}\n",
    "        if uid not in uid_dict.keys():\n",
    "            uid_dict[uid] = uid_val\n",
    "\n",
    "print()\n",
    "print(\"Initial Binding Rates: \")\n",
    "\n",
    "ind_sort = np.argsort(vec_rn.kon.detach().numpy())\n",
    "print(\"%-16s%-3s %12s\" %(\"Reaction\",\"Id\",\"kon\"))\n",
    "print()\n",
    "   \n",
    "for i in ind_sort:\n",
    "    print(\"%-4s%1s%4s %7d \\t%8.2f\" %(uid_dict[i]['reactants'],\"+\",uid_dict[i]['reactants'][1],uid_dict[i]['uid'],vec_rn.kon[i].item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using the optimizer ##\n",
    "\n",
    "### Define an instance of the optimizer class\n",
    "#### Input Arguments:\n",
    "\n",
    "reaction_network : Input the vectorized rxn network\n",
    "\n",
    "sim_runtime: The runtime of the kinetic simulation. Needs to be same as the time over the experimental reaction data.\n",
    "\n",
    "optim_iterations: No. of iterations to run the optimization. Can start at low values(100) and increase depending upon memory usage.\n",
    "\n",
    "learning_rate = The size of the gradient descent step for updating parameter values. Needs to be atleast (1e-3-1e-1)* min{parameter value}. If learning rate is too high, it can take a longer step and sometimes lead to negative value of parameters which is unphysical. Requires some trial runs to find the best value. \n",
    "\n",
    "device: cpu or gpu\n",
    "\n",
    "method: Choose which pytorch based optimized to use for gradient descent - Adam or RMSprop\n",
    "\n",
    "mom: Only for RMSprop method. Use momentum term during gradient descent. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.utils.benchmark as benchmark\n",
    "import time as time_mod\n",
    "\n",
    "t1 = time_mod.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vec_rn.reset(reset_params=True)\n",
    "optim = Optimizer(reaction_network=vec_rn,\n",
    "                  sim_runtime=1,\n",
    "                  optim_iterations=100,\n",
    "                  learning_rate=1e-2,\n",
    "                  device='cpu',method=\"RMSprop\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the optimization method\n",
    "\n",
    "#### Input arguments\n",
    "\n",
    "conc_scale: Controls the conc step at each iteration. Since the numerical integration is not performed over fixed time steps but over fixed conc. steps. For e.g. for a value of 1uM, at each iteration step a total of app. 1uM is reacted (includes all species). Can be run using the default value. A general rule is use conc_scale = 0.01 * Max_yield\n",
    "\n",
    "conc_thresh: This can be used to periodically decrease the conc_scale parameter. After each iteration if the conc_scale is greater than the conc_thresh, then the conc_scale is decreased by mod_factor. Can be run using the default value. \n",
    "\n",
    "mod_bool: This argument is necessary to fix the mass balance criteria. Sometimes if the conc_scale is large, then the simulation can lead to a higher consumption of a particular species which is very low in conc, and create more of this species out of nothing. Default value:True\n",
    "\n",
    "max_thresh: Max. allowed values of parameters being updated. Beyond this maximum a penalty is imposed on the cost function. (Regularization)\n",
    "\n",
    "max_yield: It is a control variable that is used to store the updated parameter values over all iterations for further analysis. The parameter values are stored only if the current yield exceed this max_yield. \n",
    "\n",
    "yield_species: Yield of the species being optimized(node index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reaction Parameters before optimization: \n",
      "[Parameter containing:\n",
      "tensor([10., 10., 10., 10., 10., 10.], dtype=torch.float64, requires_grad=True)]\n",
      "Optimizer State: <bound method Optimizer.state_dict of RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")>\n",
      "Using CPU\n",
      "Yield on sim. iteration 0 was 55.4%.\n",
      "current params: tensor([10., 10., 10., 10., 10., 10.], dtype=torch.float64)\n",
      "tensor(0.5540, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 1 was 55.4%.\n",
      "current params: tensor([10.1000, 10.1000, 10.1000, 10.1000, 10.1000, 10.1000],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5540, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 2 was 55.4%.\n",
      "current params: tensor([10.1705, 10.1705, 10.1705, 10.1705, 10.1705, 10.1705],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5540, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 3 was 55.4%.\n",
      "current params: tensor([10.1859, 10.2281, 10.1859, 10.1340, 10.1558, 10.1340],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5542, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 4 was 55.5%.\n",
      "current params: tensor([10.2014, 10.2779, 10.1813, 10.1201, 10.1193, 10.1094],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5554, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 5 was 55.5%.\n",
      "current params: tensor([10.2168, 10.3224, 10.1767, 10.0857, 10.0947, 10.0958],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5556, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 6 was 55.5%.\n",
      "current params: tensor([10.2323, 10.3630, 10.1721, 10.0726, 10.0705, 10.0620],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5558, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 7 was 55.6%.\n",
      "current params: tensor([10.2477, 10.4006, 10.1676, 10.0399, 10.0468, 10.0491],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5560, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 8 was 55.6%.\n",
      "current params: tensor([10.2632, 10.4358, 10.1631, 10.0274, 10.0236, 10.0169],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5562, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 9 was 55.6%.\n",
      "current params: tensor([10.2786, 10.4690, 10.1586,  9.9962, 10.0007, 10.0046],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5563, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 10 was 55.6%.\n",
      "current params: tensor([10.2939, 10.5005, 10.1541,  9.9843,  9.9783,  9.9737],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5564, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 11 was 55.6%.\n",
      "current params: tensor([10.1952, 10.5990, 10.0582,  9.9247,  9.9208,  9.9205],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5565, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 12 was 55.6%.\n",
      "current params: tensor([10.1032, 10.6900,  9.9669,  9.8520,  9.8467,  9.8459],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5567, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 13 was 55.6%.\n",
      "current params: tensor([10.0381, 10.7541,  9.9019,  9.7953,  9.7894,  9.7886],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5568, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 14 was 55.6%.\n",
      "current params: tensor([ 9.9619, 10.8290,  9.8259,  9.7281,  9.7206,  9.7182],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5570, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 15 was 55.7%.\n",
      "current params: tensor([ 9.8650, 10.9256,  9.7291,  9.6333,  9.6252,  9.6222],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5573, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 16 was 55.7%.\n",
      "current params: tensor([ 9.8383, 10.9520,  9.7022,  9.6048,  9.5973,  9.5948],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5573, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 17 was 55.7%.\n",
      "current params: tensor([ 9.8043, 10.9855,  9.6680,  9.5699,  9.5628,  9.5605],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5574, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 18 was 55.7%.\n",
      "current params: tensor([ 9.7556, 11.0332,  9.6191,  9.5217,  9.5144,  9.5118],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5576, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 19 was 55.7%.\n",
      "current params: tensor([ 9.6682, 11.1198,  9.5317,  9.4355,  9.4280,  9.4248],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5579, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 20 was 55.7%.\n",
      "current params: tensor([ 9.6523, 11.1355,  9.5156,  9.4186,  9.4114,  9.4085],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5580, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 21 was 55.8%.\n",
      "current params: tensor([ 9.6340, 11.1534,  9.4972,  9.3996,  9.3926,  9.3899],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5580, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 22 was 55.7%.\n",
      "current params: tensor([ 9.6069, 11.1686,  9.4677,  9.4623,  9.4453,  9.4245],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5578, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 23 was 55.7%.\n",
      "current params: tensor([ 9.5860, 11.1896,  9.4467,  9.4447,  9.4263,  9.4038],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5579, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 24 was 55.8%.\n",
      "current params: tensor([ 9.5601, 11.2153,  9.4209,  9.4231,  9.4031,  9.3784],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5580, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 25 was 55.8%.\n",
      "current params: tensor([ 9.5254, 11.2496,  9.3862,  9.3940,  9.3719,  9.3443],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5583, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 26 was 55.8%.\n",
      "current params: tensor([ 9.4674, 11.3068,  9.3284,  9.3435,  9.3186,  9.2873],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5585, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 27 was 55.8%.\n",
      "current params: tensor([ 9.3695, 11.2085,  9.2294,  9.4435,  9.4186,  9.3873],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5584, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 28 was 55.8%.\n",
      "current params: tensor([ 9.3679, 11.2243,  9.2269,  9.4312,  9.4183,  9.3776],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5586, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 29 was 55.8%.\n",
      "current params: tensor([ 9.3666, 11.2365,  9.2250,  9.4216,  9.4180,  9.3700],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5586, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 30 was 55.8%.\n",
      "current params: tensor([ 9.3651, 11.2511,  9.2227,  9.4100,  9.4176,  9.3608],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5587, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 31 was 55.8%.\n",
      "current params: tensor([ 9.3635, 11.2665,  9.2202,  9.3971,  9.4180,  9.3510],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5588, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 32 was 55.8%.\n",
      "current params: tensor([ 9.3620, 11.2809,  9.2179,  9.3850,  9.4183,  9.3418],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5588, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 33 was 55.8%.\n",
      "current params: tensor([ 9.3605, 11.2944,  9.2157,  9.3736,  9.4187,  9.3331],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5589, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 34 was 55.8%.\n",
      "current params: tensor([ 9.3592, 11.3071,  9.2136,  9.3628,  9.4190,  9.3249],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5590, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 35 was 55.9%.\n",
      "current params: tensor([ 9.3579, 11.3191,  9.2115,  9.3525,  9.4193,  9.3171],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5590, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 36 was 55.9%.\n",
      "current params: tensor([ 9.3422, 11.3315,  9.2094,  9.3516,  9.4196,  9.3089],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5591, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 37 was 55.9%.\n",
      "current params: tensor([ 9.3407, 11.3447,  9.2072,  9.3402,  9.4199,  9.3002],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5592, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 38 was 55.9%.\n",
      "current params: tensor([ 9.3249, 11.3571,  9.2050,  9.3393,  9.4202,  9.2919],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5593, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 39 was 55.9%.\n",
      "current params: tensor([ 9.3233, 11.3714,  9.2025,  9.3267,  9.4206,  9.2823],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5593, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 40 was 55.9%.\n",
      "current params: tensor([ 9.3219, 11.3846,  9.2002,  9.3151,  9.4210,  9.2734],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5594, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 41 was 55.9%.\n",
      "current params: tensor([ 9.3042, 11.3982,  9.1978,  9.3141,  9.4213,  9.2641],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5595, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 42 was 55.9%.\n",
      "current params: tensor([ 9.3026, 11.4125,  9.1952,  9.3013,  9.4217,  9.2544],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5596, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 43 was 55.9%.\n",
      "current params: tensor([ 9.2853, 11.4257,  9.1928,  9.3003,  9.4221,  9.2452],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5597, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 44 was 55.9%.\n",
      "current params: tensor([ 9.2836, 11.4408,  9.1900,  9.2866,  9.4225,  9.2347],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5597, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 45 was 55.9%.\n",
      "current params: tensor([ 9.2820, 11.4542,  9.1875,  9.2743,  9.4229,  9.2253],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5598, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 46 was 55.9%.\n",
      "current params: tensor([ 9.2635, 11.4681,  9.1848,  9.2732,  9.4233,  9.2155],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5599, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 47 was 55.9%.\n",
      "current params: tensor([ 9.2618, 11.4823,  9.1821,  9.2601,  9.4238,  9.2054],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5600, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 48 was 56.0%.\n",
      "current params: tensor([ 9.2443, 11.4953,  9.1796,  9.2590,  9.4242,  9.1961],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5601, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 49 was 56.0%.\n",
      "current params: tensor([ 9.2427, 11.5098,  9.1767,  9.2453,  9.4246,  9.1856],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5602, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 50 was 56.0%.\n",
      "current params: tensor([ 9.2411, 11.5226,  9.1742,  9.2333,  9.4250,  9.1764],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5602, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 51 was 56.0%.\n",
      "current params: tensor([ 9.2232, 11.5358,  9.1716,  9.2322,  9.4255,  9.1668],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5603, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 52 was 56.0%.\n",
      "current params: tensor([ 9.2215, 11.5503,  9.1554,  9.2183,  9.4259,  9.1648],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5604, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 53 was 56.0%.\n",
      "current params: tensor([ 9.2014, 11.5649,  9.1525,  9.2171,  9.4264,  9.1539],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5605, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 54 was 56.0%.\n",
      "current params: tensor([ 9.1995, 11.5810,  9.1492,  9.2015,  9.4270,  9.1419],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5606, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 55 was 56.0%.\n",
      "current params: tensor([ 9.1975, 11.5970,  9.1310,  9.1859,  9.4275,  9.1397],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5606, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 56 was 56.0%.\n",
      "current params: tensor([ 9.1724, 11.6149,  9.1273,  9.1844,  9.4281,  9.1259],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5608, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 57 was 56.0%.\n",
      "current params: tensor([ 9.1703, 11.6324,  9.1070,  9.1669,  9.4288,  9.1234],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5609, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 58 was 56.0%.\n",
      "current params: tensor([ 9.1434, 11.6516,  9.1030,  9.1653,  9.4295,  9.1082],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5610, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 59 was 56.1%.\n",
      "current params: tensor([ 9.1407, 11.6735,  9.0982,  9.1430,  9.4303,  9.0908],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5611, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 60 was 56.1%.\n",
      "current params: tensor([ 9.1384, 11.6920,  9.0758,  9.1240,  9.4311,  9.0880],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5612, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 61 was 56.1%.\n",
      "current params: tensor([ 9.1066, 11.7142,  9.0709,  9.1220,  9.4320,  9.0697],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5614, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 62 was 56.1%.\n",
      "current params: tensor([ 9.1042, 11.7337,  9.0469,  9.1014,  9.4328,  9.0668],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5615, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 63 was 56.1%.\n",
      "current params: tensor([ 9.0745, 11.7544,  9.0422,  9.0995,  9.4337,  9.0492],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5616, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 64 was 56.1%.\n",
      "current params: tensor([ 9.0716, 11.7774,  9.0368,  9.0747,  9.4347,  9.0293],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5618, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 65 was 56.1%.\n",
      "current params: tensor([ 9.0694, 11.7947,  9.0145,  9.0560,  9.4355,  9.0266],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5619, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 66 was 56.2%.\n",
      "current params: tensor([ 9.0411, 11.8139,  9.0100,  9.0542,  9.4364,  9.0097],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5620, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 67 was 56.2%.\n",
      "current params: tensor([ 9.0391, 11.8297,  8.9892,  9.0367,  9.4372,  9.0071],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5621, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 68 was 56.2%.\n",
      "current params: tensor([ 9.0147, 11.8462,  8.9853,  9.0351,  9.4380,  8.9923],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5622, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 69 was 56.2%.\n",
      "current params: tensor([ 9.0126, 11.8632,  8.9812,  9.0160,  9.4388,  8.9769],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5623, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 70 was 56.2%.\n",
      "current params: tensor([ 9.0109, 11.8765,  8.9633,  9.0011,  9.4395,  8.9747],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5624, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 71 was 56.2%.\n",
      "current params: tensor([ 8.9893, 11.8908,  8.9598,  8.9997,  9.4403,  8.9615],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5625, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 72 was 56.2%.\n",
      "current params: tensor([ 8.9877, 11.9033,  8.9567,  8.9855,  9.4409,  8.9499],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5626, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 73 was 56.2%.\n",
      "current params: tensor([ 8.9695, 11.9154,  8.9402,  8.9843,  9.4416,  8.9479],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5627, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 74 was 56.2%.\n",
      "current params: tensor([ 8.9678, 11.9281,  8.9371,  8.9697,  9.4422,  8.9360],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5628, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 75 was 56.2%.\n",
      "current params: tensor([ 8.9671, 11.9380,  8.9239,  8.9573,  9.4442,  8.9334],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5629, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 76 was 56.3%.\n",
      "current params: tensor([ 8.9499, 11.9484,  8.9200,  8.9567,  9.4462,  8.9240],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5631, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 77 was 56.3%.\n",
      "current params: tensor([ 8.9542, 11.9546,  8.9255,  8.9406,  9.4594,  8.9087],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5632, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 78 was 56.3%.\n",
      "current params: tensor([ 8.9503, 11.9593,  8.9283,  8.9273,  9.4841,  8.8924],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5631, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 79 was 56.3%.\n",
      "current params: tensor([ 8.9735, 11.9489,  8.9624,  8.8998,  9.5329,  8.8601],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5633, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 80 was 56.3%.\n",
      "current params: tensor([ 9.0217, 11.9224,  9.0216,  8.8547,  9.5996,  8.8095],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5632, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 81 was 56.3%.\n",
      "current params: tensor([ 9.0607, 11.9034,  9.0601,  8.8219,  9.6442,  8.7691],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5632, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 82 was 56.3%.\n",
      "current params: tensor([ 9.0995, 11.8824,  9.0993,  8.7884,  9.6875,  8.7297],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5631, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 83 was 56.3%.\n",
      "current params: tensor([ 9.1378, 11.8597,  9.1384,  8.7547,  9.7295,  8.6913],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5631, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 84 was 56.2%.\n",
      "current params: tensor([ 9.1675, 11.8358,  9.1873,  8.7210,  9.7700,  8.6539],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5630, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 85 was 56.2%.\n",
      "current params: tensor([ 9.1975, 11.8104,  9.2337,  8.6873,  9.8095,  8.6172],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5628, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 86 was 56.2%.\n",
      "current params: tensor([ 9.2264, 11.7825,  9.2796,  8.6528,  9.8494,  8.5827],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5628, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 87 was 56.2%.\n",
      "current params: tensor([ 9.2547, 11.7548,  9.3220,  8.6196,  9.8870,  8.5494],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5627, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 88 was 56.2%.\n",
      "current params: tensor([ 9.2836, 11.7260,  9.3634,  8.5862,  9.9241,  8.5159],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5627, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 89 was 56.2%.\n",
      "current params: tensor([ 9.3131, 11.6962,  9.4040,  8.5524,  9.9608,  8.4822],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5626, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 90 was 56.2%.\n",
      "current params: tensor([ 9.3432, 11.6653,  9.4440,  8.5184,  9.9974,  8.4482],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5626, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 91 was 56.2%.\n",
      "current params: tensor([ 9.3740, 11.6336,  9.4835,  8.4839, 10.0338,  8.4139],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5625, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 92 was 56.2%.\n",
      "current params: tensor([ 9.4054, 11.6010,  9.5226,  8.4492, 10.0702,  8.3793],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5625, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 93 was 56.2%.\n",
      "current params: tensor([ 9.4372, 11.5676,  9.5613,  8.4141, 10.1064,  8.3444],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5624, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 94 was 56.2%.\n",
      "current params: tensor([ 9.4695, 11.5336,  9.5997,  8.3789, 10.1425,  8.3094],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5623, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 95 was 56.2%.\n",
      "current params: tensor([ 9.5021, 11.4990,  9.6377,  8.3434, 10.1786,  8.2741],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5622, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 96 was 56.2%.\n",
      "current params: tensor([ 9.5371, 11.4618,  9.6778,  8.3057, 10.2167,  8.2366],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5623, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 97 was 56.3%.\n",
      "current params: tensor([ 9.4373, 11.5618,  9.5778,  8.2202, 10.2313,  8.1436],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5635, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 98 was 56.3%.\n",
      "current params: tensor([ 9.4372, 11.5620,  9.5776,  8.2201, 10.2313,  8.1434],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.5635, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Using CPU\n",
      "Yield on sim. iteration 99 was 56.3%.\n",
      "optimization complete\n",
      "Final params: tensor([ 9.4372, 11.5620,  9.5776,  8.2201, 10.2313,  8.1434],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<KineticAssembly_AD.vectorized_rxn_net.VectorizedRxnNet at 0x25ecb195978>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim.rn.update_reaction_net(rn)\n",
    "optim.optimize(conc_scale=1e-1,conc_thresh=1e-1,mod_bool=True,mod_factor=10,max_thresh=1e8,max_yield=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for complete analysis: 164.9876\n"
     ]
    }
   ],
   "source": [
    "t2 = time_mod.perf_counter()\n",
    "print(\"Time taken for complete analysis: %.4f\" %(t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track the yield over optim iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.plot_yield()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the parameter values\n",
    "\n",
    "### This can be stored in a file for later analysis or used to find the best parameter value depending upon a condition. For e.g. the values that give a minimum error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields= []\n",
    "final_params=[]\n",
    "\n",
    "final_t50 = []\n",
    "final_t85 = []\n",
    "final_t95 = []\n",
    "final_t99 = []\n",
    "\n",
    "for i in range(len(optim.final_yields)):\n",
    "    yields.append(optim.final_yields[i])\n",
    "    final_params.append(optim.final_solns[i])\n",
    "    \n",
    "    #Storing the different time points it reaches a particular yield threshold\n",
    "    if optim.final_t85[i] == -1:\n",
    "        final_t85.append(1) \n",
    "    else:\n",
    "        final_t85.append(optim.final_t85[i]) \n",
    "    if optim.final_t95[i] == -1:\n",
    "        final_t95.append(1)\n",
    "    else:\n",
    "        final_t95.append(optim.final_t95[i])\n",
    "\n",
    "\n",
    "final_yield_arr = np.array(yields)\n",
    "final_param_arr = list(final_params)\n",
    "final_t85 = np.array(final_t85)\n",
    "final_t95 = np.array(final_t95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the ratio of ktri vs kdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6468\\1829585550.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Calculate the ratio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_param_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfinal_param_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#Normalize the time scale (t = t*conc*max_rate)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mask_r = final_yield_arr > 0.1\n",
    "\n",
    "#Calculate the ratio\n",
    "ratio = final_param_arr[:,-1]/final_param_arr[:,0]\n",
    "\n",
    "#Normalize the time scale (t = t*conc*max_rate)\n",
    "conc=vec_rn.initial_copies[0].item()\n",
    "scale_time = final_t95[mask_r]*conc*np.max(final_param_arr[mask_r],axis=1)\n",
    "#Calculate the y_per_time\n",
    "y_per_time = 0.95/scale_time\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(ratio,y_per_time,linestyle='',marker='o')\n",
    "ax.set_ylabel(\"Efficiency\",fontsize=20)\n",
    "ax.set_xlabel(\"Ratio\",fontsize=20)\n",
    "ax.tick_params(labelsize=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_indx = np.argmax(y_per_time)\n",
    "max_ratio = ratio[max_indx]\n",
    "max_rates = final_param_arr[max_indx]\n",
    "print(\"Ratio with maximum efficiency: \",max_ratio)\n",
    "\n",
    "reaction_rates = np.zeros(rn._rxn_count)\n",
    "counter=0\n",
    "for cls,uids in vec_rn.rxn_class.items():\n",
    "    for rid in uids:\n",
    "        reaction_rates[rid]=max_rates[counter]\n",
    "    counter+=1\n",
    "\n",
    "print(\"Optimal Rates: \",list(reaction_rates))\n",
    "\n",
    "#THE RATES BELOW ARE THE ONES TO PASTE INTO KINETIC_SIMULATION NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
