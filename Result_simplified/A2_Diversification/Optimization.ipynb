{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Framework using auto-diff to optimize binding rates\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules\n",
    "\n",
    "Every Jupyter Notebook requires the path to the KineticAssembly_AD modules (.py files in the root directory) to be mentioned. This can be done by adding the path to the 'PATH' variable of the system environment. \n",
    "\n",
    "Additonal modules are also imported which are required to run any analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make sure jupyter path is correct for loading local moudules\n",
    "import sys\n",
    "path_to_repo=\"C:\\\\Users\\\\denys\\\\AMGEN\\\\\"   \n",
    "#Insert your path here\n",
    "# path_to_repo=\"\"\n",
    "sys.path.append(path_to_repo)\n",
    "\n",
    "import copy\n",
    "from KineticAssembly_AD import ReactionNetwork, VectorizedRxnNet, VecSim, Optimizer, EquilibriumSolver\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import DoubleTensor as Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Reaction Network\n",
    "Before we begin to run the optimization routine, we need to create a Reaction Network that stores all the parameters required to run a simulation and other routines. The Reaction Network can be created by reading an input file. More information on how to create an input file can be found in the User Guide. \n",
    "\n",
    "Here a simple trimer model is used to run a simulation.\n",
    "#### Read the corresponding input file and call the ReactionNetwork class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['default_assoc', 1.0]\n",
      "['rxn_coupling', True]\n",
      "True\n",
      "['monomer_add_only', False]\n",
      "[(0, {'struct': <networkx.classes.graph.Graph object at 0x00000214283EEC88>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (1, {'struct': <networkx.classes.graph.Graph object at 0x00000214290DBA20>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (2, {'struct': <networkx.classes.graph.Graph object at 0x00000214229917B8>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1}), (3, {'struct': <networkx.classes.graph.Graph object at 0x0000021422991518>, 'copies': tensor([100.], dtype=torch.float64), 'subunits': 1})]\n",
      "New node added - Node index: 4 ; Node label: AM \n",
      "New node added - Node index: 5 ; Node label: AB \n",
      "New node added - Node index: 6 ; Node label: AS \n",
      "New node added - Node index: 7 ; Node label: BM \n",
      "New node added - Node index: 8 ; Node label: MS \n",
      "New node added - Node index: 9 ; Node label: ABM \n",
      "New node added - Node index: 10 ; Node label: AMS \n",
      "New node added - Node index: 11 ; Node label: BS \n",
      "New node added - Node index: 12 ; Node label: ABS \n",
      "New node added - Node index: 13 ; Node label: BMS \n",
      "New node added - Node index: 14 ; Node label: ABMS \n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  2 10\n",
      "The common reactant is:  B\n",
      "Edge added between:  2 14\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  3 9\n",
      "The common reactant is:  S\n",
      "Edge added between:  3 14\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  4 11\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  5 8\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  6 7\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  12 1\n",
      "The common reactant is:  M\n",
      "Edge added between:  1 14\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  13 0\n",
      "The common reactant is:  A\n",
      "Edge added between:  0 14\n",
      "Coupling Reaction ID:  {5: [0, 3], 6: [0, 4], 8: [1, 3], 9: [1, 7], 10: [3, 7], 11: [1, 3, 7], 12: [2, 4], 13: [2, 7], 14: [4, 7], 15: [2, 4, 7], 16: [1, 2, 3, 4], 17: [0, 2, 3, 7], 18: [0, 1, 4, 7], 19: [0, 1], 20: [0, 2], 21: [1, 2], 22: [3, 4], 23: [0, 3, 4], 24: [0, 1, 2]}\n",
      "Reaction Network Completed\n"
     ]
    }
   ],
   "source": [
    "base_input = './tetramer_diversification.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking reaction network\n",
    "\n",
    "The ReactionNetwork is a networkx object which creates a graph network with each node as species that can be present in the system according to the binding rules given in the input file. Each node has a unique index number that can be used to access attributes stored for that species. Each edge represents a reaction and is associated with a unique reaction_id, on and off rates and the dG value for that reaction.\n",
    "\n",
    "\n",
    "After creating a Reaction Network we can looping over all network nodes to check if all species are created\n",
    "Creating a dictionary for later reference. This dictionary holds the reactants as keys and values as the reaction index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species present in the Reaction Network: \n",
      "Index  --  Species\n",
      "  0    --  A     \n",
      "  1    --  M     \n",
      "  2    --  B     \n",
      "  3    --  S     \n",
      "  4    --  AM    \n",
      "  5    --  AB    \n",
      "  6    --  AS    \n",
      "  7    --  BM    \n",
      "  8    --  MS    \n",
      "  9    --  ABM   \n",
      " 10    --  AMS   \n",
      " 11    --  BS    \n",
      " 12    --  ABS   \n",
      " 13    --  BMS   \n",
      " 14    --  ABMS  \n",
      "\n",
      "Total Number of Reactions:  25\n",
      "Total Number of Species:  15\n",
      "\n",
      "{(0, 4): 0, (0, 5): 1, (0, 6): 2, (0, 9): 19, (0, 10): 20, (0, 12): 21, (0, 14): 24, (1, 4): 0, (1, 7): 3, (1, 8): 4, (1, 9): 5, (1, 10): 6, (1, 13): 22, (1, 14): 23, (2, 5): 1, (2, 7): 3, (2, 11): 7, (2, 9): 8, (2, 12): 9, (2, 13): 10, (2, 14): 11, (3, 6): 2, (3, 8): 4, (3, 11): 7, (3, 10): 12, (3, 12): 13, (3, 13): 14, (3, 14): 15, (4, 9): 8, (4, 10): 12, (4, 14): 16, (5, 9): 5, (5, 12): 13, (5, 14): 17, (6, 10): 6, (6, 12): 9, (6, 14): 18, (7, 13): 14, (7, 14): 18, (7, 9): 19, (8, 13): 10, (8, 14): 17, (8, 10): 20, (9, 14): 15, (10, 14): 11, (11, 14): 16, (11, 12): 21, (11, 13): 22, (12, 14): 23, (13, 14): 24}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "\n",
    "print(\"Species present in the Reaction Network: \")\n",
    "print(\"%3s  %2s  %2s\" %(\"Index\",\"--\",'Species'))\n",
    "for n in rn.network.nodes():\n",
    "    print(\"%3d  %4s  %-6s\" %(n,\"--\",gtostr(rn.network.nodes[n]['struct'])))\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_dict[(n,k)] = uid\n",
    "\n",
    "print()\n",
    "print(\"Total Number of Reactions: \",rn._rxn_count)\n",
    "print(\"Total Number of Species: \",len(rn.network.nodes()))\n",
    "        \n",
    "# Dictionary that stores source,destination of an edge and maps it to its unique id\n",
    "#Key : (First Reactant, Product)\n",
    "#Value : (Reaction_id)\n",
    "print()\n",
    "print(uid_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the initial parameter values \n",
    "The next step is to define the initial conditions for the simulation. The initial concentrations are specified from the input file. However, the initial value of the association rates can be specified either through the input file \n",
    "\n",
    "From the user_input file, currently the code only allows 1 value to be read (from default_assoc parameter).\n",
    "\n",
    "To set starting rates to different values the next code block takes in a list/array of all rxn rates and updates them in the reaction network object.\n",
    "\n",
    "For a hetero-trimer there are 6 reaction rates.\n",
    "Also defines the Vectorized Rxn Net class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 19}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 20}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 21}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 24}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 6}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 22}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 23}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 7}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 8}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 9}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 10}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 11}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 7}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 12}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 13}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 14}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 15}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 8}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 12}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 16}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 13}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 17}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 6}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 9}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 18}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 14}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 18}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 19}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 10}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 17}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 20}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 15}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 11}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 16}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 21}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 22}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 23}\n",
      "{'k_on': tensor(1., dtype=torch.float64, grad_fn=<SelectBackward>), 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 24}\n",
      "Reaction rates:  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64, grad_fn=<CopySlices>)\n",
      "dGs:  tensor([-20., -20., -20., -20., -20., -40., -40., -20., -40., -40., -40., -60.,\n",
      "        -40., -40., -40., -60., -80., -80., -80., -40., -40., -40., -40., -60.,\n",
      "        -60.], dtype=torch.float64)\n",
      "Species Concentrations:  tensor([100., 100., 100., 100.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.], dtype=torch.float64)\n",
      "Shifting to device:  cpu\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "#Define an empty torch tensor with length equal to number of reactions\n",
    "new_kon = torch.zeros([rn._rxn_count], requires_grad=True).double()\n",
    "\n",
    "#Set the initial value of the association rates\n",
    "#Note that this code sets all association rates at the same value\n",
    "'''\n",
    "#To set individual rates to different values, we need to create an list/array with different values.\n",
    "length = rn._rxn_count\n",
    "min_val = 0.1\n",
    "max_val = 5.0\n",
    "init_val = []\n",
    "\n",
    "#np.random.seed(42)\n",
    "for i in range(length):\n",
    "    # Linearly interpolate the current maximum from min_val up to max_val\n",
    "    current_max = min_val + (i / (length - 1)) * (max_val - min_val)\n",
    "    # Draw a random float uniformly between min_val and current_max\n",
    "    val = np.random.uniform(min_val, current_max)\n",
    "    init_val.append(val)\n",
    "\n",
    "new_kon = new_kon + Tensor(init_val)\n",
    "'''    \n",
    "\n",
    "#Else we could assign all initial values to be equal to 1; performs bad for lower indeces\n",
    "init_val = 1\n",
    "new_kon = new_kon + Tensor([init_val])\n",
    "\n",
    "\n",
    "\n",
    "update_kon_dict = {}\n",
    "for edge in rn.network.edges:\n",
    "    update_kon_dict[edge] = new_kon[uid_dict[edge]]\n",
    "\n",
    "nx.set_edge_attributes(rn.network,update_kon_dict,'k_on')\n",
    "for edge in rn.network.edges:\n",
    "    print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "\n",
    "vec_rn = VectorizedRxnNet(rn, dev='cpu')\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species present in the Reaction Network: \n",
      "Index  --  Species\n",
      "  0    --  A     \n",
      "  1    --  M     \n",
      "  2    --  B     \n",
      "  3    --  S     \n",
      "  4    --  AM    \n",
      "  5    --  AB    \n",
      "  6    --  AS    \n",
      "  7    --  BM    \n",
      "  8    --  MS    \n",
      "  9    --  ABM   \n",
      " 10    --  AMS   \n",
      " 11    --  BS    \n",
      " 12    --  ABS   \n",
      " 13    --  BMS   \n",
      " 14    --  ABMS  \n",
      "\n",
      "Initial Binding Rates: \n",
      "Reaction        Id           kon\n",
      "\n",
      "('A', 'M')+   M       0 \t    1.00\n",
      "('M', 'BS')+  BS      22 \t    1.00\n",
      "('A', 'BS')+  BS      21 \t    1.00\n",
      "('A', 'MS')+  MS      20 \t    1.00\n",
      "('A', 'BM')+  BM      19 \t    1.00\n",
      "('AS', 'BM')+  BM      18 \t    1.00\n",
      "('BA', 'MS')+  MS      17 \t    1.00\n",
      "('MA', 'BS')+  BS      16 \t    1.00\n",
      "('S', 'BMA')+ BMA      15 \t    1.00\n",
      "('S', 'BM')+  BM      14 \t    1.00\n",
      "('S', 'BA')+  BA      13 \t    1.00\n",
      "('M', 'BAS')+ BAS      23 \t    1.00\n",
      "('S', 'MA')+  MA      12 \t    1.00\n",
      "('B', 'MS')+  MS      10 \t    1.00\n",
      "('B', 'AS')+  AS       9 \t    1.00\n",
      "('B', 'MA')+  MA       8 \t    1.00\n",
      "('B', 'S')+   S       7 \t    1.00\n",
      "('M', 'AS')+  AS       6 \t    1.00\n",
      "('M', 'BA')+  BA       5 \t    1.00\n",
      "('M', 'S')+   S       4 \t    1.00\n",
      "('M', 'B')+   B       3 \t    1.00\n",
      "('A', 'S')+   S       2 \t    1.00\n",
      "('A', 'B')+   B       1 \t    1.00\n",
      "('B', 'MAS')+ MAS      11 \t    1.00\n",
      "('A', 'BMS')+ BMS      24 \t    1.00\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "\n",
    "print(\"Species present in the Reaction Network: \")\n",
    "print(\"%3s  %2s  %2s\" %(\"Index\",\"--\",'Species'))\n",
    "\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    print(\"%3d  %4s  %-6s\" %(n,\"--\",gtostr(rn.network.nodes[n]['struct'])))\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (\"\".join(list(r1)),\"\".join(list(r2)))\n",
    "        uid_val = {'reactants':reactants,'kon':v['k_on'],'score':v['rxn_score'],'koff':v['k_off'],'uid':uid}\n",
    "        if uid not in uid_dict.keys():\n",
    "            uid_dict[uid] = uid_val\n",
    "\n",
    "print()\n",
    "print(\"Initial Binding Rates: \")\n",
    "\n",
    "ind_sort = np.argsort(vec_rn.kon.detach().numpy())\n",
    "print(\"%-16s%-3s %12s\" %(\"Reaction\",\"Id\",\"kon\"))\n",
    "print()\n",
    "   \n",
    "for i in ind_sort:\n",
    "    print(\"%-4s%1s%4s %7d \\t%8.2f\" %(uid_dict[i]['reactants'],\"+\",uid_dict[i]['reactants'][1],uid_dict[i]['uid'],vec_rn.kon[i].item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using the optimizer ##\n",
    "\n",
    "### Define an instance of the optimizer class\n",
    "#### Input Arguments:\n",
    "\n",
    "reaction_network : Input the vectorized rxn network\n",
    "\n",
    "sim_runtime: The runtime of the kinetic simulation. Needs to be same as the time over the experimental reaction data.\n",
    "\n",
    "optim_iterations: No. of iterations to run the optimization. Can start at low values(100) and increase depending upon memory usage.\n",
    "\n",
    "learning_rate = The size of the gradient descent step for updating parameter values. Needs to be atleast (1e-3-1e-1)* min{parameter value}. If learning rate is too high, it can take a longer step and sometimes lead to negative value of parameters which is unphysical. Requires some trial runs to find the best value. \n",
    "\n",
    "device: cpu or gpu\n",
    "\n",
    "method: Choose which pytorch based optimized to use for gradient descent - Adam or RMSprop\n",
    "\n",
    "mom: Only for RMSprop method. Use momentum term during gradient descent. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.utils.benchmark as benchmark\n",
    "import time as time_mod\n",
    "\n",
    "t1 = time_mod.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vec_rn.reset(reset_params=True)\n",
    "optim = Optimizer(reaction_network=vec_rn,\n",
    "                  sim_runtime=1,\n",
    "                  optim_iterations=100,\n",
    "                  learning_rate=1e-2,\n",
    "                  device='cpu',method=\"RMSprop\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the optimization method\n",
    "\n",
    "#### Input arguments\n",
    "\n",
    "conc_scale: Controls the conc step at each iteration. Since the numerical integration is not performed over fixed time steps but over fixed conc. steps. For e.g. for a value of 1uM, at each iteration step a total of app. 1uM is reacted (includes all species). Can be run using the default value. A general rule is use conc_scale = 0.01 * Max_yield\n",
    "\n",
    "conc_thresh: This can be used to periodically decrease the conc_scale parameter. After each iteration if the conc_scale is greater than the conc_thresh, then the conc_scale is decreased by mod_factor. Can be run using the default value. \n",
    "\n",
    "mod_bool: This argument is necessary to fix the mass balance criteria. Sometimes if the conc_scale is large, then the simulation can lead to a higher consumption of a particular species which is very low in conc, and create more of this species out of nothing. Default value:True\n",
    "\n",
    "max_thresh: Max. allowed values of parameters being updated. Beyond this maximum a penalty is imposed on the cost function. (Regularization)\n",
    "\n",
    "max_yield: It is a control variable that is used to store the updated parameter values over all iterations for further analysis. The parameter values are stored only if the current yield exceed this max_yield. \n",
    "\n",
    "yield_species: Yield of the species being optimized(node index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reaction Parameters before optimization: \n",
      "[Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64, requires_grad=True)]\n",
      "Optimizer State: <bound method Optimizer.state_dict of RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")>\n",
      "Here 2\n",
      "Using CPU\n",
      "Yield on sim. iteration 0 was 53.0%.\n",
      "current params: tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor(0.5303, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Here 2\n",
      "Using CPU\n",
      "Yield on sim. iteration 1 was 53.2%.\n",
      "current params: tensor([1.1000, 1.1000, 1.1000, 1.1000, 1.1000, 1.1000], dtype=torch.float64)\n",
      "tensor(0.5323, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Here 2\n",
      "Using CPU\n",
      "Yield on sim. iteration 2 was 53.4%.\n",
      "current params: tensor([1.1700, 1.1706, 1.1710, 1.1765, 1.1715, 1.1660], dtype=torch.float64)\n",
      "tensor(0.5344, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Here 2\n",
      "Using CPU\n",
      "Yield on sim. iteration 3 was 53.5%.\n",
      "current params: tensor([1.2133, 1.2178, 1.2268, 1.2508, 1.2381, 1.2269], dtype=torch.float64)\n",
      "tensor(0.5359, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Here 2\n",
      "Using CPU\n",
      "Yield on sim. iteration 4 was 53.7%.\n",
      "current params: tensor([1.2534, 1.2632, 1.2780, 1.3100, 1.2937, 1.2746], dtype=torch.float64)\n",
      "tensor(0.5371, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Here 2\n",
      "Using CPU\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2300\\3017586339.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_reaction_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconc_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconc_thresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmod_bool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmod_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_thresh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_yield\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AMGEN\\KineticAssembly_AD\\optimizer.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, optim, node_str, max_yield, corr_rxns, max_thresh, lowvar, conc_scale, mod_factor, conc_thresh, mod_bool, verbose, change_runtime, yield_species, creat_yield, varBool, chap_mode, change_lr_yield, var_thresh)\u001b[0m\n\u001b[0;32m    272\u001b[0m                                  \u001b[0mmod_bool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmod_bool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m                                  \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m                                  yield_species=yield_species)\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[1;31m#Check change in yield from last gradient step. Break if less than a tolerance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AMGEN\\KineticAssembly_AD\\vec_sim.py\u001b[0m in \u001b[0;36msimulate\u001b[1;34m(self, optim, node_str, verbose, switch, switch_time, switch_rates, corr_rxns, conc_scale, mod_factor, conc_thresh, mod_bool, yield_species, store_interval, change_cscale_tit)\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m                     \u001b[0ml_conc_prod_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_log_copy_prod_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                 \u001b[0ml_conc_prod_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_log_copy_prod_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AMGEN\\KineticAssembly_AD\\vectorized_rxn_net.py\u001b[0m in \u001b[0;36mget_log_copy_prod_vector\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    853\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrxn_count\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m         \"\"\"\n\u001b[1;32m--> 855\u001b[1;33m         \u001b[0mr_filter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;31m#Invert signs of reactants amd products.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m         \u001b[1;31m# r_filter = -1 * M.T.clone()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mr_filter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr_filter\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m            \u001b[1;31m#Also changing molecules not involved in reactions to -1. After this, only reactants in each rxn are positive.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optim.rn.update_reaction_net(rn)\n",
    "optim.optimize(conc_scale=1e-1,conc_thresh=1e-1,mod_bool=True,mod_factor=10,max_thresh=1e8,max_yield=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = time_mod.perf_counter()\n",
    "print(\"Time taken for complete analysis: %.4f\" %(t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track the yield over optim iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optim.plot_yield()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the parameter values\n",
    "\n",
    "### This can be stored in a file for later analysis or used to find the best parameter value depending upon a condition. For e.g. the values that give a minimum error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields= []\n",
    "final_params=[]\n",
    "\n",
    "final_t50 = []\n",
    "final_t85 = []\n",
    "final_t95 = []\n",
    "final_t99 = []\n",
    "\n",
    "for i in range(len(optim.final_yields)):\n",
    "    yields.append(optim.final_yields[i])\n",
    "    final_params.append(optim.final_solns[i])\n",
    "    \n",
    "    #Storing the different time points it reaches a particular yield threshold\n",
    "    if optim.final_t85[i] == -1:\n",
    "        final_t85.append(1) \n",
    "    else:\n",
    "        final_t85.append(optim.final_t85[i]) \n",
    "    if optim.final_t95[i] == -1:\n",
    "        final_t95.append(1)\n",
    "    else:\n",
    "        final_t95.append(optim.final_t95[i])\n",
    "\n",
    "\n",
    "final_yield_arr = np.array(yields)\n",
    "final_param_arr = np.array(final_params)\n",
    "final_t85 = np.array(final_t85)\n",
    "final_t95 = np.array(final_t95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the ratio of ktri vs kdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mask_r = final_yield_arr > 0.1\n",
    "\n",
    "#Calculate the ratio\n",
    "ratio = final_param_arr[:,-1]/final_param_arr[:,0]\n",
    "\n",
    "#Normalize the time scale (t = t*conc*max_rate)\n",
    "conc=vec_rn.initial_copies[0].item()\n",
    "scale_time = final_t95[mask_r]*conc*np.max(final_param_arr[mask_r],axis=1)\n",
    "#Calculate the y_per_time\n",
    "y_per_time = 0.95/scale_time\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(ratio,y_per_time,linestyle='',marker='o')\n",
    "ax.set_ylabel(\"Efficiency\",fontsize=20)\n",
    "ax.set_xlabel(\"Ratio\",fontsize=20)\n",
    "ax.tick_params(labelsize=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_indx = np.argmax(y_per_time)\n",
    "max_ratio = ratio[max_indx]\n",
    "max_rates = final_param_arr[max_indx]\n",
    "print(\"Ratio with maximum efficiency: \",max_ratio)\n",
    "\n",
    "reaction_rates = np.zeros(rn._rxn_count)\n",
    "counter=0\n",
    "for cls,uids in vec_rn.rxn_class.items():\n",
    "    for rid in uids:\n",
    "        reaction_rates[rid]=max_rates[counter]\n",
    "    counter+=1\n",
    "\n",
    "print(\"Optimal Rates: \",list(reaction_rates))\n",
    "\n",
    "#THE RATES BELOW ARE THE ONES TO PASTE INTO KINETIC_SIMULATION NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
