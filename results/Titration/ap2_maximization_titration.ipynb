{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization of Titration rates of sub units to escape kinetic traps #\n",
    "\n",
    "### Modes : ###\n",
    "##### There are two types of optimization routines for this protocol - ##\n",
    "a) Single Rate - Where all the subunits are titrated at a single rate\n",
    "b) Multi Rate - In this case, two subunits are in bulk and the other subunits are titrated at different rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make sure jupyter path is correct for loading local moudules\n",
    "import sys\n",
    "# path to steric_simulator module relative to notebook\n",
    "sys.path.append(\"../../../\")\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from KineticAssembly_AD import ReactionNetwork, VectorizedRxnNet, VecSim, Optimizer, EquilibriumSolver\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import DoubleTensor as Tensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Input files ### \n",
    "\n",
    "As mentioned in the user guide, a titration reaction is mentioned by the reaction: \n",
    "\n",
    "null -> A(a) G=0\n",
    "\n",
    "You also need to specifiy the target monomer concentration by the \"titration_time_int\" keyword in the parameter block. \n",
    "\n",
    "For Single Rate, ensure each species has it's creation reaction and the initial concentration is set to 0.\n",
    "For Multi Rate, only the species which are to be titrated are required to have their respective creation rule. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['default_assoc', 1.0]\n",
      "['titration_time_int', 100]\n",
      "Setting Titration End Point\n",
      "['monomer_add_only', True]\n",
      "Found Creation rxn\n",
      "Found Creation rxn\n",
      "New node added - Node index: 4 ; Node label: AM \n",
      "New node added - Node index: 5 ; Node label: AB \n",
      "New node added - Node index: 6 ; Node label: AS \n",
      "Trying internal bonds\n",
      "New node added - Node index: 7 ; Node label: BM \n",
      "New node added - Node index: 8 ; Node label: MS \n",
      "New node added - Node index: 9 ; Node label: ABM \n",
      "New node added - Node index: 10 ; Node label: AMS \n",
      "Trying internal bonds\n",
      "New node added - Node index: 11 ; Node label: BS \n",
      "New node added - Node index: 12 ; Node label: ABS \n",
      "New node added - Node index: 13 ; Node label: BMS \n",
      "New node added - Node index: 14 ; Node label: ABMS \n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  2 10\n",
      "The common reactant is:  B\n",
      "Edge added between:  2 14\n",
      "Trying internal bonds\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  3 9\n",
      "The common reactant is:  S\n",
      "Edge added between:  3 14\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  12 1\n",
      "The common reactant is:  M\n",
      "Edge added between:  1 14\n",
      "Trying internal bonds\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  13 0\n",
      "The common reactant is:  A\n",
      "Edge added between:  0 14\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "Resolving Creation and Destruction rxns\n",
      "['A', 'M']\n",
      "Creation Reactions: \n",
      "[0, 1]\n",
      "{0: {'uid': 22, 'k_on': 0.1}, 1: {'uid': 23, 'k_on': 0.1}}\n",
      "Destructions Reactions: \n",
      "[]\n",
      "{}\n",
      "Reaction Network Completed\n"
     ]
    }
   ],
   "source": [
    "base_input = '../input_files/tetramer_titration_multi.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking reaction network\n",
    "Looping over all network nodes to check if all species are created\n",
    "Creating a dictionary for later reference. This dictionary holds the reactants as keys and values as the reaction index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -- A\n",
      "1 -- M\n",
      "2 -- B\n",
      "3 -- S\n",
      "4 -- AM\n",
      "5 -- AB\n",
      "6 -- AS\n",
      "7 -- BM\n",
      "8 -- MS\n",
      "9 -- ABM\n",
      "10 -- AMS\n",
      "11 -- BS\n",
      "12 -- ABS\n",
      "13 -- BMS\n",
      "14 -- ABMS\n",
      "{(0, 4): 0, (0, 5): 1, (0, 6): 2, (0, 9): 16, (0, 10): 17, (0, 12): 18, (0, 14): 21, (1, 4): 0, (1, 7): 3, (1, 8): 4, (1, 9): 5, (1, 10): 6, (1, 13): 19, (1, 14): 20, (2, 5): 1, (2, 7): 3, (2, 11): 7, (2, 9): 8, (2, 12): 9, (2, 13): 10, (2, 14): 11, (3, 6): 2, (3, 8): 4, (3, 11): 7, (3, 10): 12, (3, 12): 13, (3, 13): 14, (3, 14): 15, (4, 9): 8, (4, 10): 12, (5, 9): 5, (5, 12): 13, (6, 10): 6, (6, 12): 9, (7, 13): 14, (7, 9): 16, (8, 13): 10, (8, 10): 17, (9, 14): 15, (10, 14): 11, (11, 12): 18, (11, 13): 19, (12, 14): 20, (13, 14): 21}\n",
      "{(0, 1, 4): 0, (0, 2, 5): 1, (0, 3, 6): 2, (1, 2, 7): 3, (1, 3, 8): 4, (1, 5, 9): 5, (2, 4, 9): 8, (0, 7, 9): 16, (3, 4, 10): 12, (1, 6, 10): 6, (8, 0, 10): 17, (2, 3, 11): 7, (3, 5, 12): 13, (0, 11, 12): 18, (2, 6, 12): 9, (8, 2, 13): 10, (3, 7, 13): 14, (1, 11, 13): 19, (9, 3, 14): 15, (1, 12, 14): 20, (0, 13, 14): 21, (10, 2, 14): 11}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "react_dict = {}\n",
    "sys.path.append(\"../../\")\n",
    "nodes_list = []\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    print(n,\"--\",gtostr(rn.network.nodes[n]['struct']))\n",
    "    nodes_list.append(gtostr(rn.network.nodes[n]['struct']))\n",
    "    for r_set in rn.get_reactant_sets(n):\n",
    "        r_tup = tuple(list(r_set)+[n])\n",
    "#         print(r_tup)\n",
    "        data = rn.network.get_edge_data(r_tup[0], n)\n",
    "        reaction_id = data['uid']\n",
    "        react_dict[r_tup]=reaction_id\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (\"\".join(r1),\"\".join(r2))\n",
    "#         print(reactants)\n",
    "        uid_dict[(n,k)] = uid\n",
    "#         react_dict[reactants] = uid\n",
    "\n",
    "print(uid_dict)\n",
    "print(react_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 16}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 17}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 18}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 21}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 6}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 19}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 20}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 7}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 8}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 9}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 10}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 11}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 7}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 12}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 13}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 14}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 15}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 8}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 12}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 13}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 6}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 9}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 14}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 16}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 10}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 17}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 15}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 11}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 18}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 19}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 20}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 21}\n",
      "Creation Data: \n",
      "{0: {'uid': 22, 'k_on': 60}, 1: {'uid': 23, 'k_on': 70}}\n"
     ]
    }
   ],
   "source": [
    "#Do modifications here\n",
    "#Changing Initial Conditions\n",
    "import networkx as nx\n",
    "#Changin k_on\n",
    "new_kon = torch.zeros([rn._rxn_count], requires_grad=True).double()\n",
    "new_kon = new_kon + Tensor([1.]*np.array(1e0))\n",
    "\n",
    "update_kon_dict = {}\n",
    "for edge in rn.network.edges:\n",
    "    update_kon_dict[edge] = new_kon[uid_dict[edge]]\n",
    "\n",
    "\n",
    "\n",
    "nx.set_edge_attributes(rn.network,update_kon_dict,'k_on')\n",
    "\n",
    "new_params = [60,70] \n",
    "# new_params = [47.896,34.259,50.007]\n",
    "# new_params = [30.347,98.222,96.897]\n",
    "for n,data in rn.creation_rxn_data.items():\n",
    "    data['k_on'] = new_params[n]\n",
    "\n",
    "\n",
    "print(\"Creation Data: \")\n",
    "print(rn.creation_rxn_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Vectorized Reaction Network class\n",
    "\n",
    "For this protocol the Vectorized Rxn Network class takes an important argument called the optim_rates. The optim_rates includes the reaction ids of only those rates which are to be optimized. \n",
    "\n",
    "The corresponding values of the rid are printed out in the above cell (uid values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "Reactant Sets:\n",
      "M\n",
      "Reactant Sets:\n",
      "B\n",
      "Reactant Sets:\n",
      "S\n",
      "Reactant Sets:\n",
      "AM\n",
      "Reactant Sets:\n",
      "(0, 1)\n",
      "AB\n",
      "Reactant Sets:\n",
      "(0, 2)\n",
      "AS\n",
      "Reactant Sets:\n",
      "(0, 3)\n",
      "BM\n",
      "Reactant Sets:\n",
      "(1, 2)\n",
      "MS\n",
      "Reactant Sets:\n",
      "(1, 3)\n",
      "ABM\n",
      "Reactant Sets:\n",
      "(1, 5)\n",
      "(2, 4)\n",
      "(0, 7)\n",
      "AMS\n",
      "Reactant Sets:\n",
      "(3, 4)\n",
      "(1, 6)\n",
      "(8, 0)\n",
      "BS\n",
      "Reactant Sets:\n",
      "(2, 3)\n",
      "ABS\n",
      "Reactant Sets:\n",
      "(3, 5)\n",
      "(0, 11)\n",
      "(2, 6)\n",
      "BMS\n",
      "Reactant Sets:\n",
      "(8, 2)\n",
      "(3, 7)\n",
      "(1, 11)\n",
      "ABMS\n",
      "Reactant Sets:\n",
      "(8, 5)\n",
      "(6, 7)\n",
      "(9, 3)\n",
      "(1, 12)\n",
      "(0, 13)\n",
      "(11, 4)\n",
      "(10, 2)\n",
      "Before:  tensor([[-1., -1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0., -1., -1., -1.,  0.,  0., -1.,  1.,  0.,  1.,\n",
      "          1.,  1., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "         -0., -0., -0., -0.,  1.,  1.,  1., -0., -0.,  1., -1., -0.],\n",
      "        [-1.,  0.,  0., -1., -1., -1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1., -1.,  0.,  0.,  1.,  1.,\n",
      "         -0., -0.,  1.,  1.,  1.,  1., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "         -0., -0., -0., -0., -0., -0., -0.,  1.,  1., -0., -0., -1.],\n",
      "        [ 0., -1.,  0., -1.,  0.,  0.,  0., -1., -1., -1., -1., -1.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,\n",
      "          1., -0.,  1., -0., -0., -0.,  1.,  1.,  1.,  1.,  1., -0., -0., -0.,\n",
      "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
      "        [ 0.,  0., -1.,  0., -1.,  0.,  0., -1.,  0.,  0.,  0.,  0., -1., -1.,\n",
      "         -1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,\n",
      "         -0.,  1., -0.,  1., -0., -0.,  1., -0., -0., -0., -0.,  1.,  1.,  1.,\n",
      "          1., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
      "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0., -1.,  0.,\n",
      "          0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
      "         -0., -0., -0., -0., -0., -0., -0.,  1., -0., -0., -0.,  1., -0., -0.,\n",
      "         -0.,  1., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
      "          0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,\n",
      "         -1., -0., -0., -0.,  1., -0., -0., -0., -0., -0., -0., -0.,  1., -0.,\n",
      "         -0., -0.,  1., -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0., -1.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,\n",
      "         -0., -1., -0., -0., -0.,  1., -0., -0.,  1., -0., -0., -0., -0., -0.,\n",
      "         -0., -0., -0.,  1., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         -1.,  0.,  0.,  0., -1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,\n",
      "         -0., -0., -1., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,  1.,\n",
      "         -0., -0., -0.,  1.,  1., -0., -0., -0., -0., -0., -0., -0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0., -1.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0., -0.,\n",
      "         -0., -0., -0., -1., -0., -0., -0., -0., -0.,  1., -0., -0., -0., -0.,\n",
      "         -0., -0.,  1., -0., -0.,  1., -0., -0., -0., -0., -0., -0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0., -1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,\n",
      "         -0., -0., -0., -0., -1., -0., -0., -1., -0., -0., -0., -0., -0., -0.,\n",
      "          1., -0., -0., -0., -1., -0., -0., -0., -0., -0., -0., -0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0., -1.,  1.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0., -0.,\n",
      "         -0., -0., -0., -0., -0., -1., -0., -0., -0., -0.,  1., -1., -0., -0.,\n",
      "         -0., -0., -0., -0., -0., -1., -0., -0., -0., -0., -0., -0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0., -1.,  0.,  0.,  0.,  0., -1., -1.,  0.,  0.,  0.,  0., -0.,\n",
      "         -0., -0., -0., -0., -0., -0., -1., -0., -0., -0., -0., -0., -0., -0.,\n",
      "         -0.,  1., -0., -0., -0., -0.,  1.,  1., -0., -0., -0., -0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0., -1.,  0.,  0.,  0., -0.,\n",
      "         -0., -0., -0., -0., -0., -0., -0., -0., -1., -0., -0., -0., -1., -0.,\n",
      "         -0., -0., -0., -0., -0., -0., -1., -0.,  1., -0., -0., -0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
      "          1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0., -1.,  0.,  0., -0.,\n",
      "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -1., -0., -0., -0., -1.,\n",
      "         -0., -0., -0., -0., -0., -0., -0., -1., -0.,  1., -0., -0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
      "          0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0., -0.,\n",
      "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -1., -0., -0., -0.,\n",
      "         -1., -1., -1., -1., -0., -0., -0., -0., -1., -1., -0., -0.]],\n",
      "       dtype=torch.float64)\n",
      "tensor(60., dtype=torch.float64)\n",
      "tensor(70., dtype=torch.float64)\n",
      "is Leaf:  True\n",
      "is Leaf:  True\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 60., 70.],\n",
      "       dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "optim_rates = [25,26]\n",
    "\n",
    "vec_rn = VectorizedRxnNet(rn, dev='cpu',optim_rates=optim_rates)\n",
    "print(vec_rn.kon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using the optimizer ##\n",
    "\n",
    "### Define an instance of the optimizer class\n",
    "#### Input Arguments:\n",
    "\n",
    "reaction_network : Input the vectorized rxn network\n",
    "\n",
    "sim_runtime: The runtime of the kinetic simulation. Needs to be same as the time over the experimental reaction data.\n",
    "\n",
    "optim_iterations: No. of iterations to run the optimization. Can start at low values(100) and increase depending upon memory usage.\n",
    "\n",
    "learning_rate = The size of the gradient descent step for updating parameter values. Needs to be atleast (1e-3-1e-1)* min{parameter value}. If learning rate is too high, it can take a longer step and sometimes lead to negative value of parameters which is unphysical. Requires some trial runs to find the best value. \n",
    "\n",
    "device: cpu or gpu\n",
    "\n",
    "method: Choose which pytorch based optimized to use for gradient descent - Adam or RMSprop\n",
    "\n",
    "mom: Only for RMSprop method. Use momentum term during gradient descent. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Params:  [Parameter containing:\n",
      "tensor(60., dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor(70., dtype=torch.float64, requires_grad=True)]\n",
      "Reaction Parameters before optimization: \n",
      "[Parameter containing:\n",
      "tensor(60., dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor(70., dtype=torch.float64, requires_grad=True)]\n",
      "Optimizer State: <bound method Optimizer.state_dict of RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.05\n",
      "    momentum: 0.8\n",
      "    weight_decay: 0\n",
      "\n",
      "Parameter Group 1\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.1\n",
      "    momentum: 0.8\n",
      "    weight_decay: 0\n",
      ")>\n",
      "New Runtime:  tensor(2.6667, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.6\n",
      "Ending Titration!\n",
      "Current Time:  tensor(1.7376, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(2.6964, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  10115\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  15.9\n",
      "RAM Usage (GB):  28.270355224609375\n",
      "[100.01044309 100.0029784 ]\n",
      "Final Yield:  tensor(0.9489, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 0 was 94.8%\n",
      "current params: [tensor(60., dtype=torch.float64), tensor(70., dtype=torch.float64)]\n",
      "Var:  tensor(50., grad_fn=<VarBackward0>) Penalty:  tensor(92.3077, grad_fn=<MulBackward0>)\n",
      "Grad: Parameter containing:\n",
      "tensor(60., dtype=torch.float64, requires_grad=True) - tensor(1.5933, dtype=torch.float64) Parameter containing:\n",
      "tensor(70., dtype=torch.float64, requires_grad=True) - tensor(-1.4811, dtype=torch.float64) \n",
      "New Runtime:  tensor(2.6807, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  15.9\n",
      "Ending Titration!\n",
      "Current Time:  tensor(1.7897, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(2.6930, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  10096\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  16.1\n",
      "RAM Usage (GB):  28.73171615600586\n",
      "[100.02656977 100.01751428]\n",
      "Final Yield:  tensor(0.9497, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 1 was 94.9%\n",
      "current params: [tensor(59.5000, dtype=torch.float64), tensor(71.0000, dtype=torch.float64)]\n",
      "Var:  tensor(66.1250, grad_fn=<VarBackward0>) Penalty:  tensor(89.8659, grad_fn=<MulBackward0>)\n",
      "Grad: Parameter containing:\n",
      "tensor(59.5000, dtype=torch.float64, requires_grad=True) - tensor(1.8357, dtype=torch.float64) Parameter containing:\n",
      "tensor(71.0000, dtype=torch.float64, requires_grad=True) - tensor(-1.6865, dtype=torch.float64) \n",
      "New Runtime:  tensor(2.7030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.1\n",
      "Ending Titration!\n",
      "Current Time:  tensor(1.9090, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(2.7334, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  10066\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  16.4\n",
      "RAM Usage (GB):  29.19184112548828\n",
      "[100.01193324 100.00790715]\n",
      "Final Yield:  tensor(0.9517, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 2 was 95.1%\n",
      "current params: [tensor(58.7216, dtype=torch.float64), tensor(72.5530, dtype=torch.float64)]\n",
      "Var:  tensor(95.6546, grad_fn=<VarBackward0>) Penalty:  tensor(85.4268, grad_fn=<MulBackward0>)\n",
      "Grad: Parameter containing:\n",
      "tensor(58.7216, dtype=torch.float64, requires_grad=True) - tensor(2.2138, dtype=torch.float64) Parameter containing:\n",
      "tensor(72.5530, dtype=torch.float64, requires_grad=True) - tensor(-1.9979, dtype=torch.float64) \n",
      "New Runtime:  tensor(2.7313, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.4\n",
      "Ending Titration!\n",
      "Current Time:  tensor(2.1742, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Next time:  tensor(2.7410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  10029\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  16.6\n",
      "RAM Usage (GB):  29.65142822265625\n",
      "[100.02402248 100.00722223]\n",
      "Final Yield:  tensor(0.9535, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 3 was 95.3%\n",
      "current params: [tensor(57.7609, dtype=torch.float64), tensor(74.4630, dtype=torch.float64)]\n",
      "Var:  tensor(139.4811, grad_fn=<VarBackward0>) Penalty:  tensor(78.9023, grad_fn=<MulBackward0>)\n",
      "Grad: Parameter containing:\n",
      "tensor(57.7609, dtype=torch.float64, requires_grad=True) - tensor(2.6813, dtype=torch.float64) Parameter containing:\n",
      "tensor(74.4630, dtype=torch.float64, requires_grad=True) - tensor(-2.3685, dtype=torch.float64) \n",
      "New Runtime:  tensor(2.7645, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.6\n",
      "Ending Titration!\n",
      "Next time:  tensor(2.7655, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  9988\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  16.9\n",
      "RAM Usage (GB):  30.110107421875\n",
      "[100.04341102 100.00825965]\n",
      "Final Yield:  tensor(0.9558, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 4 was 95.5%\n",
      "current params: [tensor(56.6746, dtype=torch.float64), tensor(76.6135, dtype=torch.float64)]\n",
      "Var:  tensor(198.7798, grad_fn=<VarBackward0>) Penalty:  tensor(70.1729, grad_fn=<MulBackward0>)\n",
      "Grad: Parameter containing:\n",
      "tensor(56.6746, dtype=torch.float64, requires_grad=True) - tensor(3.2110, dtype=torch.float64) Parameter containing:\n",
      "tensor(76.6135, dtype=torch.float64, requires_grad=True) - tensor(-2.7698, dtype=torch.float64) \n",
      "New Runtime:  tensor(2.8017, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  16.9\n",
      "Ending Titration!\n",
      "Next time:  tensor(2.8391, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  9945\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  17.1\n",
      "RAM Usage (GB):  30.566978454589844\n",
      "[100.03775234 100.02139278]\n",
      "Final Yield:  tensor(0.9586, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 5 was 95.8%\n",
      "current params: [tensor(55.5018, dtype=torch.float64), tensor(78.9243, dtype=torch.float64)]\n",
      "Var:  tensor(274.3064, grad_fn=<VarBackward0>) Penalty:  tensor(59.1885, grad_fn=<MulBackward0>)\n",
      "Grad: Parameter containing:\n",
      "tensor(55.5018, dtype=torch.float64, requires_grad=True) - tensor(3.7839, dtype=torch.float64) Parameter containing:\n",
      "tensor(78.9243, dtype=torch.float64, requires_grad=True) - tensor(-3.1828, dtype=torch.float64) \n",
      "New Runtime:  tensor(2.8426, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.1\n",
      "Ending Titration!\n",
      "Next time:  tensor(2.8518, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  9898\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  17.3\n",
      "RAM Usage (GB):  31.02214813232422\n",
      "[100.02025046 100.02257897]\n",
      "Final Yield:  tensor(0.9604, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 6 was 96.0%\n",
      "current params: [tensor(54.2716, dtype=torch.float64), tensor(81.3363, dtype=torch.float64)]\n",
      "Var:  tensor(366.2508, grad_fn=<VarBackward0>) Penalty:  tensor(45.9839, grad_fn=<MulBackward0>)\n",
      "Grad: Parameter containing:\n",
      "tensor(54.2716, dtype=torch.float64, requires_grad=True) - tensor(4.3854, dtype=torch.float64) Parameter containing:\n",
      "tensor(81.3363, dtype=torch.float64, requires_grad=True) - tensor(-3.5949, dtype=torch.float64) \n",
      "New Runtime:  tensor(2.8866, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.4\n",
      "Ending Titration!\n",
      "Next time:  tensor(2.9189, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  9852\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  17.6\n",
      "RAM Usage (GB):  31.47528839111328\n",
      "[100.03029504 100.01805553]\n",
      "Final Yield:  tensor(0.9630, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 7 was 96.2%\n",
      "current params: [tensor(53.0062, dtype=torch.float64), tensor(83.8048, dtype=torch.float64)]\n",
      "Var:  tensor(474.2769, grad_fn=<VarBackward0>) Penalty:  tensor(30.6668, grad_fn=<MulBackward0>)\n",
      "Grad: Parameter containing:\n",
      "tensor(53.0062, dtype=torch.float64, requires_grad=True) - tensor(5.0047, dtype=torch.float64) Parameter containing:\n",
      "tensor(83.8048, dtype=torch.float64, requires_grad=True) - tensor(-3.9971, dtype=torch.float64) \n",
      "New Runtime:  tensor(2.9334, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.6\n",
      "Ending Titration!\n",
      "Next time:  tensor(2.9699, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  9805\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  17.8\n",
      "RAM Usage (GB):  31.926055908203125\n",
      "[100.02105686 100.01083113]\n",
      "Final Yield:  tensor(0.9650, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 8 was 96.5%\n",
      "current params: [tensor(51.7228, dtype=torch.float64), tensor(86.2953, dtype=torch.float64)]\n",
      "Var:  tensor(597.6298, grad_fn=<VarBackward0>) Penalty:  tensor(13.3984, grad_fn=<MulBackward0>)\n",
      "Grad: Parameter containing:\n",
      "tensor(51.7228, dtype=torch.float64, requires_grad=True) - tensor(5.6329, dtype=torch.float64) Parameter containing:\n",
      "tensor(86.2953, dtype=torch.float64, requires_grad=True) - tensor(-4.3840, dtype=torch.float64) \n",
      "New Runtime:  tensor(2.9828, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  17.8\n",
      "Ending Titration!\n",
      "Next time:  tensor(3.0023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  9759\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  18.1\n",
      "RAM Usage (GB):  32.37425231933594\n",
      "[100.03192816 100.02172005]\n",
      "Final Yield:  tensor(0.9666, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 9 was 96.6%\n",
      "current params: [tensor(50.4347, dtype=torch.float64), tensor(88.7820, dtype=torch.float64)]\n",
      "Var:  tensor(735.2585, grad_fn=<VarBackward0>) Penalty:  tensor(0., grad_fn=<MulBackward0>)\n",
      "Grad: Parameter containing:\n",
      "tensor(50.4347, dtype=torch.float64, requires_grad=True) - tensor(-0.0044, dtype=torch.float64) Parameter containing:\n",
      "tensor(88.7820, dtype=torch.float64, requires_grad=True) - tensor(-0.0015, dtype=torch.float64) \n",
      "New Runtime:  tensor(3.0241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.1\n",
      "Ending Titration!\n",
      "Next time:  tensor(3.0302, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  9722\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  18.3\n",
      "RAM Usage (GB):  32.82068634033203\n",
      "[100.04072936 100.01216882]\n",
      "Final Yield:  tensor(0.9679, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 10 was 96.7%\n",
      "current params: [tensor(49.4044, dtype=torch.float64), tensor(90.7716, dtype=torch.float64)]\n",
      "Var:  tensor(855.6193, grad_fn=<VarBackward0>) Penalty:  tensor(0., grad_fn=<MulBackward0>)\n",
      "Grad: Parameter containing:\n",
      "tensor(49.4044, dtype=torch.float64, requires_grad=True) - tensor(-0.0043, dtype=torch.float64) Parameter containing:\n",
      "tensor(90.7716, dtype=torch.float64, requires_grad=True) - tensor(-0.0016, dtype=torch.float64) \n",
      "New Runtime:  tensor(3.0584, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.3\n",
      "Ending Titration!\n",
      "Next time:  tensor(3.0643, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  9693\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  18.5\n",
      "RAM Usage (GB):  33.26559066772461\n",
      "[100.02327211 100.02702147]\n",
      "Final Yield:  tensor(0.9688, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 11 was 96.8%\n",
      "current params: [tensor(48.5804, dtype=torch.float64), tensor(92.3634, dtype=torch.float64)]\n",
      "Var:  tensor(958.4731, grad_fn=<VarBackward0>) Penalty:  tensor(0., grad_fn=<MulBackward0>)\n",
      "Grad: Parameter containing:\n",
      "tensor(48.5804, dtype=torch.float64, requires_grad=True) - tensor(-0.0043, dtype=torch.float64) Parameter containing:\n",
      "tensor(92.3634, dtype=torch.float64, requires_grad=True) - tensor(-0.0015, dtype=torch.float64) \n",
      "New Runtime:  tensor(3.0867, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.5\n",
      "Ending Titration!\n",
      "Next time:  tensor(3.1149, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  9670\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  18.8\n",
      "RAM Usage (GB):  33.70933532714844\n",
      "[100.02424097 100.00827619]\n",
      "Final Yield:  tensor(0.9699, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 12 was 96.9%\n",
      "current params: [tensor(47.9214, dtype=torch.float64), tensor(93.6370, dtype=torch.float64)]\n",
      "Var:  tensor(1044.9563, grad_fn=<VarBackward0>) Penalty:  tensor(0., grad_fn=<MulBackward0>)\n",
      "Grad: Parameter containing:\n",
      "tensor(47.9214, dtype=torch.float64, requires_grad=True) - tensor(-0.0042, dtype=torch.float64) Parameter containing:\n",
      "tensor(93.6370, dtype=torch.float64, requires_grad=True) - tensor(-0.0015, dtype=torch.float64) \n",
      "New Runtime:  tensor(3.1100, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  18.8\n",
      "Ending Titration!\n",
      "Next time:  tensor(3.1443, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  9652\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  19.0\n",
      "RAM Usage (GB):  34.15263748168945\n",
      "[100.04138262 100.00167764]\n",
      "Final Yield:  tensor(0.9707, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 13 was 97.0%\n",
      "current params: [tensor(47.3944, dtype=torch.float64), tensor(94.6561, dtype=torch.float64)]\n",
      "Var:  tensor(1116.8309, grad_fn=<VarBackward0>) Penalty:  tensor(0., grad_fn=<MulBackward0>)\n",
      "Grad: Parameter containing:\n",
      "tensor(47.3944, dtype=torch.float64, requires_grad=True) - tensor(-0.0041, dtype=torch.float64) Parameter containing:\n",
      "tensor(94.6561, dtype=torch.float64, requires_grad=True) - tensor(-0.0016, dtype=torch.float64) \n",
      "New Runtime:  tensor(3.1289, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.0\n",
      "Ending Titration!\n",
      "Next time:  tensor(3.1613, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  9637\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  19.2\n",
      "RAM Usage (GB):  34.59564971923828\n",
      "[100.02579686 100.0009924 ]\n",
      "Final Yield:  tensor(0.9711, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 14 was 97.1%\n",
      "current params: [tensor(46.9730, dtype=torch.float64), tensor(95.4715, dtype=torch.float64)]\n",
      "Var:  tensor(1176.0510, grad_fn=<VarBackward0>) Penalty:  tensor(0., grad_fn=<MulBackward0>)\n",
      "Grad: Parameter containing:\n",
      "tensor(46.9730, dtype=torch.float64, requires_grad=True) - tensor(-0.0041, dtype=torch.float64) Parameter containing:\n",
      "tensor(95.4715, dtype=torch.float64, requires_grad=True) - tensor(-0.0016, dtype=torch.float64) \n",
      "New Runtime:  tensor(3.1443, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.3\n",
      "Ending Titration!\n",
      "Next time:  tensor(3.1661, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  9625\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  19.5\n",
      "RAM Usage (GB):  35.03682327270508\n",
      "[100.00976418 100.00962564]\n",
      "Final Yield:  tensor(0.9712, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 15 was 97.1%\n",
      "current params: [tensor(46.6361, dtype=torch.float64), tensor(96.1240, dtype=torch.float64)]\n",
      "Var:  tensor(1224.5280, grad_fn=<VarBackward0>) Penalty:  tensor(0., grad_fn=<MulBackward0>)\n",
      "Grad: Parameter containing:\n",
      "tensor(46.6361, dtype=torch.float64, requires_grad=True) - tensor(-0.0042, dtype=torch.float64) Parameter containing:\n",
      "tensor(96.1240, dtype=torch.float64, requires_grad=True) - tensor(-0.0015, dtype=torch.float64) \n",
      "New Runtime:  tensor(3.1567, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.5\n",
      "Ending Titration!\n",
      "Next time:  tensor(3.1586, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  9616\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  19.7\n",
      "RAM Usage (GB):  35.47947692871094\n",
      "[100.0363847  100.01740502]\n",
      "Final Yield:  tensor(0.9713, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 16 was 97.1%\n",
      "current params: [tensor(46.3667, dtype=torch.float64), tensor(96.6462, dtype=torch.float64)]\n",
      "Var:  tensor(1264.0131, grad_fn=<VarBackward0>) Penalty:  tensor(0., grad_fn=<MulBackward0>)\n",
      "Grad: Parameter containing:\n",
      "tensor(46.3667, dtype=torch.float64, requires_grad=True) - tensor(-0.0042, dtype=torch.float64) Parameter containing:\n",
      "tensor(96.6462, dtype=torch.float64, requires_grad=True) - tensor(-0.0015, dtype=torch.float64) \n",
      "New Runtime:  tensor(3.1668, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  19.7\n",
      "Ending Titration!\n",
      "Next time:  tensor(3.1904, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  9608\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  19.9\n",
      "RAM Usage (GB):  35.919586181640625\n",
      "[100.00077628 100.00382994]\n",
      "Final Yield:  tensor(0.9717, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 17 was 97.1%\n",
      "current params: [tensor(46.1515, dtype=torch.float64), tensor(97.0642, dtype=torch.float64)]\n",
      "Var:  tensor(1296.0504, grad_fn=<VarBackward0>) Penalty:  tensor(0., grad_fn=<MulBackward0>)\n",
      "Grad: Parameter containing:\n",
      "tensor(46.1515, dtype=torch.float64, requires_grad=True) - tensor(-0.0042, dtype=torch.float64) Parameter containing:\n",
      "tensor(97.0642, dtype=torch.float64, requires_grad=True) - tensor(-0.0015, dtype=torch.float64) \n",
      "New Runtime:  tensor(3.1749, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  20.0\n",
      "Ending Titration!\n",
      "Next time:  tensor(3.2118, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Final Conc Scale:  0.1\n",
      "Number of steps:  9603\n",
      "Next time larger than simulation runtime. Ending simulation.\n",
      "Memory Used:  20.2\n",
      "RAM Usage (GB):  36.36063766479492\n",
      "[100.00186846 100.0248721 ]\n",
      "Final Yield:  tensor(0.9721, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "yield on sim iteration 18 was 97.2%\n",
      "current params: [tensor(45.9795, dtype=torch.float64), tensor(97.3987, dtype=torch.float64)]\n",
      "Var:  tensor(1321.9681, grad_fn=<VarBackward0>) Penalty:  tensor(0., grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "meth ='RMSprop'\n",
    "# lr=1e-4\n",
    "lr = [5e-2,1e-1]\n",
    "mom=0.8\n",
    "gam=0.1\n",
    "creat_yield=0.98\n",
    "vec_rn.reset(reset_params=True)\n",
    "optim = Optimizer(reaction_network=vec_rn,\n",
    "                  sim_runtime=1,\n",
    "                  optim_iterations=50,\n",
    "                  learning_rate=lr,\n",
    "                  device='cpu',method=meth,lr_change_step=None,mom=mom,gamma=gam,random_lr=False)\n",
    "optim.rn.update_reaction_net(rn)\n",
    "optim.optimize(conc_scale=1e-1,conc_thresh=1e-1,mod_bool=True,mod_factor=10,max_thresh=100,verbose=True,change_runtime=True,max_yield=0,creat_yield=creat_yield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields= []\n",
    "final_params=[]\n",
    "asymm = []\n",
    "final_t50 = []\n",
    "final_t85 = []\n",
    "final_t95 = []\n",
    "final_t99 = []\n",
    "final_unused = []\n",
    "final_times = []\n",
    "for i in range(len(optim.final_yields)):\n",
    "    yields.append(optim.final_yields[i].item())\n",
    "#     print(optim.final_solns[i].numpy())\n",
    "    params=[]\n",
    "#     params.append(new_params[0])\n",
    "    for j in range(len(optim.final_solns[i])):\n",
    "#         print(optim.final_solns[i][j])\n",
    "        params.append(optim.final_solns[i][j].item())\n",
    "#     params.append(new_params[1])\n",
    "#     params.append(new_params[2])\n",
    "#     params.append(new_params[3])\n",
    "    \n",
    "    final_params.append(params)\n",
    "    final_unused.append(optim.final_unused_mon[i].item())\n",
    "    final_times.append(optim.curr_time[i].item())\n",
    "    \n",
    "    if type(optim.final_t50[i])==int:\n",
    "        final_t50.append(1) \n",
    "    else:\n",
    "        final_t50.append(optim.final_t50[i].item()) \n",
    "    if type(optim.final_t85[i])==int:\n",
    "        final_t85.append(1) \n",
    "    else:\n",
    "        final_t85.append(optim.final_t85[i].item()) \n",
    "    if type(optim.final_t95[i])==int:\n",
    "        final_t95.append(1)\n",
    "    else:\n",
    "        final_t95.append(optim.final_t95[i].item())\n",
    "\n",
    "\n",
    "sort_indx=np.argsort(np.array(yields))\n",
    "sorted_yields=np.array(yields)\n",
    "sorted_final_times=np.array(final_times)\n",
    "sorted_excess = np.array(final_unused)#[sort_indx]\n",
    "sorted_params = np.array(final_params)#[sort_indx]\n",
    "\n",
    "sorted_t50 = np.array(final_t50)#[sort_indx]\n",
    "sorted_t85 = np.array(final_t85)#[sort_indx]\n",
    "sorted_t95 = np.array(final_t95)#[sort_indx]\n",
    "\n",
    "\n",
    "print(\"Max Yield: \",sorted_yields[-1],\"\\nParams: \",list(sorted_params[-1]))\n",
    "print(final_unused[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing all solutions to a file\n",
    "\n",
    "\n",
    "\n",
    "klabels=['k'+str(i) for i in range(len(vec_rn.kon))]\n",
    "header = '#Yield\\t' + 'Ex\\t' +'FinalTime\\t'+ \"\\t\".join(klabels) + \"\\tt50\\tt85\\tt95\\n\"\n",
    "print(type(lr))\n",
    "if type(lr)==type([]):\n",
    "    description1 = '# Method: %8s\\n' %(meth)\n",
    "    lr_str = '#LR: '\n",
    "    for l in lr:\n",
    "        lr_str+=str(l)+' : '\n",
    "    description2 = '#MOM: %.1f\\t GAMMA: %.2f\\t Creat_yield: %.2f\\n' %(mom,gam,creat_yield)\n",
    "    \n",
    "    description = description1 + lr_str.strip()[:-1] + \"\\n\" + description2\n",
    "else:\n",
    "    description = '# Method: %8s\\n#LR: %.1e\\n #MOM: %.1f\\t GAMMA: %.2f\\t Creat_yield: %.2f\\n' %(meth,lr,mom,gam,creat_yield)\n",
    "\n",
    "with open(\"Solutions_Titration_Asymmetric_12kT\",'a') as fl:\n",
    "    fl.write(header)\n",
    "    fl.write(description)\n",
    "    for i in range(len(sorted_yields)):\n",
    "        fl.write(\"%f\" %(sorted_yields[i]))\n",
    "        fl.write(\"\\t%f\" %(sorted_excess[i]))\n",
    "        fl.write(\"\\t%f\" %(sorted_final_times[i]))\n",
    "        for j in range((sorted_params[i].shape[0])):\n",
    "            \n",
    "            fl.write(\"\\t%f\" %(sorted_params[i][j]))\n",
    "        fl.write(\"\\t%f\\t%f\\t%f\\n\" %(sorted_t50[i],sorted_t85[i],sorted_t95[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vec_rn.rxn_class)\n",
    "\n",
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "final_rxn_class = {}\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "    \n",
    "        #Find no. of bonds formed for this uid\n",
    "        for cls,r_id in vec_rn.rxn_class.items():\n",
    "            if uid in r_id:\n",
    "                nb = cls\n",
    "\n",
    "        #Formula to get separate id for each type of rxn\n",
    "        key_id = abs(len(r1) - len(r2)) * nb + len(p)\n",
    "#         print(reactants,key_id)\n",
    "        \n",
    "        if key_id not in final_rxn_class:\n",
    "            final_rxn_class[key_id] = [uid]\n",
    "        else:\n",
    "            if uid not in final_rxn_class[key_id]:\n",
    "                final_rxn_class[key_id].append(uid)\n",
    "                \n",
    "print(final_rxn_class)\n",
    "\n",
    "#Code for labels\n",
    "#Only for full topology\n",
    "\n",
    "lb_rxn_class = {2:'mono-mono',5:'mono-dim',10:'mono-tri',4:'dim-dim'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_var(v1,v2):\n",
    "    sq_sum=0\n",
    "    for i in range(len(v1)):\n",
    "        sq_sum=(v1[i]-v2[i])**2+sq_sum\n",
    "    \n",
    "    sq_sum = ((sq_sum)**0.5)/(len(v1)-1)\n",
    "    return(sq_sum)\n",
    "\n",
    "def calc_asymm(par):\n",
    "    \n",
    "    avg_rates = []\n",
    "    var_rates = []\n",
    "    rat1 = []\n",
    "    rat2 =  []\n",
    "    \n",
    "    lb_1 = []\n",
    "    lb_2 = []\n",
    "    \n",
    "    for rclass,uid in final_rxn_class.items():\n",
    "        a1 = np.mean(par[uid])\n",
    "        avg_rates.append(a1)\n",
    "        lb_1.append(\"Avg rates - {:s}\".format(lb_rxn_class[rclass]))\n",
    "        \n",
    "        var1 = np.var(par[uid])\n",
    "        var_rates.append(var1)\n",
    "        lb_2.append(\"Var rates - {:s}\".format(lb_rxn_class[rclass]))\n",
    "        \n",
    "    final_val = avg_rates+var_rates\n",
    "    final_lb = lb_1+lb_2\n",
    "    return(final_val,final_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields= []\n",
    "final_params=[]\n",
    "asymm = []\n",
    "final_t50 = []\n",
    "final_t85 = []\n",
    "final_t95 = []\n",
    "final_t99 = []\n",
    "for i in range(len(optim.final_yields)):\n",
    "    yields.append(optim.final_yields[i].item())\n",
    "#     print(optim.final_solns[i].numpy())\n",
    "\n",
    "    all_params = np.zeros((len(vec_rn.kon)))\n",
    "    all_params[r_to_change] = new_opt_rates\n",
    "    all_params[optim_rates] = optim.final_solns[i].numpy()\n",
    "    final_params.append(all_params)\n",
    "    \n",
    "    if type(optim.final_t50[i])==int:\n",
    "        final_t50.append(1) \n",
    "    else:\n",
    "        final_t50.append(optim.final_t50[i].item()) \n",
    "    if type(optim.final_t85[i])==int:\n",
    "        final_t85.append(1) \n",
    "    else:\n",
    "        final_t85.append(optim.final_t85[i].item()) \n",
    "    if type(optim.final_t95[i])==int:\n",
    "        final_t95.append(1)\n",
    "    else:\n",
    "        final_t95.append(optim.final_t95[i].item())\n",
    "#     if type(optim.final_t99[i])==int:\n",
    "#         final_t99.append(1)\n",
    "#     else:\n",
    "#         final_t99.append(optim.final_t99[i].item())\n",
    "\n",
    "sort_indx=np.argsort(np.array(yields))\n",
    "sorted_yields=np.array(yields)[sort_indx]\n",
    "sorted_params = np.array(final_params)[sort_indx]\n",
    "\n",
    "sorted_t50 = np.array(final_t50)[sort_indx]\n",
    "sorted_t85 = np.array(final_t85)[sort_indx]\n",
    "sorted_t95 = np.array(final_t95)[sort_indx]\n",
    "\n",
    "p0 = sorted_params[0]\n",
    "var_params = []\n",
    "for i in range(len(sorted_params)):\n",
    "    var_params.append(calc_var(p0,sorted_params[i]))\n",
    "    \n",
    "    final_val,final_lb = calc_asymm(sorted_params[i])\n",
    "    asymm.append(final_val)\n",
    "    \n",
    "arg_indx = np.argsort(np.array(var_params))\n",
    "sorted_var = np.array(var_params)[arg_indx]\n",
    "\n",
    "print(sorted_var[0])\n",
    "print(sorted_var[-1])\n",
    "print(\"Yield: \",sorted_yields[arg_indx[0]],\"\\nParams: \",sorted_params[arg_indx[0]])\n",
    "\n",
    "print(\"Yield: \",sorted_yields[arg_indx[-1]],\"\\nParams: \",sorted_params[arg_indx[-1]])\n",
    "print(\"Max Yield: \",sorted_yields[-1],\"\\nParams: \",sorted_params[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Writing all solutions to a file\n",
    "\n",
    "# klabels=['k'+str(i) for i in range(len(vec_rn.kon))]\n",
    "# header = '#Yield\\t' + \"\\t\".join(klabels) + \"\\tt50\\tt85\\tt95\\n\"\n",
    "\n",
    "\n",
    "# with open(\"Solutions_Titration_20kT_Asymmetric_100uM_2params\",'a') as fl:\n",
    "#     fl.write(header)\n",
    "#     for i in range(len(sorted_yields)):\n",
    "#         fl.write(\"%f\" %(sorted_yields[i]))\n",
    "        \n",
    "#         for j in range((sorted_params[i].shape[0])):\n",
    "            \n",
    "#             fl.write(\"\\t%f\" %(sorted_params[i][j]))\n",
    "#         fl.write(\"\\t%f\\t%f\\t%f\\n\" %(sorted_t50[i],sorted_t85[i],sorted_t95[i]))\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "n_features = len(asymm[0])\n",
    "fig,ax = plt.subplots(int(n_features/2),2,figsize=(16,16))\n",
    "# %matplotlib notebook\n",
    "\n",
    "asymm = np.reshape(np.array(asymm),(len(sorted_yields),len(asymm[0])))\n",
    "sorted_yields.reshape((sorted_yields.shape[0],1))\n",
    "\n",
    "mask = (sorted_yields < 1.0) & (sorted_yields >0.9)\n",
    "\n",
    "row=0\n",
    "col=0\n",
    "counter=0\n",
    "for i in range(n_features):\n",
    "    ax[row,col].plot(sorted_yields[mask],asymm[mask,i],marker='x',linestyle='',label=final_lb[i])\n",
    "    ax[row,col].legend()\n",
    "    ax[row,col].set_xlabel(\"Yield\")\n",
    "    ax[row,col].set_ylabel(\"Rate Values\")\n",
    "    \n",
    "    counter+=1\n",
    "    row = row+(col%2)\n",
    "    col = counter%2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "n_features = len(asymm[0])\n",
    "fig,ax = plt.subplots(int(n_features/2),2,figsize=(16,16))\n",
    "# %matplotlib notebook\n",
    "\n",
    "asymm = np.reshape(np.array(asymm),(len(sorted_yields),len(asymm[0])))\n",
    "sorted_yields.reshape((sorted_yields.shape[0],1))\n",
    "\n",
    "\n",
    "row=0\n",
    "col=0\n",
    "counter=0\n",
    "for i in range(n_features):\n",
    "    ax[row,col].plot(sorted_t85[mask],asymm[mask,i],marker='x',linestyle='',label='t85')\n",
    "    ax[row,col].plot(sorted_t95[mask],asymm[mask,i],marker='x',linestyle='',label='t95')\n",
    "    ax[row,col].plot(sorted_t50[mask],asymm[mask,i],marker='x',linestyle='',label='t50')\n",
    "    ax[row,col].legend()\n",
    "    ax[row,col].set_xlabel(\"Yield\")\n",
    "    ax[row,col].set_ylabel(final_lb[i])\n",
    "    \n",
    "    ax[row,col].set_xscale(\"log\")\n",
    "    \n",
    "    \n",
    "    counter+=1\n",
    "    row = row+(col%2)\n",
    "    col = counter%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see what some clustering reveals\n",
    "#Is there a trend with high yield\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def cluster_params(params,final_y,n_clust):\n",
    "#     feat_mat = np.concatenate((params,final_y),axis=1)\n",
    "    feat_mat = params\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(feat_mat)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters = n_clust, random_state=0).fit(X_scaled)\n",
    "    clus_cen = kmeans.cluster_centers_ #Obtain centroids for all the clusters\n",
    "    transform_mat = kmeans.transform(feat_mat) #This method calculates the distance of each point from each cluster\n",
    "    labels = kmeans.labels_  #Labels which frame belongs to which cluster\n",
    "    \n",
    "    return(labels,clus_cen,transform_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering\n",
    "print(asymm.shape,sorted_yields.shape)\n",
    "n_clust=8\n",
    "\n",
    "var_feat_mat = asymm[mask][:,:]\n",
    "\n",
    "labels,clus_cen,transform_mat = cluster_params(var_feat_mat,sorted_yields.reshape((sorted_yields.shape[0],1)),n_clust)\n",
    "\n",
    "\n",
    "clr_input = ['skyblue','orange','green','red','purple','gold','brown','olive','crimson','peru','lightgreen','turquoise','cyan']\n",
    "\n",
    "print(transform_mat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_rates =sorted_params[mask]\n",
    "sel_t50 = sorted_t50[mask]\n",
    "sel_t85 = sorted_t85[mask]\n",
    "sel_t95 = sorted_t95[mask]\n",
    "\n",
    "asymm_new = asymm[mask]\n",
    "\n",
    "#Create a bianry matrix to know which elements are form a cluster\n",
    "mask_01=(np.array(labels)==0)\n",
    "cluster_mask = mask_01.reshape((len(labels),1))\n",
    "for i in range(1,n_clust):\n",
    "    n_arr = i*np.ones((len(labels),1))-np.array(labels).reshape(((len(labels),1)))\n",
    "    mask_01=(n_arr==0)\n",
    "    print(n_arr.shape)\n",
    "    cluster_mask=np.hstack((cluster_mask,mask_01))\n",
    "\n",
    "# cluster_mask = cluster_mask.astype(float)\n",
    "\n",
    "fig,ax = plt.subplots(int(n_features/2),2,figsize=(16,16))\n",
    "ax_hd = []\n",
    "\n",
    "clust_min_solutions={}\n",
    "for i in range(n_clust):\n",
    "    \n",
    "    clus_1_dist = transform_mat[cluster_mask[:,i],i]\n",
    "    clus_1_par = feat_rates[cluster_mask[:,i],:]\n",
    "    clus_1_t50 = sel_t50[cluster_mask[:,i]]\n",
    "    clus_1_t85 = sel_t85[cluster_mask[:,i]]\n",
    "    clus_1_t95 = sel_t95[cluster_mask[:,i]]\n",
    "    clus_1_asymm = asymm_new[cluster_mask[:,i]]\n",
    "    indx_sort = np.argsort(clus_1_dist)\n",
    "    \n",
    "    print(\"Cluster: \",i)\n",
    "    print(\"Cluster Centroid: \",clus_cen[i])\n",
    "    sorted_dist = clus_1_dist[indx_sort]\n",
    "    sorted_par = clus_1_par[indx_sort]\n",
    "    clus_sorted_t50 = clus_1_t50[indx_sort]\n",
    "    clus_sorted_t85 = clus_1_t85[indx_sort]\n",
    "    clus_sorted_t95 = clus_1_t95[indx_sort]\n",
    "    clus_sorted_asymm = clus_1_asymm[indx_sort]\n",
    "#     print(\"Max distance: \",sorted_dist[-1],\"Params: \",sorted_par[-1])\n",
    "    print(\"Min distance: \",sorted_dist[0],\"Params: \",list(sorted_par[0]))\n",
    "    clust_min_solutions[i]=sorted_par[0]\n",
    "    \n",
    "    \n",
    "    #Plotting\n",
    "    row=0\n",
    "    col=0\n",
    "    counter=0\n",
    "    for j in range(n_features):\n",
    "        \n",
    "#         h1=ax[row,col].scatter(clus_sorted_t85[-1],clus_sorted_asymm[-1,j],s=100,alpha=0.6,marker='o',color=clr_input[i], label='85%')\n",
    "        h1 = ax[row,col].scatter(clus_sorted_t85[0:6],clus_sorted_asymm[0:6,j],s=200,alpha=0.6,marker='o',edgecolor=clr_input[i], facecolor='none', label='85%')\n",
    "        \n",
    "        ax[row,col].set_xlabel(\"Time taken\",fontdict={'fontsize':'xx-large'},labelpad=1.0)\n",
    "        ax[row,col].set_ylabel(final_lb[j],fontdict={'fontsize':'xx-large'},labelpad=2.0)\n",
    "\n",
    "        ax[row,col].set_xscale(\"log\")\n",
    "        ax[row,col].tick_params(labelsize='xx-large')\n",
    "        \n",
    "        if counter==0:\n",
    "            ax_hd.append(h1)\n",
    "        counter+=1\n",
    "        row = row+(col%2)\n",
    "        col = counter%2\n",
    "fig.legend(ax_hd,['C0','C1','C2','C3','C4','C5','C6','C7'],fontsize='x-large')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uid_dict = {}\n",
    "uid_reactants = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_val = {'uid':uid,'reactants':reactants,'kon':v['k_on'],'score':v['rxn_score'],'koff':v['k_off']}\n",
    "        uid_reactants[uid]=reactants\n",
    "        if uid not in uid_dict.keys():\n",
    "            uid_dict[uid] = uid_val\n",
    "    print(gtostr(rn.network.nodes[n]['struct']))\n",
    "    #for r_set in rn.get_reactant_sets(n):\n",
    "    #    print(tuple(r_set))\n",
    "    #print(rn.network[n]['struct'])\n",
    "ind_sort = np.argsort(vec_rn.kon.detach().numpy())\n",
    "for i in ind_sort:\n",
    "    print(vec_rn.kon[i])\n",
    "    print(uid_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl_id,lab in lb_rxn_class.items():\n",
    "    \n",
    "    print(\"------------------------------\")\n",
    "    print(\"------------------------------\")\n",
    "    print(\"------    {:s}    -------\".format(lab))\n",
    "    print(\"------------------------------\")\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"%-12s\\t%-4s\\t%-4s\\t%-4s\\t%-4s\\t%-4s\\t%-4s\\t%-4s\\t%-4s\\t%-4s\\n\" %('Reaction','uid','C0','C1','C2','C3','C4','C5','C6','C7'))\n",
    "    for r_id in final_rxn_class[cl_id]:\n",
    "        r1 = \"\".join(list(uid_reactants[r_id][0]))\n",
    "        r2 = \"\".join(list(uid_reactants[r_id][1]))\n",
    "        print(\"{:^4s} + {:^4s}\".format(r1,r2),end='\\t')\n",
    "        print(r_id,end='\\t')\n",
    "        for clust,rates in clust_min_solutions.items():\n",
    "            print(\"%-5.3f\" %(rates[r_id]),end='\\t')\n",
    "        print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "from torch import DoubleTensor as Tensor\n",
    "\n",
    "def get_max_edge(n):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "        \n",
    "        kon_sum = 0\n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "#             #Calculate k_off also\n",
    "#             std_c = Tensor([1.])\n",
    "#             l_kon = torch.log(temp_kon)\n",
    "#             l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (self._R * self._T)) + l_kon + torch.log(std_c)\n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "\n",
    "pathway = []\n",
    "kon_sumarray = []\n",
    "total_con_rate = {}\n",
    "for n in rn.network.nodes():\n",
    "    \n",
    "    n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "    \n",
    "    paths = [n_str]\n",
    "    kon_sum = 0\n",
    "    temp_node = n\n",
    "    max_edge = True\n",
    "    consumption_rate = 0\n",
    "    if n < len(rn.network.nodes()):#num_monomers:\n",
    "#         print(\"Current node: \")\n",
    "#         print(n_str)\n",
    "        while max_edge:\n",
    "            max_edge = get_max_edge(temp_node)\n",
    "            if max_edge:\n",
    "                total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                temp_node = max_edge[1]\n",
    "                kon_sum += max_edge[0].item()\n",
    "                \n",
    "#                 print(\"Next node: \")\n",
    "#                 print(temp_node)\n",
    "\n",
    "                paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "            else:\n",
    "                break\n",
    "        pathway.append(paths)\n",
    "        kon_sumarray.append(kon_sum)\n",
    "        paths=[]\n",
    "\n",
    "print(pathway)\n",
    "print(kon_sumarray)\n",
    "#print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in sorted(total_con_rate.items(),key=lambda x : x[1]):\n",
    "    print(k,\" : \", v.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's first visualize some of the data.\n",
    "\n",
    "**Without any optimization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nodes_list = ['A','B','S','M','AB','BMS','ABS','AMS','ABMS','AM','AS']\n",
    "#nodes_list = ['A','B','ABMS']\n",
    "optim.plot_observable(0,nodes_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**After 750 optimization iterations**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optim.plot_observable(-1,nodes_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.plot_yield()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It seems like we've found a stable solution that produces greater yield than equilibrium. This should be thermodynamically\n",
    "impossible. Let's try to find an explanation. We'll run simulations using the learned optimal parameters at a few different\n",
    "timescales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "optim_rn = optim.rn\n",
    "for i, runtime in enumerate([1, 8, 64]):\n",
    "    optim_rn.reset()\n",
    "    sim = VecSim(optim_rn, runtime, device='cpu')\n",
    "    y = sim.simulate()\n",
    "    sim.plot_observable(nodes_list,ax=ax[i],)\n",
    "    ax[i].set_title(\"runtime: \" + str(runtime) + \" seconds\")\n",
    "fig.set_size_inches(18, 6)\n",
    "node_map = {}\n",
    "for node in rn.network.nodes():\n",
    "    node_map[gtostr(rn.network.nodes[node]['struct'])] = node\n",
    "\n",
    "print(node_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_map = {}\n",
    "for node in rn.network.nodes():\n",
    "    node_map[gtostr(rn.network.nodes[node]['struct'])] = node\n",
    "\n",
    "print(node_map)\n",
    "def get_max_edge(n):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "\n",
    "        kon_sum = 0\n",
    "        total_flux_outedges = 0\n",
    "        total_flux_inedges = 0\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "            \n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "             \n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "\n",
    "        \n",
    "def get_node_flux(n):\n",
    "    total_flux_outedges = 0\n",
    "    total_flux_inedges = 0\n",
    "    #Go over all the out edges\n",
    "    edges_out = rn.network.out_edges(n)\n",
    "    if len(edges_out)>0:\n",
    "\n",
    "        for edge in edges_out:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Calculate k_off also\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Getting conc. of reactants and products\n",
    "            #Get product\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct']) \n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux = koff*vec_rn.copies_vec[edge[1]] - temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])\n",
    "            #edge_flux = koff*vec_rn.copies_vec[edge[1]] \n",
    "\n",
    "            print(\"Reaction: \", gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react,\" -> \",prod)\n",
    "            print(\"Net flux: \",edge_flux)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Reaction data OUTWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_outedges+=edge_flux\n",
    "    \n",
    "    #Now go over all the in edges\n",
    "    edges_in = rn.network.in_edges(n)\n",
    "    react_list = []\n",
    "    if len(edges_in) > 0:\n",
    "        for edge in edges_in:\n",
    "            if edge[0] in react_list:\n",
    "                continue\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            uid = data['uid']\n",
    "\n",
    "\n",
    "            #Get generation rates; which would be kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Get consumption rates; which is k_off\n",
    "            std_c = Tensor([1.])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Get conc. of reactants and products\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct'])\n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "            react_list.append(node_map[react])\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux_in = temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])- koff*vec_rn.copies_vec[edge[1]]\n",
    "            #edge_flux_in = koff*vec_rn.copies_vec[edge[1]]\n",
    "            \n",
    "\n",
    "\n",
    "            print(\"Reaction: \", prod ,\" -> \",gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react)\n",
    "            print(\"Net flux: \",edge_flux_in)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Raction data INWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_inedges+=edge_flux_in\n",
    "    net_node_flux = total_flux_outedges + total_flux_inedges\n",
    "    \n",
    "    return(net_node_flux)\n",
    "    \n",
    "pathway = []\n",
    "kon_sumarray = []\n",
    "total_con_rate = {}\n",
    "net_flux = {}\n",
    "for n in rn.network.nodes():\n",
    "    \n",
    "    n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "    \n",
    "    paths = [n_str]\n",
    "    kon_sum = 0\n",
    "    temp_node = n\n",
    "    max_edge = True\n",
    "    consumption_rate = 0\n",
    "    if n < len(rn.network.nodes()):#num_monomers:\n",
    "#         print(\"Current node: \")\n",
    "#         print(n_str)\n",
    "        while max_edge:\n",
    "            max_edge = get_max_edge(temp_node)\n",
    "            if max_edge:\n",
    "                total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                \n",
    "                temp_node = max_edge[1]\n",
    "                kon_sum += max_edge[0].item()\n",
    "                \n",
    "                \n",
    "#                 print(\"Next node: \")\n",
    "#                 print(temp_node)\n",
    "\n",
    "                paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "            else:\n",
    "                break\n",
    "        pathway.append(paths)\n",
    "        kon_sumarray.append(kon_sum)\n",
    "        paths=[]\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"|                                                                             |\")\n",
    "    node_flux = get_node_flux(n)\n",
    "    net_flux[gtostr(rn.network.nodes[n]['struct'])] = node_flux\n",
    "    print(\"|                                                                             |\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "print(pathway)\n",
    "print(kon_sumarray)\n",
    "\n",
    "#print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in sorted(net_flux.items(),key=lambda x : x[1]):\n",
    "    print(k,\" : \", v)\n",
    "\n",
    "print(vec_rn.copies_vec)\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(solution)\n",
    "poly_system = EquilibriumSolver(rn)\n",
    "solution = poly_system.solve(init_val=vec_rn.copies_vec.detach().numpy().tolist())\n",
    "#solution = poly_system.solve(verifyBool = False)\n",
    "if solution == None:\n",
    "    print(\"No Equilibrium solution\")\n",
    "else:\n",
    "    print(solution)\n",
    "    print(\"Equilibrium expected yield: \", 100 * solution[-1] / min(vec_rn.initial_copies[:vec_rn.num_monomers]), '%')\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the equilibrium reached by the system still matches the equilibrium solution. We have however found a set of parameters that can increase available complete AP2 at some point before equilibrium to levels significantly higher than at equilibrium. We don't observe any trapping, but have uncovered an interesting effect. \n",
    "\n",
    "Now we'll move on to looking at ARP23. This is 7 subunits, which drastically increases the number of possible reactions. Expect longer runtimes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
