{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ad5f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure jupyter path is correct for loading local moudules\n",
    "import sys\n",
    "# path to steric_simulator module relative to notebook\n",
    "sys.path.append(\"../../../\")\n",
    "import copy\n",
    "from KineticAssembly_AD import ReactionNetwork, VectorizedRxnNet, VecSim, Optimizer, EquilibriumSolver,TrapMetric\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import DoubleTensor as Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e8f5bc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input_files/ap2_creation.pwr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20732\\3900297963.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbase_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'input_files/ap2_creation.pwr'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReactionNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AMGEN\\KineticAssembly_AD\\reaction_network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, bngl_path, one_step, seed)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;31m# resolve graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_copies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_bngl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbngl_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m  \u001b[1;31m# gradient params\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_energy_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input_files/ap2_creation.pwr'"
     ]
    }
   ],
   "source": [
    "base_input = 'input_files/ap2_creation.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a2d05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_dict = {}\n",
    "react_dict = {}\n",
    "sys.path.append(\"../../\")\n",
    "nodes_list = []\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    print(n,\"--\",gtostr(rn.network.nodes[n]['struct']))\n",
    "    nodes_list.append(gtostr(rn.network.nodes[n]['struct']))\n",
    "    for r_set in rn.get_reactant_sets(n):\n",
    "        r_tup = tuple(list(r_set)+[n])\n",
    "#         print(r_tup)\n",
    "        data = rn.network.get_edge_data(r_tup[0], n)\n",
    "        reaction_id = data['uid']\n",
    "        react_dict[r_tup]=reaction_id\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (\"\".join(r1),\"\".join(r2))\n",
    "#         print(reactants)\n",
    "        uid_dict[(n,k)] = uid\n",
    "#         react_dict[reactants] = uid\n",
    "\n",
    "print(uid_dict)\n",
    "print(react_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52cff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_kon = torch.zeros([rn._rxn_count], requires_grad=True).double()\n",
    "#new_kon = [0.2244, 0.2244, 0.2255, 1.6039, 1.6039, 1.6040] # M-1 s-1   \n",
    "#new_kon = [0.0125, 0.1947, 0.0125, 3.6241, 3.4263, 3.4258] #Max yield Simruntime = 10sec\n",
    "new_kon = new_kon + Tensor([1.]*np.array(1e0))\n",
    "# new_kon[7]=1e-6\n",
    "# new_kon = new_kon + Tensor([0.0158, 4.8523, 4.8524, 4.8517, 4.8521, 0.0122, 0.0122, 1.4120, 3.8928,\n",
    "#         3.8763, 3.7180, 1.3986, 3.8942, 3.8792, 3.7292, 1.6763, 1.6764, 0.0111,\n",
    "#         0.0111, 3.4412, 3.4471])\n",
    "# new_kon = new_kon + Tensor([0.1500, 5.7619, 5.7887, 5.7685, 5.7934, 0.0162, 0.0171, 1.1242, 4.8607,\n",
    "#                             4.8561, 6.4445, 1.1185, 4.8608, 4.8562, 6.4342, 0.4273, 0.4490, 0.0177,\n",
    "#                             0.0169, 4.9485, 4.9159]) #5sec opti time\n",
    "\n",
    "# new_kon = new_kon + Tensor([0.0101, 4.9091, 4.9091, 4.9049, 4.9044, 0.0146, 0.0145, 4.4233, 4.8614,\n",
    "#         4.8579, 6.7328, 4.4090, 4.8596, 4.8564, 6.7438, 4.5641, 4.5641, 0.0164,\n",
    "#         0.0163, 4.2838, 4.3043]) #1sec opti time\n",
    "                            \n",
    "# new_kon = new_kon + Tensor([0.01500, 0.016, 0.016, 0.016, 0.016, 1.0, 1.0, 1.0, 1.0,\n",
    "#                             1.0, 10.0, 1.0, 1.0, 1.0, 10.0, 10.0, 10.0, 1.0,\n",
    "#                             1.0, 10.0, 10.0])\n",
    "\n",
    "# new_kon = new_kon + Tensor([4.8587, 4.9136, 4.8577, 4.9425, 4.8712, 0.0129, 0.0248, 4.9163, 0.0146,\n",
    "#         0.0138, 0.0175, 7.2391, 0.0179, 0.0115, 0.0165, 7.8065, 7.1411, 7.1320,\n",
    "#         7.1691, 0.0134, 0.0200, 0.0111, 0.0114, 7.7209, 7.8547])   #Optim rates with BS bond\n",
    "update_kon_dict = {}\n",
    "for edge in rn.network.edges:\n",
    "    print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "    update_kon_dict[edge] = new_kon[uid_dict[edge]]\n",
    "\n",
    "\n",
    "nx.set_edge_attributes(rn.network,update_kon_dict,'k_on')\n",
    "# for edge in rn.network.edges:\n",
    "#     print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "\n",
    "# new_params = [36.289535, 95.123275]\n",
    "# new_params = [33.170844 , 76.489304]\n",
    "new_params = [36.289535, 85.123275]\n",
    "# new_params=[10,10,10,10]\n",
    "for n,data in rn.creation_rxn_data.items():\n",
    "    data['k_on'] = new_params[n]\n",
    "\n",
    "print(\"Creation Data: \")\n",
    "print(rn.creation_rxn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22319088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd4096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_rates = [25,26]\n",
    "\n",
    "vec_rn = VectorizedRxnNet(rn, dev='cpu',optim_rates=optim_rates)\n",
    "vec_rn.reset()\n",
    "# print(vec_rn.kon)\n",
    "runtime =1e2\n",
    "sim = VecSim(vec_rn, runtime, device='cpu')\n",
    "y = sim.simulate(conc_scale=1e-2,conc_thresh=1e-2,mod_factor=10,mod_bool=True,verbose=True,change_cscale_tit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d670b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t95 : \",y[-1])\n",
    "print(\"Efficiency: \",(y[-1][-2]*torch.max(new_kon)*100))\n",
    "times = []\n",
    "for i in y[-1]:\n",
    "    if i==-1:\n",
    "        times.append(-1)\n",
    "    else:\n",
    "        times.append(i.item())\n",
    "        \n",
    "print(\"Times: \",times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82474bb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib notebook\n",
    "fig, ax = plt.subplots()\n",
    "nodes_list = ['A','B','AB','ABM','ABMS']\n",
    "# nodes_list_repeat = ['A','B','S','AB','AS','AA','BS','ABS','AAB','AAS','AABS']\n",
    "sim.plot_observable(nodes_list, ax=ax,legend=False,seed=198)\n",
    "ax.set_title(\"runtime: \" + str(runtime) + \" seconds\")\n",
    "handles,labels = ax.get_legend_handles_labels()\n",
    "ax.set_xscale(\"log\")\n",
    "fig.legend(handles,nodes_list,loc='upper center',fancybox=True,ncol=3,fontsize='small',markerscale=1.0)\n",
    "ax.grid(which=\"major\",axis=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7da932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_arr = np.array(sim.steps)\n",
    "complx_conc = sim.observables[14][1]\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(sim.steps,complx_conc,linestyle='',marker='x')\n",
    "ax.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c202f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time_interval(time,conc,time_int=0.1):\n",
    "    start_time=time[0]\n",
    "    time_array = []\n",
    "    conc_array = []\n",
    "    for i in range(len(time)):\n",
    "        new_time=time[i]\n",
    "        ts = new_time/start_time\n",
    "        if ts>=time_int:\n",
    "            time_array.append(time[i])\n",
    "            conc_array.append(conc[i])\n",
    "            start_time=new_time\n",
    "    return(time_array,conc_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9ea85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vec_rn.titration_time_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5a726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_time = vec_rn.titration_time_map[25]\n",
    "# print(mod_time)\n",
    "\n",
    "\n",
    "\n",
    "sel_time = (time_arr >= mod_time)\n",
    "sel_indx = np.argwhere(sel_time)[0][0]\n",
    "\n",
    "\n",
    "filter_time,filter_conc = convert_time_interval(time_arr[sel_indx-1:],complx_conc[sel_indx-1:],time_int=1.10)\n",
    "final_time = np.concatenate((time_arr[:sel_indx],filter_time[:]))\n",
    "final_conc = np.concatenate((complx_conc[:sel_indx],filter_conc[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29f29ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(filter_time[:],filter_conc[:],linestyle='',marker='x')\n",
    "ax.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bc27df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trap_met = TrapMetric(sim)\n",
    "\n",
    "# lag,time_bounds = trap_met.calc_lag(np.array(sim.steps),np.array(sim.observables[14][1]),99.9)\n",
    "\n",
    "\n",
    "mask = (final_time > mod_time)\n",
    "\n",
    "\n",
    "fig,[ax1,ax2,ax3] = plt.subplots(3,1,figsize=(6,12))\n",
    "ax1.plot(final_time[mask],final_conc[mask],linestyle='',marker='x')\n",
    "# ax1.vlines(time_bounds[0],ymin=0,ymax=100,color='k',linestyle='--')\n",
    "# ax1.vlines(time_bounds[1],ymin=0,ymax=100,color='r',linestyle='--')\n",
    "# ax1.vlines(time_bounds[2],ymin=0,ymax=100,color='g',linestyle='--')\n",
    "ax1.set_xscale(\"log\")\n",
    "\n",
    "#Clean Version GRAD1\n",
    "clean_time1 = time_arr\n",
    "\n",
    "# l_grad2_unclean = trap_met.calc_slope(clean_time1,l_grad,mode='log')\n",
    "# clean_time2,l_grad2 = trap_met.clean_data(clean_time1,l_grad2_unclean,mode='hist')\n",
    "# l_grad3 = trap_met.calc_slope(clean_time2,l_grad2,mode='log')\n",
    "# mask = (clean_time < 183) & (clean_time>181)\n",
    "\n",
    "#Uncleaned version - GRAD1\n",
    "l_grad_unclean = trap_met.calc_slope(final_time,final_conc,mode='log')\n",
    "\n",
    "#Clean Version - GRAD2\n",
    "# clean_time2,l_grad2 = trap_met.clean_data(clean_time1,l_grad,mode='hist')\n",
    "\n",
    "#Unclean Version - GRAD2\n",
    "l_grad2_unclean = trap_met.calc_slope(final_time,l_grad_unclean,mode='log')\n",
    "\n",
    "ax2.plot(final_time[mask],l_grad_unclean[mask],linestyle='',marker='.',alpha=0.6)\n",
    "# ax2.plot(np.array(sim.steps)[:],np.degrees(np.arctan(l_grad[:])),linestyle='',marker='.',alpha=0.6)\n",
    "# ax2.vlines(time_bounds[0],ymin=0,ymax=100,color='k',linestyle='--')\n",
    "# ax2.vlines(time_bounds[1],ymin=0,ymax=100,color='r',linestyle='--')\n",
    "# ax2.vlines(time_bounds[2],ymin=0,ymax=100,color='g',linestyle='--')\n",
    "ax2.set_xscale(\"log\")\n",
    "\n",
    "ax3.plot(final_time[mask],l_grad2_unclean[mask],linestyle='',marker='.',alpha=0.6)\n",
    "# ax3.vlines(time_bounds[0],ymin=0,ymax=10,color='k',linestyle='--')\n",
    "# ax3.vlines(time_bounds[1],ymin=0,ymax=10,color='r',linestyle='--')\n",
    "# ax3.vlines(time_bounds[2],ymin=0,ymax=10,color='g',linestyle='--')\n",
    "ax3.set_xscale(\"log\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6465126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysing GRAD1\n",
    "\n",
    "l_grad_unclean = trap_met.calc_slope(final_time,final_conc,mode='log')\n",
    "# step_size=[]\n",
    "# for i in range(len(time_arr)-1):\n",
    "#     delta = time_arr[i+1]-time_arr[i]\n",
    "#     step_size.append(delta)\n",
    "# remove_indx = []\n",
    "# for i in range(len(step_size)-1):\n",
    "#     delta = step_size[i+1]-step_size[i]\n",
    "#     if delta < 0:\n",
    "#         remove_indx.append(i)\n",
    "# mask_bool = np.ones((len(time_arr)),dtype='bool')\n",
    "# for i in range(len(remove_indx)):\n",
    "#     mask_bool[remove_indx[i]:remove_indx[i]+1]=False\n",
    "# clean_time1 = time_arr[mask_bool]\n",
    "# l_grad = l_grad_unclean[mask_bool]\n",
    "\n",
    "# clean_time1,l_grad=trap_met.clean_data(final_time,l_grad_unclean,mode='hist')\n",
    "\n",
    "def clean_data(time,l_grad,thresh_freq=1,bin_num=50):\n",
    "    data=np.histogram(l_grad,bins=bin_num)\n",
    "    print(data[0])\n",
    "    # print(data)\n",
    "    flag=False\n",
    "    count=0\n",
    "    bin_val_min=0\n",
    "    bin_val_max=0\n",
    "    for i in range(len(data[0])):\n",
    "        if data[0][i] >=10 and not flag:\n",
    "            flag=True\n",
    "            count+=1\n",
    "            bin_val_min = data[1][i]\n",
    "        elif data[0][i] <=1 and flag:\n",
    "            count+=1\n",
    "            bin_val_max=data[1][i]\n",
    "            break\n",
    "\n",
    "    mask_out = (l_grad <= bin_val_max) & (l_grad >= bin_val_min)\n",
    "    new_time = np.array(time)[mask_out]\n",
    "    l_grad_new = l_grad[mask_out]\n",
    "\n",
    "    return(new_time,l_grad_new)\n",
    "\n",
    "clean_time1,l_grad = clean_data(final_time,l_grad_unclean)\n",
    "fig,ax2 = plt.subplots()\n",
    "\n",
    "ax2.plot(final_time,l_grad_unclean,linestyle='',marker='.',alpha=0.6)\n",
    "ax2.set_xscale(\"log\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c82e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_l_grad = l_grad_unclean\n",
    "actual_time = final_time\n",
    "\n",
    "#Finding time points by just visual picking\n",
    "first_peak_mask = actual_time<1e4\n",
    "first_peak_indx = np.argmax(actual_l_grad[first_peak_mask])\n",
    "first_peak = actual_time[first_peak_mask][first_peak_indx]\n",
    "\n",
    "second_regime_mask = (actual_time>1e3)\n",
    "second_peak_indx = np.argmax(actual_l_grad[second_regime_mask])\n",
    "second_peak = actual_time[second_regime_mask][second_peak_indx]\n",
    "\n",
    "# third_regime_mask = (actual_time>1e6)\n",
    "# third_peak_indx = np.argmax(actual_l_grad[third_regime_mask])\n",
    "# third_peak = actual_time[third_regime_mask][third_peak_indx]\n",
    "\n",
    "# time_bounds = [first_peak,second_peak,third_peak]\n",
    "time_bounds = [first_peak,second_peak]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb8af4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(time_bounds)\n",
    "lag_time = np.log(time_bounds[1]/time_bounds[0])\n",
    "print(\"Lag Factor: \",lag_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dd9545",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,[ax1,ax2,ax3] = plt.subplots(3,1,figsize=(6,12))\n",
    "ax1.plot(final_time,final_conc,linestyle='',marker='x')\n",
    "ax1.vlines(time_bounds[0],ymin=0,ymax=100,color='k',linestyle='--')\n",
    "ax1.vlines(time_bounds[1],ymin=0,ymax=100,color='r',linestyle='--')\n",
    "# ax1.vlines(time_bounds[2],ymin=0,ymax=100,color='g',linestyle='--')\n",
    "ax1.set_xscale(\"log\")\n",
    "# ax1.set_xlim(left=1e3,right=1e5)\n",
    "ax2.plot(final_time[mask],l_grad_unclean[mask],linestyle='',marker='.',alpha=0.6)\n",
    "ax2.vlines(time_bounds[0],ymin=0,ymax=20,color='k',linestyle='--')\n",
    "ax2.vlines(time_bounds[1],ymin=0,ymax=20,color='r',linestyle='--')\n",
    "# ax2.vlines(time_bounds[2],ymin=0,ymax=20,color='g',linestyle='--')\n",
    "ax2.set_xscale(\"log\")\n",
    "# ax2.set_xlim(left=1e3,right=1e5)\n",
    "# ax3.plot(clean_time2[:],l_grad2_new[:],linestyle='',marker='.',alpha=0.6)\n",
    "# ax3.vlines(time_bounds[0],ymin=0,ymax=10,color='k',linestyle='--')\n",
    "# ax3.vlines(time_bounds[1],ymin=0,ymax=10,color='r',linestyle='--')\n",
    "# # ax3.vlines(time_bounds[2],ymin=0,ymax=10,color='g',linestyle='--')\n",
    "# ax3.set_xscale(\"log\")\n",
    "# ax3.set_xlim(left=1e3,right=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fc81f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vec_rn.copies_vec)\n",
    "print(\"Unused AMount: \",y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e739361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating chemical potential and fluxes\n",
    "#Calculating correlation b/w fluxes\n",
    "def corr_matrix(M):\n",
    "    return(np.corrcoef(M))\n",
    "\n",
    "\n",
    "flux_corr_matrix = corr_matrix(np.transpose(sim.uid_flux.detach().numpy()))\n",
    "# print(np.transpose(sim.uid_flux.detach().numpy()))\n",
    "\n",
    "%matplotlib notebook\n",
    "fig_c,ax_c = plt.subplots(figsize=(12,12))\n",
    "hm = ax_c.imshow(flux_corr_matrix)\n",
    "\n",
    "\n",
    "fw_labels=[gtostr(rn.network.nodes[tup[0]]['struct'])+'+'+gtostr(rn.network.nodes[tup[1]]['struct']) for tup in list(react_dict.keys())]\n",
    "rw_labels=[gtostr(rn.network.nodes[tup[0]]['struct'])+'-'+gtostr(rn.network.nodes[tup[1]]['struct']) for tup in list(react_dict.keys())]\n",
    "ax_labels = fw_labels+rw_labels\n",
    "ax_c.set_xticks(np.arange(len(ax_labels)))\n",
    "ax_c.set_yticks(np.arange(len(ax_labels)))\n",
    "ax_c.set_xticklabels(ax_labels)\n",
    "ax_c.set_yticklabels(ax_labels)\n",
    "plt.setp(ax_c.get_xticklabels(),rotation=90, ha='center',fontsize=10,va='top')\n",
    "plt.setp(ax_c.get_yticklabels(),va='center',fontsize=10)\n",
    "fig_c.colorbar(hm,ax=ax_c,aspect=40,label=\"Corr Coeff\",orientation='horizontal',panchor=(0.5,0.0),pad=0.2,shrink=0.5)\n",
    "# ax_c.grid()\n",
    "\n",
    "for i in range(len(ax_labels)):\n",
    "    for j in range(len(ax_labels)):\n",
    "#         print(ax_labels[j],ax_labels[i])\n",
    "        ax.text(1.0,1.0,flux_corr_matrix[i,j],ha=\"center\", va=\"center\", color=\"w\",transform=ax.transAxes)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "label = \"Reaction Fluxes\"\n",
    "ax_c.set_title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c0f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import os\n",
    "# pick_path = \"./correlation_matrix_reference.pickle\"\n",
    "# ref_corr_matrix=np.zeros((2,2))\n",
    "# if os.path.exists(pick_path):\n",
    "#     with open(pick_path,'rb') as pick_handle:\n",
    "#         ref_corr_matrix = pickle.load(pick_handle)\n",
    "# else:\n",
    "#     with open(pick_path,\"wb\") as pick_handle2:\n",
    "#         pickle.dump(flux_corr_matrix,pick_handle2)\n",
    "\n",
    "# if ref_corr_matrix.all() !=0:\n",
    "#     diff_matrix = flux_corr_matrix-ref_corr_matrix\n",
    "#     fig_diff,ax_diff = plt.subplots(figsize=(12,12))\n",
    "#     hm = ax_diff.imshow(diff_matrix)\n",
    "    \n",
    "#     fw_labels=[gtostr(rn.network.nodes[tup[0]]['struct'])+'+'+gtostr(rn.network.nodes[tup[1]]['struct']) for tup in list(react_dict.keys())]\n",
    "#     rw_labels=[gtostr(rn.network.nodes[tup[0]]['struct'])+'-'+gtostr(rn.network.nodes[tup[1]]['struct']) for tup in list(react_dict.keys())]\n",
    "#     ax_labels = fw_labels+rw_labels\n",
    "#     ax_diff.set_xticks(np.arange(len(ax_labels)))\n",
    "#     ax_diff.set_yticks(np.arange(len(ax_labels)))\n",
    "#     ax_diff.set_xticklabels(ax_labels)\n",
    "#     ax_diff.set_yticklabels(ax_labels)\n",
    "#     plt.setp(ax_diff.get_xticklabels(),rotation=90, ha='center',fontsize=10,va='top')\n",
    "#     plt.setp(ax_diff.get_yticklabels(),va='center',fontsize=10)\n",
    "#     fig_diff.colorbar(hm,ax=ax_diff,aspect=40,label=\"Corr Coeff\",orientation='horizontal',panchor=(0.5,0.0),pad=0.2,shrink=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74701dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_data=sim.uid_flux.detach().numpy()[:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d962b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate lag between diff fluxes\n",
    "from scipy import signal\n",
    "def calc_lag(x,y):\n",
    "    corr_array = signal.correlate(x,y,mode='full')\n",
    "#     lags = signal.correlation_lags(x.size, y.size, mode=\"full\")\n",
    "#     lag = lags[np.argmax(corr_array)]\n",
    "#     np_corr_array = np.correlate(x,y,mode='full')\n",
    "    lag1 = np.argmax(corr_array)-np.floor(corr_array.shape[0]/2)\n",
    "    corr_coeff = np.corrcoef(x,y,rowvar=False)\n",
    "    \n",
    "#     print(corr_array)\n",
    "#     print(np_corr_array)\n",
    "#     print(corr_coeff)\n",
    "#     print(\"Lag time: \",lag1)\n",
    "    return(lag1)\n",
    "    \n",
    "\n",
    "lag_matrix = np.zeros((flux_data.shape[1],flux_data.shape[1]))\n",
    "# coeff_matrix = np.zeros(flux_data.shape)\n",
    "for i in range(flux_data.shape[1]):\n",
    "    x=flux_data[:,i]\n",
    "    for j in range(flux_data.shape[1]):\n",
    "        y=flux_data[:,j]\n",
    "        lag_matrix[i,j]=calc_lag(x,y)\n",
    "        \n",
    "\n",
    "fig_l,ax_l = plt.subplots(figsize=(12,12))\n",
    "hm = ax_l.imshow(lag_matrix,cmap='inferno')\n",
    "# fw_labels=list(react_dict.values())\n",
    "# rw_labels=['-'+str(l) for l in fw_labels]\n",
    "# ax_labels = fw_labels+rw_labels\n",
    "fw_labels=[gtostr(rn.network.nodes[tup[0]]['struct'])+'+'+gtostr(rn.network.nodes[tup[1]]['struct']) for tup in list(react_dict.keys())]\n",
    "rw_labels=[gtostr(rn.network.nodes[tup[0]]['struct'])+'-'+gtostr(rn.network.nodes[tup[1]]['struct']) for tup in list(react_dict.keys())]\n",
    "ax_labels = fw_labels+rw_labels\n",
    "ax_l.set_xticks(np.arange(len(ax_labels)))\n",
    "ax_l.set_yticks(np.arange(len(ax_labels)))\n",
    "ax_l.set_xticklabels(ax_labels)\n",
    "ax_l.set_yticklabels(ax_labels)\n",
    "plt.setp(ax_l.get_xticklabels(),rotation=90, ha='center',fontsize=10,va='top')\n",
    "plt.setp(ax_l.get_yticklabels(),va='center',fontsize=10)\n",
    "fig_l.colorbar(hm,ax=ax_l,aspect=40,label=\"Corr Coeff\",orientation='horizontal',pad=0.07,shrink=0.5)\n",
    "fig_l.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02342191",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_map = {}\n",
    "for node in rn.network.nodes():\n",
    "    node_map[gtostr(rn.network.nodes[node]['struct'])] = node\n",
    "\n",
    "print(node_map)\n",
    "def get_max_edge(n):\n",
    "    \"\"\"\n",
    "    Calculates the max rate (k_on) for a given node\n",
    "    To find out the maximum flow path to the final complex starting from the current node.\n",
    "    \n",
    "    Can also calculate the total rate of consumption of a node by summing up all rates. \n",
    "    Can tell which component is used quickly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        edges = rn.network.out_edges(n)\n",
    "        #Loop over all edges\n",
    "        #Get attributes\n",
    "        kon_max = -1\n",
    "        next_node = -1\n",
    "\n",
    "        kon_sum = 0\n",
    "        total_flux_outedges = 0\n",
    "        total_flux_inedges = 0\n",
    "        if len(edges)==0:\n",
    "            return(False)\n",
    "            \n",
    "        for edge in edges:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "            kon_sum+=temp_kon\n",
    "            \n",
    "            if temp_kon > kon_max:\n",
    "                kon_max = temp_kon\n",
    "                next_node=edge[1]\n",
    "             \n",
    "        return(kon_max,next_node,kon_sum)\n",
    "    except Exception as err:\n",
    "        raise(err)\n",
    "\n",
    "        \n",
    "def get_node_flux(n):\n",
    "    total_flux_outedges = 0\n",
    "    total_flux_inedges = 0\n",
    "    #Go over all the out edges\n",
    "    edges_out = rn.network.out_edges(n)\n",
    "    if len(edges_out)>0:\n",
    "\n",
    "        for edge in edges_out:\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            #print(data)\n",
    "            #Get uid\n",
    "            uid = data['uid']\n",
    "\n",
    "            #Get updated kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Calculate k_off also\n",
    "            std_c = Tensor([1e6])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Getting conc. of reactants and products\n",
    "            #Get product\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct']) \n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux = koff*vec_rn.copies_vec[edge[1]] - temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])\n",
    "            #edge_flux = koff*vec_rn.copies_vec[edge[1]] \n",
    "\n",
    "            print(\"Reaction: \", gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react,\" -> \",prod)\n",
    "            print(\"Net flux: \",edge_flux)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Reaction data OUTWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_outedges+=edge_flux\n",
    "    \n",
    "    #Now go over all the in edges\n",
    "    edges_in = rn.network.in_edges(n)\n",
    "    react_list = []\n",
    "    if len(edges_in) > 0:\n",
    "        for edge in edges_in:\n",
    "            if edge[0] in react_list:\n",
    "                continue\n",
    "            data = rn.network.get_edge_data(edge[0],edge[1])\n",
    "            uid = data['uid']\n",
    "\n",
    "\n",
    "            #Get generation rates; which would be kon\n",
    "            temp_kon = vec_rn.kon[uid]\n",
    "\n",
    "            #Get consumption rates; which is k_off\n",
    "            std_c = Tensor([1e6])\n",
    "            l_kon = torch.log(temp_kon)\n",
    "            l_koff = (vec_rn.rxn_score_vec[uid] * 1. / (vec_rn._R * vec_rn._T)) + l_kon + torch.log(std_c)\n",
    "            koff = torch.exp(l_koff)\n",
    "\n",
    "            #Get conc. of reactants and products\n",
    "            prod = gtostr(rn.network.nodes[edge[1]]['struct'])\n",
    "            #Get other reactant\n",
    "            react = \"\".join(sorted(list(set(prod) - set(gtostr(rn.network.nodes[edge[0]]['struct']) ))))\n",
    "            react_list.append(node_map[react])\n",
    "            #Net flux from this edge = Generation - consumption\n",
    "            edge_flux_in = temp_kon*(vec_rn.copies_vec[edge[0]])*(vec_rn.copies_vec[node_map[react]])- koff*vec_rn.copies_vec[edge[1]]\n",
    "            #edge_flux_in = koff*vec_rn.copies_vec[edge[1]]\n",
    "            \n",
    "\n",
    "\n",
    "            print(\"Reaction: \", prod ,\" -> \",gtostr(rn.network.nodes[edge[0]]['struct']), \"+\",react)\n",
    "            print(\"Net flux: \",edge_flux_in)\n",
    "            print(\"kon : \",temp_kon)\n",
    "            print(\"koff: \",koff)\n",
    "            print(\"Raction data INWARD: \")\n",
    "            print(data)\n",
    "\n",
    "            total_flux_inedges+=edge_flux_in\n",
    "    net_node_flux = total_flux_outedges + total_flux_inedges\n",
    "    \n",
    "    return(net_node_flux)\n",
    "    \n",
    "pathway = []\n",
    "kon_sumarray = []\n",
    "total_con_rate = {}\n",
    "net_flux = {}\n",
    "for n in rn.network.nodes():\n",
    "    \n",
    "    n_str = gtostr(rn.network.nodes[n]['struct']) \n",
    "    \n",
    "    paths = [n_str]\n",
    "    kon_sum = 0\n",
    "    temp_node = n\n",
    "    max_edge = True\n",
    "    consumption_rate = 0\n",
    "    if n < len(rn.network.nodes()):#num_monomers:\n",
    "#         print(\"Current node: \")\n",
    "#         print(n_str)\n",
    "        while max_edge:\n",
    "            max_edge = get_max_edge(temp_node)\n",
    "            if max_edge:\n",
    "                total_con_rate[gtostr(rn.network.nodes[temp_node]['struct'])] = max_edge[2]\n",
    "                \n",
    "                temp_node = max_edge[1]\n",
    "                kon_sum += max_edge[0].item()\n",
    "                \n",
    "                \n",
    "#                 print(\"Next node: \")\n",
    "#                 print(temp_node)\n",
    "\n",
    "                paths.append(gtostr(rn.network.nodes[temp_node]['struct']))\n",
    "            else:\n",
    "                break\n",
    "        pathway.append(paths)\n",
    "        kon_sumarray.append(kon_sum)\n",
    "        paths=[]\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"|                                                                             |\")\n",
    "    node_flux = get_node_flux(n)\n",
    "    net_flux[gtostr(rn.network.nodes[n]['struct'])] = node_flux\n",
    "    print(\"|                                                                             |\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "print(pathway)\n",
    "print(kon_sumarray)\n",
    "\n",
    "#print(total_con_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4240403c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for k,v in sorted(net_flux.items(),key=lambda x : x[1]):\n",
    "#     print(k,\" : \", v)\n",
    "\n",
    "print(vec_rn.copies_vec)\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44561dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for k,v in sorted(total_con_rate.items(),key=lambda x : x[1]):\n",
    "#     print(k,\" : \", v.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531e38a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "labels = nx.get_node_attributes(rn.network, 'struct')\n",
    "labels = {key:gtostr(labels[key]) for key in labels.keys()}\n",
    "# nx.draw_networkx(rn.network,labels=labels,node_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90b7d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "sl_pos = nx.shell_layout(rn.network)\n",
    "nx.draw_networkx(rn.network,pos=sl_pos,labels=labels,node_size=1000,node_color='indianred',ax=ax,edgelist=[])\n",
    "# new_kon = 0.5*np.array([0.8179, 0.8172, 0.8174, 0.8174, 0.8218, 0.0296, 0.0295, 4.6052, 0.8188,\n",
    "#         0.8188, 7.7299, 5.4280, 0.8199, 0.8183, 7.1332, 4.9835, 4.9838, 0.0307,\n",
    "#         0.0315, 5.2260, 5.2278])\n",
    "\n",
    "if vec_rn.rxn_coupling:\n",
    "    label_kon = 0.5*sim.coupled_kon.detach().numpy()\n",
    "else:\n",
    "    label_kon = 0.5*vec_rn.kon.detach().numpy()\n",
    "    \n",
    "sample_colors = ['black','black','black','black','olivedrab','orchid','darkorange','teal','']\n",
    "edge_widths = []\n",
    "edge_colors= []\n",
    "for edge,uid in uid_dict.items():\n",
    "    edge_widths.append(label_kon[uid])\n",
    "    #edge_colors.append(sample_colors[uid])\n",
    "nx.draw_networkx_edges(rn.network,pos=sl_pos,width=edge_widths,label=edge_widths,arrowsize=10,min_target_margin=15.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad30e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(figsize=(6,6))\n",
    "# nx.draw_networkx(rn.network,pos=sl_pos,labels=labels,node_size=1000,node_color='indianred',ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3bfe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "poly_system = EquilibriumSolver(rn)\n",
    "solution = poly_system.solve(init_val=vec_rn.copies_vec.detach().numpy().tolist())\n",
    "#solution = poly_system.solve(verifyBool = False)\n",
    "if solution == None:\n",
    "    print(\"No Equilibrium solution\")\n",
    "else:\n",
    "    print(solution)\n",
    "    print(\"Equilibrium expected yield: \", 100 * solution[-1] / min(vec_rn.initial_copies[:vec_rn.num_monomers]), '%')\n",
    "print(vec_rn.kon)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
