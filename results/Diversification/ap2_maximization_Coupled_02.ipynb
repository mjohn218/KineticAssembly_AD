{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Equilibrium Maximazation of Yield #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make sure jupyter path is correct for loading local moudules\n",
    "import sys\n",
    "# path to steric_simulator module relative to notebook\n",
    "sys.path.append(\"../../../\")\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnergyExplorer Module is not available. Check Rosetta installation. <ipykernel.iostream.OutStream object at 0x7f7ecebb8c50>\n"
     ]
    }
   ],
   "source": [
    "from KineticAssembly_AD import ReactionNetwork, VectorizedRxnNet, VecSim, Optimizer, EquilibriumSolver\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import DoubleTensor as Tensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with the AP2 complex that we've worked with before. Pairwise $\\Delta Gs$ were derived from the PDB structures via Rossetta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['default_assoc', 1.0]\n",
      "['rxn_coupling', True]\n",
      "True\n",
      "['monomer_add_only', False]\n",
      "New node added - Node index: 4 ; Node label: AM \n",
      "New node added - Node index: 5 ; Node label: AB \n",
      "New node added - Node index: 6 ; Node label: AS \n",
      "Trying internal bonds\n",
      "New node added - Node index: 7 ; Node label: BM \n",
      "New node added - Node index: 8 ; Node label: MS \n",
      "New node added - Node index: 9 ; Node label: ABM \n",
      "New node added - Node index: 10 ; Node label: AMS \n",
      "Trying internal bonds\n",
      "New node added - Node index: 11 ; Node label: BS \n",
      "New node added - Node index: 12 ; Node label: ABS \n",
      "New node added - Node index: 13 ; Node label: BMS \n",
      "New node added - Node index: 14 ; Node label: ABMS \n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  2 10\n",
      "The common reactant is:  B\n",
      "Edge added between:  2 14\n",
      "Trying internal bonds\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  3 9\n",
      "The common reactant is:  S\n",
      "Edge added between:  3 14\n",
      "Trying internal bonds\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  4 11\n",
      "Trying internal bonds\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  5 8\n",
      "Trying internal bonds\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  6 7\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  12 1\n",
      "The common reactant is:  M\n",
      "Edge added between:  1 14\n",
      "Trying internal bonds\n",
      "The number of bonds formed are not compensated by the number of edges\n",
      "This could be possible due to presence of a repeating subunit\n",
      "SOurce1:  13 0\n",
      "The common reactant is:  A\n",
      "Edge added between:  0 14\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "Coupling Reaction ID:  {5: [0, 3], 6: [0, 4], 8: [1, 3], 9: [1, 7], 10: [3, 7], 11: [1, 3, 7], 12: [2, 4], 13: [2, 7], 14: [4, 7], 15: [2, 4, 7], 16: [1, 2, 3, 4], 17: [0, 2, 3, 7], 18: [0, 1, 4, 7], 19: [0, 1], 20: [0, 2], 21: [1, 2], 22: [3, 4], 23: [0, 3, 4], 24: [0, 1, 2]}\n",
      "Reaction Network Completed\n",
      "Reaction rates:  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64, grad_fn=<CopySlices>)\n",
      "dGs:  tensor([-20., -20., -20., -20., -20., -40., -40., -20., -40., -40., -40., -60.,\n",
      "        -40., -40., -40., -60., -80., -80., -80., -40., -40., -40., -40., -60.,\n",
      "        -60.], dtype=torch.float64)\n",
      "Species Concentrations:  tensor([100., 100., 100., 100.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.], dtype=torch.float64)\n",
      "Shifting to device:  cpu\n"
     ]
    }
   ],
   "source": [
    "base_input = '../input_files/tetramer_diversification.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()\n",
    "vec_rn = VectorizedRxnNet(rn, dev='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -- A\n",
      "1 -- M\n",
      "2 -- B\n",
      "3 -- S\n",
      "4 -- AM\n",
      "5 -- AB\n",
      "6 -- AS\n",
      "7 -- BM\n",
      "8 -- MS\n",
      "9 -- ABM\n",
      "10 -- AMS\n",
      "11 -- BS\n",
      "12 -- ABS\n",
      "13 -- BMS\n",
      "14 -- ABMS\n",
      "{(0, 4): 0, (0, 5): 1, (0, 6): 2, (0, 9): 19, (0, 10): 20, (0, 12): 21, (0, 14): 24, (1, 4): 0, (1, 7): 3, (1, 8): 4, (1, 9): 5, (1, 10): 6, (1, 13): 22, (1, 14): 23, (2, 5): 1, (2, 7): 3, (2, 11): 7, (2, 9): 8, (2, 12): 9, (2, 13): 10, (2, 14): 11, (3, 6): 2, (3, 8): 4, (3, 11): 7, (3, 10): 12, (3, 12): 13, (3, 13): 14, (3, 14): 15, (4, 9): 8, (4, 10): 12, (4, 14): 16, (5, 9): 5, (5, 12): 13, (5, 14): 17, (6, 10): 6, (6, 12): 9, (6, 14): 18, (7, 13): 14, (7, 14): 18, (7, 9): 19, (8, 13): 10, (8, 14): 17, (8, 10): 20, (9, 14): 15, (10, 14): 11, (11, 14): 16, (11, 12): 21, (11, 13): 22, (12, 14): 23, (13, 14): 24}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    print(n,\"--\",gtostr(rn.network.nodes[n]['struct']))\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_dict[(n,k)] = uid\n",
    "\n",
    "print(uid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 19}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 20}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 21}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 24}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 6}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 22}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 23}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 7}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 8}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 9}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 10}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 11}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 7}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 12}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 13}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 14}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 15}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 8}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 12}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 16}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 13}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 17}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 6}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 9}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 18}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 14}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 18}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 19}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 10}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 17}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 20}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 15}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 11}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-80.], dtype=torch.float64), 'uid': 16}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 21}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 22}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 23}\n",
      "{'k_on': 1.0, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-60.], dtype=torch.float64), 'uid': 24}\n",
      "Reaction rates:  tensor([3.0000, 3.0000, 3.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "       dtype=torch.float64, grad_fn=<CopySlices>)\n",
      "dGs:  tensor([-20., -20., -20., -20., -20., -40., -40., -20., -40., -40., -40., -60.,\n",
      "        -40., -40., -40., -60., -80., -80., -80., -40., -40., -40., -40., -60.,\n",
      "        -60.], dtype=torch.float64)\n",
      "Species Concentrations:  tensor([100., 100., 100., 100.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.], dtype=torch.float64)\n",
      "Shifting to device:  cpu\n",
      "tensor([3.0000, 3.0000, 3.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "       dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "#Do modifications here\n",
    "#Changing Initial Conditions\n",
    "import networkx as nx\n",
    "#Changin k_on\n",
    "new_kon = torch.zeros([rn._rxn_count], requires_grad=True).double()\n",
    "new_kon = new_kon + Tensor([1.]*np.array(1e-1))\n",
    "new_kon[0:3]=3\n",
    "\n",
    "update_kon_dict = {}\n",
    "for edge in rn.network.edges:\n",
    "    print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "    update_kon_dict[edge] = new_kon[uid_dict[edge]]\n",
    "\n",
    "nx.set_edge_attributes(rn.network,update_kon_dict,'k_on')\n",
    "\n",
    "\n",
    "vec_rn = VectorizedRxnNet(rn, dev='cpu')\n",
    "print(vec_rn.kon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(1, 1): [0, 1, 2, 3, 4, 7], (2, 1): [5, 6, 8, 9, 10, 12, 13, 14, 19, 20, 21, 22], (3, 1): [11, 15, 23, 24], (2, 2): [16, 17, 18]}\n"
     ]
    }
   ],
   "source": [
    "print(vec_rn.rxn_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using the optimizer ##\n",
    "\n",
    "### Define an instance of the optimizer class\n",
    "#### Input Arguments:\n",
    "\n",
    "reaction_network : Input the vectorized rxn network\n",
    "\n",
    "sim_runtime: The runtime of the kinetic simulation. Needs to be same as the time over the experimental reaction data.\n",
    "\n",
    "optim_iterations: No. of iterations to run the optimization. Can start at low values(100) and increase depending upon memory usage.\n",
    "\n",
    "learning_rate = The size of the gradient descent step for updating parameter values. Needs to be atleast (1e-3-1e-1)* min{parameter value}. If learning rate is too high, it can take a longer step and sometimes lead to negative value of parameters which is unphysical. Requires some trial runs to find the best value. \n",
    "\n",
    "device: cpu or gpu\n",
    "\n",
    "method: Choose which pytorch based optimized to use for gradient descent - Adam or RMSprop\n",
    "\n",
    "mom: Only for RMSprop method. Use momentum term during gradient descent. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vec_rn.reset(reset_params=True)\n",
    "optim = Optimizer(reaction_network=vec_rn,\n",
    "                  sim_runtime=1,\n",
    "                  optim_iterations=100,\n",
    "                  learning_rate=1e-2,\n",
    "                  device='cpu',method=\"RMSprop\",)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the optimization method\n",
    "\n",
    "#### Input arguments\n",
    "\n",
    "conc_scale, conc_thresh, mod_bool, mod_factor = As defined for the VecSim class. \n",
    "\n",
    "max_thresh: Max. allowed values of parameters being updated. Beyond this maximum a penalty is imposed on the cost function. (Regularization)\n",
    "\n",
    "max_yield: It is a control variable that is used to store the updated parameter values over all iterations for further analysis. The parameter values are stored only if the current yield exceed this max_yield. \n",
    "\n",
    "yield_species: Yield of the species being optimized(node index). Default value is -1 (picks the last element from the array which is always the final complex for a fully connected topology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reaction Parameters before optimization: \n",
      "[Parameter containing:\n",
      "tensor([3.0000, 3.0000, 3.0000, 0.1000, 0.1000, 0.1000], dtype=torch.float64,\n",
      "       requires_grad=True)]\n",
      "Optimizer State: <bound method Optimizer.state_dict of RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")>\n",
      "Using CPU\n",
      "Yield on sim. iteration 0 was 89.9%.\n",
      "current params: tensor([3.0000, 3.0000, 3.0000, 0.1000, 0.1000, 0.1000], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 1 was 93.3%.\n",
      "current params: tensor([3.1000e+00, 3.1000e+00, 3.1000e+00, 2.0000e-01, 1.8913e-08, 3.5591e-08],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 2 was 85.2%.\n",
      "current params: tensor([3.0000, 3.0000, 3.2000, 0.3000, 0.1000, 0.1000], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 3 was 84.2%.\n",
      "current params: tensor([3.0013, 2.9956, 3.1992, 0.3123, 0.1257, 0.1105], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 4 was 83.4%.\n",
      "current params: tensor([3.0040, 2.9859, 3.1999, 0.3245, 0.1415, 0.1195], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 5 was 78.2%.\n",
      "current params: tensor([2.9625, 2.9615, 3.1720, 0.4193, 0.2364, 0.2128], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 6 was 77.1%.\n",
      "current params: tensor([2.9351, 2.9761, 3.1568, 0.4440, 0.2575, 0.2377], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 7 was 76.9%.\n",
      "current params: tensor([2.9333, 2.9730, 3.1554, 0.4476, 0.2611, 0.2412], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 8 was 77.2%.\n",
      "current params: tensor([2.9371, 2.9787, 3.1573, 0.4417, 0.2550, 0.2353], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 9 was 77.1%.\n",
      "current params: tensor([2.9355, 2.9759, 3.1560, 0.4451, 0.2584, 0.2386], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 10 was 76.9%.\n",
      "current params: tensor([2.9336, 2.9726, 3.1545, 0.4489, 0.2623, 0.2423], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 11 was 77.2%.\n",
      "current params: tensor([2.9376, 2.9785, 3.1564, 0.4429, 0.2560, 0.2362], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 12 was 77.0%.\n",
      "current params: tensor([2.9358, 2.9754, 3.1550, 0.4464, 0.2597, 0.2397], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 13 was 76.8%.\n",
      "current params: tensor([2.9339, 2.9720, 3.1534, 0.4504, 0.2638, 0.2436], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 14 was 77.1%.\n",
      "current params: tensor([2.9380, 2.9778, 3.1552, 0.4445, 0.2575, 0.2375], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 15 was 76.9%.\n",
      "current params: tensor([2.9362, 2.9746, 3.1537, 0.4483, 0.2614, 0.2412], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 16 was 77.2%.\n",
      "current params: tensor([2.9402, 2.9806, 3.1557, 0.4420, 0.2549, 0.2349], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 17 was 77.0%.\n",
      "current params: tensor([2.9384, 2.9776, 3.1544, 0.4456, 0.2585, 0.2384], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 18 was 76.9%.\n",
      "current params: tensor([2.9365, 2.9742, 3.1528, 0.4496, 0.2626, 0.2423], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 19 was 77.2%.\n",
      "current params: tensor([2.9407, 2.9803, 3.1548, 0.4433, 0.2560, 0.2359], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 20 was 77.0%.\n",
      "current params: tensor([2.9388, 2.9771, 3.1533, 0.4470, 0.2598, 0.2396], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 21 was 76.8%.\n",
      "current params: tensor([2.9367, 2.9735, 3.1516, 0.4513, 0.2642, 0.2437], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 22 was 77.1%.\n",
      "current params: tensor([2.9411, 2.9796, 3.1535, 0.4450, 0.2576, 0.2373], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 23 was 76.9%.\n",
      "current params: tensor([2.9392, 2.9761, 3.1519, 0.4491, 0.2617, 0.2413], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 24 was 76.7%.\n",
      "current params: tensor([2.9368, 2.9722, 3.1500, 0.4537, 0.2664, 0.2458], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 25 was 76.9%.\n",
      "current params: tensor([2.9413, 2.9773, 3.1511, 0.4487, 0.2610, 0.2405], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 26 was 76.7%.\n",
      "current params: tensor([2.9390, 2.9733, 3.1492, 0.4533, 0.2658, 0.2450], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 27 was 77.0%.\n",
      "current params: tensor([2.9436, 2.9791, 3.1507, 0.4475, 0.2596, 0.2389], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 28 was 76.8%.\n",
      "current params: tensor([2.9413, 2.9752, 3.1488, 0.4520, 0.2642, 0.2434], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 29 was 77.1%.\n",
      "current params: tensor([2.9460, 2.9818, 3.1510, 0.4453, 0.2572, 0.2365], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 30 was 76.9%.\n",
      "current params: tensor([2.9439, 2.9782, 3.1492, 0.4496, 0.2615, 0.2407], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 31 was 76.7%.\n",
      "current params: tensor([2.9415, 2.9739, 3.1472, 0.4545, 0.2666, 0.2455], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 32 was 76.9%.\n",
      "current params: tensor([2.9462, 2.9795, 3.1484, 0.4490, 0.2608, 0.2397], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 33 was 76.7%.\n",
      "current params: tensor([2.9437, 2.9752, 3.1464, 0.4540, 0.2658, 0.2445], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 34 was 77.0%.\n",
      "current params: tensor([2.9486, 2.9815, 3.1482, 0.4476, 0.2591, 0.2380], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 35 was 76.8%.\n",
      "current params: tensor([2.9463, 2.9774, 3.1462, 0.4524, 0.2639, 0.2426], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 36 was 76.5%.\n",
      "current params: tensor([2.9435, 2.9726, 3.1438, 0.4579, 0.2696, 0.2480], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 37 was 76.4%.\n",
      "current params: tensor([2.9462, 2.9714, 3.1403, 0.4605, 0.2717, 0.2496], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 38 was 75.2%.\n",
      "current params: tensor([2.9402, 2.9476, 3.1215, 0.4893, 0.2999, 0.2758], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 39 was 73.9%.\n",
      "current params: tensor([2.9272, 2.9213, 3.0997, 0.5210, 0.3310, 0.3056], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 40 was 73.5%.\n",
      "current params: tensor([2.8360, 3.0152, 3.0697, 0.5390, 0.3144, 0.3415], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 41 was 71.5%.\n",
      "current params: tensor([2.8559, 2.9778, 3.0158, 0.5955, 0.3691, 0.3876], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 42 was 70.9%.\n",
      "current params: tensor([2.9056, 2.9366, 2.9839, 0.6154, 0.3938, 0.3886], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 43 was 68.5%.\n",
      "current params: tensor([2.8722, 2.8929, 2.9151, 0.6915, 0.4697, 0.4639], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 44 was 68.5%.\n",
      "current params: tensor([2.8713, 2.8956, 2.9104, 0.6932, 0.4699, 0.4650], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 45 was 68.4%.\n",
      "current params: tensor([2.8702, 2.8982, 2.9055, 0.6951, 0.4704, 0.4663], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 46 was 68.4%.\n",
      "current params: tensor([2.8690, 2.9007, 2.9001, 0.6973, 0.4712, 0.4680], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 47 was 68.3%.\n",
      "current params: tensor([2.8673, 2.9024, 2.8946, 0.7002, 0.4725, 0.4703], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 48 was 68.2%.\n",
      "current params: tensor([2.8649, 2.9034, 2.8882, 0.7040, 0.4747, 0.4735], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 49 was 68.1%.\n",
      "current params: tensor([2.8612, 2.9030, 2.8798, 0.7100, 0.4789, 0.4788], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 50 was 67.7%.\n",
      "current params: tensor([2.8525, 2.8972, 2.8644, 0.7236, 0.4900, 0.4915], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 51 was 65.1%.\n",
      "current params: tensor([2.7774, 2.7998, 2.7684, 0.8203, 0.5862, 0.5882], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 52 was 65.3%.\n",
      "current params: tensor([2.7950, 2.8034, 2.7767, 0.8135, 0.5809, 0.5815], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 53 was 63.5%.\n",
      "current params: tensor([2.6983, 2.7489, 2.6885, 0.8963, 0.6551, 0.6637], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 54 was 63.2%.\n",
      "current params: tensor([2.6793, 2.7421, 2.6697, 0.9106, 0.6662, 0.6772], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 55 was 62.8%.\n",
      "current params: tensor([2.6513, 2.7283, 2.6434, 0.9316, 0.6834, 0.6975], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Yield on sim. iteration 56 was 62.6%.\n",
      "current params: tensor([2.6294, 2.7445, 2.6117, 0.9478, 0.6895, 0.7100], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 57 was 62.5%.\n",
      "current params: tensor([2.6139, 2.7547, 2.5914, 0.9584, 0.6936, 0.7185], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 58 was 62.5%.\n",
      "current params: tensor([2.6152, 2.7523, 2.5934, 0.9577, 0.6938, 0.7181], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 59 was 62.5%.\n",
      "current params: tensor([2.6164, 2.7500, 2.5954, 0.9570, 0.6939, 0.7177], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 60 was 62.5%.\n",
      "current params: tensor([2.6176, 2.7475, 2.5974, 0.9563, 0.6941, 0.7173], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 61 was 62.5%.\n",
      "current params: tensor([2.6188, 2.7451, 2.5995, 0.9556, 0.6943, 0.7169], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 62 was 62.5%.\n",
      "current params: tensor([2.6201, 2.7425, 2.6016, 0.9549, 0.6945, 0.7164], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 63 was 62.5%.\n",
      "current params: tensor([2.6213, 2.7400, 2.6037, 0.9541, 0.6947, 0.7160], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 64 was 62.5%.\n",
      "current params: tensor([2.6226, 2.7373, 2.6059, 0.9534, 0.6949, 0.7156], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 65 was 62.5%.\n",
      "current params: tensor([2.6239, 2.7347, 2.6081, 0.9526, 0.6951, 0.7152], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 66 was 62.5%.\n",
      "current params: tensor([2.6252, 2.7319, 2.6104, 0.9519, 0.6953, 0.7147], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 67 was 62.5%.\n",
      "current params: tensor([2.6265, 2.7291, 2.6127, 0.9511, 0.6956, 0.7143], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 68 was 62.5%.\n",
      "current params: tensor([2.6278, 2.7262, 2.6151, 0.9503, 0.6958, 0.7138], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 69 was 62.5%.\n",
      "current params: tensor([2.6292, 2.7232, 2.6176, 0.9494, 0.6960, 0.7134], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 70 was 62.5%.\n",
      "current params: tensor([2.6306, 2.7201, 2.6201, 0.9486, 0.6963, 0.7129], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 71 was 62.5%.\n",
      "current params: tensor([2.6320, 2.7169, 2.6227, 0.9477, 0.6966, 0.7124], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 72 was 62.5%.\n",
      "current params: tensor([2.6334, 2.7136, 2.6254, 0.9468, 0.6968, 0.7119], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 73 was 63.4%.\n",
      "current params: tensor([2.7057, 2.6826, 2.7037, 0.8872, 0.6610, 0.6588], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 74 was 63.2%.\n",
      "current params: tensor([2.7028, 2.6668, 2.6891, 0.8997, 0.6773, 0.6670], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 75 was 62.7%.\n",
      "current params: tensor([2.6946, 2.6387, 2.6638, 0.9220, 0.7061, 0.6822], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 76 was 62.6%.\n",
      "current params: tensor([2.7085, 2.6247, 2.6450, 0.9326, 0.7160, 0.6842], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 77 was 62.5%.\n",
      "current params: tensor([2.7221, 2.6079, 2.6246, 0.9445, 0.7280, 0.6869], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 78 was 62.3%.\n",
      "current params: tensor([2.7392, 2.5848, 2.5993, 0.9597, 0.7437, 0.6905], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 79 was 62.3%.\n",
      "current params: tensor([2.8013, 2.5464, 2.5573, 0.9754, 0.7528, 0.6769], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 80 was 62.4%.\n",
      "current params: tensor([2.7794, 2.5653, 2.5748, 0.9677, 0.7463, 0.6808], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 81 was 62.4%.\n",
      "current params: tensor([2.7465, 2.5907, 2.6003, 0.9567, 0.7381, 0.6876], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 82 was 62.0%.\n",
      "current params: tensor([2.8459, 2.4923, 2.5015, 1.0496, 0.8193, 0.5972], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 83 was 62.0%.\n",
      "current params: tensor([2.8462, 2.4903, 2.5022, 1.0488, 0.8200, 0.5965], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 84 was 62.0%.\n",
      "current params: tensor([2.8479, 2.4833, 2.5028, 1.0483, 0.8245, 0.5944], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 85 was 62.0%.\n",
      "current params: tensor([2.8494, 2.4773, 2.5033, 1.0479, 0.8282, 0.5926], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 86 was 62.0%.\n",
      "current params: tensor([2.8506, 2.4721, 2.5039, 1.0474, 0.8314, 0.5911], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 87 was 62.0%.\n",
      "current params: tensor([2.8682, 2.4147, 2.5118, 1.0377, 0.8659, 0.5669], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 88 was 62.1%.\n",
      "current params: tensor([2.8610, 2.4261, 2.5190, 1.0305, 0.8545, 0.5735], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 89 was 61.9%.\n",
      "current params: tensor([2.8846, 2.3907, 2.4941, 1.0563, 0.8924, 0.5532], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 90 was 61.9%.\n",
      "current params: tensor([2.8863, 2.3894, 2.4936, 1.0556, 0.8906, 0.5501], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 91 was 61.9%.\n",
      "current params: tensor([2.8872, 2.3890, 2.4935, 1.0550, 0.8893, 0.5485], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 92 was 62.0%.\n",
      "current params: tensor([2.8880, 2.3887, 2.4934, 1.0544, 0.8879, 0.5469], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 93 was 62.4%.\n",
      "current params: tensor([2.9057, 2.3862, 2.4937, 1.0355, 0.8485, 0.5101], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 94 was 62.5%.\n",
      "current params: tensor([2.9055, 2.3883, 2.4938, 1.0348, 0.8458, 0.5098], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 95 was 62.5%.\n",
      "current params: tensor([2.9054, 2.3894, 2.4942, 1.0339, 0.8438, 0.5093], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 96 was 62.5%.\n",
      "current params: tensor([2.9053, 2.3905, 2.4946, 1.0330, 0.8417, 0.5089], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 97 was 62.5%.\n",
      "current params: tensor([2.9052, 2.3916, 2.4950, 1.0320, 0.8397, 0.5084], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 98 was 62.5%.\n",
      "current params: tensor([2.9051, 2.3928, 2.4954, 1.0311, 0.8376, 0.5080], dtype=torch.float64)\n",
      "Using CPU\n",
      "Yield on sim. iteration 99 was 62.6%.\n",
      "optimization complete\n",
      "Final params: tensor([2.9051, 2.3928, 2.4954, 1.0311, 0.8376, 0.5080], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<KineticAssembly_AD.vectorized_rxn_net.VectorizedRxnNet at 0x7f7df6f01090>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim.rn.update_reaction_net(rn)\n",
    "optim.optimize(conc_scale=1,conc_thresh=1,max_thresh=10,yield_species=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track the yield over optim iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.plot_yield()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calc_var' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2f4c98e7caae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mvar_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mvar_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msorted_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0marg_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calc_var' is not defined"
     ]
    }
   ],
   "source": [
    "yields= []\n",
    "final_params=[]\n",
    "for i in range(len(optim.final_yields)):\n",
    "    yields.append(optim.final_yields[i].item())\n",
    "#     print(optim.final_solns[i].numpy())\n",
    "    final_params.append(optim.final_solns[i].numpy())\n",
    "\n",
    "sort_indx=np.argsort(np.array(yields))\n",
    "sorted_yields=np.array(yields)[sort_indx]\n",
    "sorted_params = np.array(final_params)[sort_indx]\n",
    "\n",
    "p0 = sorted_params[0]\n",
    "var_params = []\n",
    "for i in range(len(sorted_params)):\n",
    "    var_params.append(calc_var(p0,sorted_params[i]))\n",
    "    \n",
    "arg_indx = np.argsort(np.array(var_params))\n",
    "sorted_var = np.array(var_params)[arg_indx]\n",
    "\n",
    "print(sorted_var[0])\n",
    "print(sorted_var[-1])\n",
    "print(\"Yield: \",sorted_yields[arg_indx[0]],\"\\nParams: \",sorted_params[arg_indx[0]])\n",
    "\n",
    "print(\"Yield: \",sorted_yields[arg_indx[-1]],\"\\nParams: \",sorted_params[arg_indx[-1]])\n",
    "print(\"Max Yield: \",sorted_yields[-1],\"\\nParams: \",sorted_params[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vec_rn.rx_cid)\n",
    "print(vec_rn.coup_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yields= []\n",
    "final_params=[]\n",
    "asymm = []\n",
    "final_t50 = []\n",
    "final_t85 = []\n",
    "final_t95 = []\n",
    "final_t99 = []\n",
    "for i in range(len(optim.final_yields)):\n",
    "    yields.append(optim.final_yields[i].item())\n",
    "#     print(optim.final_solns[i].numpy())\n",
    "    coupled_params=np.zeros(len(vec_rn.kon))\n",
    "    if vec_rn.partial_opt:\n",
    "        for j in range(len(vec_rn.kon)):\n",
    "            if j in vec_rn.rx_cid.keys():\n",
    "                all_rates=[]\n",
    "                for rate in vec_rn.rx_cid[j]:\n",
    "                    if rate in vec_rn.optim_rates:\n",
    "                        all_rates.append(optim.final_solns[i][vec_rn.coup_map[rate]])\n",
    "                    else:\n",
    "                        if vec_rn.slow_rates is not None and rate in vec_rn.slow_rates:\n",
    "                            all_rates.append(torch.mean(optim.final_solns[i][vec_rn.optim_rates])/vec_rn.slow_ratio)\n",
    "                        else:\n",
    "                            all_rates.append(vec_rn.kon[rate])\n",
    "                coupled_params[j] = max(all_rates)\n",
    "            else:\n",
    "                if j in vec_rn.optim_rates:\n",
    "                    coupled_params[j] = optim.final_solns[i][vec_rn.coup_map[j]]\n",
    "                else:\n",
    "                    if vec_rn.slow_rates is not None and j in vec_rn.slow_rates:       #Can be replaced later so that the RN figures out by iteself which are fast  interfaces and which are slow.\n",
    "                        coupled_params[j] = torch.mean(optim.final_solns[i][vec_rn.optim_rates])/vec_rn.slow_ratio\n",
    "                    else:\n",
    "                        coupled_params[j] = vec_rn.kon[j]\n",
    "    else:\n",
    "        for j in range(len(vec_rn.kon)):\n",
    "            if j in vec_rn.rx_cid.keys():\n",
    "                #new_kon[i] = 1.0\n",
    "                coupled_params[j] = max(optim.final_solns[i].numpy()[vec_rn.coup_map[rate]] for rate in vec_rn.rx_cid[j])\n",
    "                # print(\"Max rate for reaction %s chosen as %.3f\" %(i,self.coupled_kon[i]))\n",
    "            else:\n",
    "                coupled_params[j] = optim.final_solns[i].numpy()[vec_rn.coup_map[j]]\n",
    "    final_params.append(coupled_params)\n",
    "    \n",
    "    if type(optim.final_t50[i])==int:\n",
    "        final_t50.append(1) \n",
    "    else:\n",
    "        final_t50.append(optim.final_t50[i].item()) \n",
    "    if type(optim.final_t85[i])==int:\n",
    "        final_t85.append(1) \n",
    "    else:\n",
    "        final_t85.append(optim.final_t85[i].item()) \n",
    "    if type(optim.final_t95[i])==int:\n",
    "        final_t95.append(1)\n",
    "    else:\n",
    "        final_t95.append(optim.final_t95[i].item())\n",
    "\n",
    "final_yield_arr = np.array(yields)\n",
    "final_param_arr = np.array(final_params)\n",
    "final_t85 = np.array(final_t85)\n",
    "final_t95 = np.array(final_t95)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mask_r = final_yield_arr > 0.5\n",
    "\n",
    "#Calculate the ratio\n",
    "ratio = final_param_arr[:,1]/final_param_arr[:,0]\n",
    "\n",
    "#Normalize the time scale (t = t*conc*max_rate)\n",
    "conc=vec_rn.initial_copies[0].item()\n",
    "scale_time = final_t95[mask_r]*conc*np.max(final_param_arr[mask_r],axis=1)\n",
    "#Calculate the y_per_time\n",
    "y_per_time = 0.95/scale_time\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(ratio,y_per_time,linestyle='',marker='o')\n",
    "ax.set_ylabel(\"Efficiency\",fontsize=20)\n",
    "ax.set_xlabel(\"Ratio\",fontsize=20)\n",
    "ax.tick_params(labelsize=25)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
