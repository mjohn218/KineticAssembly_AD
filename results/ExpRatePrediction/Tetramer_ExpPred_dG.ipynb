{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine kon and dG from observed yield vs time data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make sure jupyter path is correct for loading local moudules\n",
    "import sys\n",
    "# path to steric_simulator module relative to notebook\n",
    "sys.path.append(\"/home/adip/mjohn218_KineticAssembly\")\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from KineticAssembly_AD import ReactionNetwork, VectorizedRxnNetExp, VecSim, Optimizer, EquilibriumSolver,OptimizerExp\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import DoubleTensor as Tensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Reaction Network\n",
    "#### Read the corresponding input file and call the ReactionNetwork class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_input = 'path_to_input'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking reaction network\n",
    "Looping over all network nodes to check if all species are created\n",
    "Creating a dictionary for later reference. This dictionary holds the reactants as keys and values as the reaction index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    print(n,\"--\",gtostr(rn.network.nodes[n]['struct']))\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_dict[(n,k)] = uid\n",
    "\n",
    "print(uid_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the initial parameter values \n",
    "For a tetramer model there are 22 reactions. We can set an initial value for all reaction rates as given in the next cell. \n",
    "\n",
    "For the Rategrowth, the number of rates decrease to only 3 values. To set the initial values for all rates in a rate growth model, additional code is also given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set initial rate values for all reactions\n",
    "\"\"\"\n",
    "import networkx as nx\n",
    "#Define a new tensor array with all values initialized to zero\n",
    "new_kon = torch.zeros([rn._rxn_count], requires_grad=True).double()\n",
    "#Assign value for each rate \n",
    "new_kon = new_kon + Tensor([1]*np.array(1e0))\n",
    "\n",
    "\"\"\"\n",
    "For RateGrowth model, initial values are assigned differently\n",
    "\"\"\"\n",
    "#Define initial values for dimer,trimer and tetramer rate\n",
    "# kdim=\n",
    "# ktri=\n",
    "# ktetra=\n",
    "# rates= [kdim, ktri, ktetra]\n",
    "\n",
    "#Assign the corresponding reaction values to it's reaction type.\n",
    "# counter=0\n",
    "# for k,v in rn.rxn_class.items():\n",
    "#     for rid in v:\n",
    "#         new_kon[v] = rates[counter]\n",
    "#     counter+=1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Update the reaction network with the new initial values\n",
    "\"\"\"\n",
    "update_kon_dict = {}\n",
    "for edge in rn.network.edges:\n",
    "    print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "    update_kon_dict[edge] = new_kon[uid_dict[edge]]\n",
    "\n",
    "nx.set_edge_attributes(rn.network,update_kon_dict,'k_on')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Vectorized Reaction Network class\n",
    "\n",
    "In this class all reaction rates, concentrations, dG's are stored in Tensors for vectorized operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_rn = VectorizedRxnNet(rn, dev='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using the optimizer ##\n",
    "\n",
    "### Define an instance of the optimizer class\n",
    "#### Input Arguments:\n",
    "\n",
    "reaction_network : Input the vectorized rxn network\n",
    "\n",
    "sim_runtime: The runtime of the kinetic simulation. Needs to be same as the time over the experimental reaction data.\n",
    "\n",
    "optim_iterations: No. of iterations to run the optimization. Can start at low values(100) and increase depending upon memory usage.\n",
    "\n",
    "learning_rate = The size of the gradient descent step for updating parameter values. Needs to be atleast (1e-3-1e-1)* min{parameter value}. If learning rate is too high, it can take a longer step and sometimes lead to negative value of parameters which is unphysical. Requires some trial runs to find the best value. \n",
    "\n",
    "device: cpu or gpu\n",
    "\n",
    "method: Choose which pytorch based optimized to use for gradient descent - Adam or RMSprop\n",
    "\n",
    "mom: Only for RMSprop method. Use momentum term during gradient descent. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn_rate=[1e-3,1e-3]\n",
    "learn_rate=1e-3\n",
    "momentum=0.2\n",
    "runtime=10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "vec_rn.reset(reset_params=True)\n",
    "optim = OptimizerExp(reaction_network=vec_rn,\n",
    "                  sim_runtime=runtime,\n",
    "                  optim_iterations=100,\n",
    "                  learning_rate=learn_rate,\n",
    "                  device='cpu',method=\"Adam\",reg_penalty=1000000,mom=momentum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the optimization method\n",
    "\n",
    "#### Input arguments\n",
    "\n",
    "files_range = Array that hold list of concentration values to be simulated for global optimization. All values are stored as integers\n",
    "\n",
    "conc_files_pref = Path location and prefix for data files with true values of yield at each time points\n",
    "\n",
    "yield_species: Yield of the species being optimized(node index)\n",
    "\n",
    "yield_thresh= Used to define the maximum yield point of the window used for calculating the error between the true and predicted yield values.\n",
    "\n",
    "yield_min = Min point of the window used for calculating yield error.\n",
    "\n",
    "mode = Mode of calculating error. There are two modes - a) 'square' - Sum of Squared error b) 'abs' - Using absolute value of error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_range=[100,500,1000,5000,10000]\n",
    "yield_thresh=0.8\n",
    "yield_min=0.7\n",
    "\n",
    "optim.rn.update_reaction_net(rn)\n",
    "optim.optimize_wrt_conc_beta(conc_scale=1e-1,conc_thresh=1e-1,mod_bool=True,mod_factor=10,max_thresh=1e2,max_yield=0,yield_species=14,\n",
    "                        conc_files_pref=\"dG_trap/ConcProfile_Time_HomoRates_\",conc_files_range=files_range,yield_threshmin=yield_min,yield_threshmax=yield_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track the error over optim iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "ax.plot(optim.mse_error)\n",
    "\n",
    "ax.tick_params(labelsize='xx-large')\n",
    "\n",
    "ax.set_xlabel(\"Iterations\",fontsize=25)\n",
    "ax.set_ylabel(\"MSE\",fontsize=25)\n",
    "\n",
    "\n",
    "# ax.legend(fontsize='large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store parameter values obtained over the entire optimization run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields= []\n",
    "final_params=[]\n",
    "mse_error = []\n",
    "\n",
    "for i in range(len(optim.yield_per_iter)):\n",
    "    yields.append(optim.yield_per_iter[i])\n",
    "    params=[]\n",
    "    for j in range(len(optim.parameter_history[i])):\n",
    "        params.append(np.array(optim.parameter_history[i][j]))\n",
    "    final_params.append(params)\n",
    "    mse_error.append(optim.mse_error[i])\n",
    "    \n",
    "sorted_yields=np.array(yields)#[sort_indx]\n",
    "sorted_params = np.array(final_params)#[sort_indx]\n",
    "mse_error = np.array(mse_error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select parameter values with min error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_indx = np.argmin(mse_error)\n",
    "\n",
    "min_rates = list(sorted_params[min_indx])\n",
    "min_error = mse_error[min_indx]\n",
    "\n",
    "dG = -1*torch.log(min_rates[0][0]*vec_rn._C0/min_rates[1][0])\n",
    "print(\"Params: \",min_rates)\n",
    "print(\"dG: \",dG)\n",
    "print(\"Min SSE: \",min_error )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing parameter values in a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For part 1 - Only kon optimization ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing all solutions to a file\n",
    "\n",
    "klabels=['k'+str(i) for i in range(len(vec_rn.kon))]\n",
    "header = '#Yield\\t' + \"\\t\".join(klabels) + \"\\tt50\\tt85\\tt95\\n\"\n",
    "\n",
    "files_range = [str(f) for f in files_range]\n",
    "filestr = \",\".join(files_range)\n",
    "\n",
    "\n",
    "with open(\"Solutions_Conc_Homorates_dGNotrap_02_part1\",'a') as fl:\n",
    "    fl.write(header)\n",
    "    fl.write(\"# Range of Concentrations: %s\\n\" %filestr)\n",
    "    fl.write(\"# Learning rate: %s\\n\" %(str(learn_rate)))\n",
    "    fl.write(\"# Momentum: %f\\n\" %(momentum))\n",
    "    fl.write(\"# Yield thresh: %f\\n\" %(yield_thresh))\n",
    "    for i in range(len(sorted_yields)):\n",
    "        fl.write(\"%f\" %(sorted_yields[i]))\n",
    "        fl.write(\"\\t%f\" %(mse_error[i]))\n",
    "        for j in range((sorted_params[i].shape[0])):\n",
    "            fl.write(\"\\t%f\" %(sorted_params[i][j]))\n",
    "        fl.write(\"\\n\")\n",
    "                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - koff optimization ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Writing all solutions to a file\n",
    "\n",
    "# klabels=['k'+str(i) for i in range(len(vec_rn.kon))]\n",
    "# header = '#Yield\\t' + \"\\t\".join(klabels) + \"\\tt50\\tt85\\tt95\\n\"\n",
    "\n",
    "# files_range = [str(f) for f in files_range]\n",
    "# filestr = \",\".join(files_range)\n",
    "\n",
    "\n",
    "# with open(\"Solutions_Conc_Homorates_dGparam_07_part2\",'a') as fl:\n",
    "#     fl.write(header)\n",
    "#     fl.write(\"# Range of Concentrations: %s\\n\" %filestr)\n",
    "#     fl.write(\"# Learning rate: %s\\n\" %(\",\".join(str(lr) for lr in learn_rate)))\n",
    "#     fl.write(\"# Momentum: %f\\n\" %(momentum))\n",
    "#     fl.write(\"# Yield thresh: %f\\n\" %(yield_thresh))\n",
    "#     for i in range(len(sorted_yields)):\n",
    "#         fl.write(\"%f\" %(sorted_yields[i]))\n",
    "#         fl.write(\"\\t%f\" %(mse_error[i]))\n",
    "#         for j in range((sorted_params[i].shape[0])):\n",
    "#             for k in range(len(sorted_params[i][j])):\n",
    "#                 fl.write(\"\\t%f\" %(sorted_params[i][j][k]))\n",
    "#         fl.write(\"\\n\")\n",
    "        \n",
    "                 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
