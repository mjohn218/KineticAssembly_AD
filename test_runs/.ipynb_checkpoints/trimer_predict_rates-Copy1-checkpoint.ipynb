{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Framework using auto-diff to predict binding rates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnergyExplorer Module is not available. Check Rosetta installation. <ipykernel.iostream.OutStream object at 0x7f8037db9f10>\n"
     ]
    }
   ],
   "source": [
    "# make sure jupyter path is correct for loading local moudules\n",
    "import sys\n",
    "# path to steric_simulator module relative to notebook\n",
    "sys.path.append(\"../../\")\n",
    "import copy\n",
    "from KineticAssembly_AD import ReactionNetwork, VectorizedRxnNet, VecSim, Optimizer, EquilibriumSolver\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import DoubleTensor as Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Reaction Network\n",
    "#### Read the corresponding input file and call the ReactionNetwork class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['default_assoc', 1.0]\n",
      "['A']\n",
      "100.0\n",
      "['B']\n",
      "100.0\n",
      "['C']\n",
      "100.0\n",
      "Parsing rule...\n",
      "Parsing rule...\n",
      "Parsing rule...\n",
      "New node added - Node index: 3 ; Node label: AB \n",
      "New node added - Node index: 4 ; Node label: AC \n",
      "Trying internal bonds\n",
      "New node added - Node index: 5 ; Node label: BC \n",
      "New node added - Node index: 6 ; Node label: ABC \n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "Trying internal bonds\n",
      "Reaction Network Completed\n"
     ]
    }
   ],
   "source": [
    "base_input = './trimer.pwr'\n",
    "rn = ReactionNetwork(base_input, one_step=True)\n",
    "rn.resolve_tree()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking reaction network\n",
    "Looping over all network nodes to check if all species are created\n",
    "Creating a dictionary for later reference. This dictionary holds the reactants as keys and values as the reaction index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -- A\n",
      "1 -- B\n",
      "2 -- C\n",
      "3 -- AB\n",
      "4 -- AC\n",
      "5 -- BC\n",
      "6 -- ABC\n",
      "{(0, 3): 0, (0, 4): 1, (0, 6): 5, (1, 3): 0, (1, 5): 2, (1, 6): 3, (2, 4): 1, (2, 5): 2, (2, 6): 4, (3, 6): 4, (4, 6): 3, (5, 6): 5}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    print(n,\"--\",gtostr(rn.network.nodes[n]['struct']))\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_dict[(n,k)] = uid\n",
    "\n",
    "print(uid_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the initial parameter values \n",
    "For a hetero-trimer there are 6 reaction rates.\n",
    "Also defines the Vectorized Rxn NEt class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k_on': 5, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': 5, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': 5, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 5}\n",
      "{'k_on': 5, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 0}\n",
      "{'k_on': 5, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': 5, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': 5, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 1}\n",
      "{'k_on': 5, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-20.], dtype=torch.float64), 'uid': 2}\n",
      "{'k_on': 5, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': 5, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 4}\n",
      "{'k_on': 5, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 3}\n",
      "{'k_on': 5, 'k_off': None, 'lcf': 1, 'rxn_score': tensor([-40.], dtype=torch.float64), 'uid': 5}\n",
      "(0, 1)\n",
      "(0, 2)\n",
      "(1, 2)\n",
      "(2, 3)\n",
      "(1, 4)\n",
      "(0, 5)\n",
      "Stoichiometric Matrix:  tensor([[-1., -1.,  0.,  0.,  0., -1.,  1.,  1., -0., -0., -0.,  1.],\n",
      "        [-1.,  0., -1., -1.,  0.,  0.,  1., -0.,  1.,  1., -0., -0.],\n",
      "        [ 0., -1., -1.,  0., -1.,  0., -0.,  1.,  1., -0.,  1., -0.],\n",
      "        [ 1.,  0.,  0.,  0., -1.,  0., -1., -0., -0., -0.,  1., -0.],\n",
      "        [ 0.,  1.,  0., -1.,  0.,  0., -0., -1., -0.,  1., -0., -0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0., -1., -0., -0., -1., -0., -0.,  1.],\n",
      "        [ 0.,  0.,  0.,  1.,  1.,  1., -0., -0., -0., -1., -1., -1.]],\n",
      "       dtype=torch.float64)\n",
      "Reaction rates:  tensor([5., 5., 5., 5., 5., 5.], dtype=torch.float64, grad_fn=<CopySlices>)\n",
      "dGs:  tensor([-20., -20., -20., -40., -40., -40.], dtype=torch.float64)\n",
      "Species Concentrations:  tensor([100., 100., 100.,   0.,   0.,   0.,   0.], dtype=torch.float64)\n",
      "Shifting to device:  cpu\n",
      "Parameter containing:\n",
      "tensor([5., 5., 5., 5., 5., 5.], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "new_kon = torch.zeros([rn._rxn_count], requires_grad=True).double()\n",
    "new_kon = [5,5,5,5,5,5]\n",
    "\n",
    "update_kon_dict = {}\n",
    "for edge in rn.network.edges:\n",
    "    update_kon_dict[edge] = new_kon[uid_dict[edge]]\n",
    "\n",
    "nx.set_edge_attributes(rn.network,update_kon_dict,'k_on')\n",
    "for edge in rn.network.edges:\n",
    "    print(rn.network.get_edge_data(edge[0],edge[1]))\n",
    "\n",
    "\n",
    "vec_rn = VectorizedRxnNet(rn, dev='cpu')\n",
    "print(vec_rn.kon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "AB\n",
      "AC\n",
      "BC\n",
      "ABC\n",
      "tensor(5., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'A'}, {'B'}), 'kon': 5, 'score': tensor([-20.], dtype=torch.float64), 'koff': None, 'uid': 0}\n",
      "tensor(5., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'A'}, {'C'}), 'kon': 5, 'score': tensor([-20.], dtype=torch.float64), 'koff': None, 'uid': 1}\n",
      "tensor(5., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'B'}, {'C'}), 'kon': 5, 'score': tensor([-20.], dtype=torch.float64), 'koff': None, 'uid': 2}\n",
      "tensor(5., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'B'}, {'C', 'A'}), 'kon': 5, 'score': tensor([-40.], dtype=torch.float64), 'koff': None, 'uid': 3}\n",
      "tensor(5., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'C'}, {'A', 'B'}), 'kon': 5, 'score': tensor([-40.], dtype=torch.float64), 'koff': None, 'uid': 4}\n",
      "tensor(5., dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "{'reactants': ({'A'}, {'C', 'B'}), 'kon': 5, 'score': tensor([-40.], dtype=torch.float64), 'koff': None, 'uid': 5}\n"
     ]
    }
   ],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_val = {'reactants':reactants,'kon':v['k_on'],'score':v['rxn_score'],'koff':v['k_off'],'uid':uid}\n",
    "        if uid not in uid_dict.keys():\n",
    "            uid_dict[uid] = uid_val\n",
    "    print(gtostr(rn.network.nodes[n]['struct']))\n",
    "    #for r_set in rn.get_reactant_sets(n):\n",
    "    #    print(tuple(r_set))\n",
    "    #print(rn.network[n]['struct'])\n",
    "ind_sort = np.argsort(vec_rn.kon.detach().numpy())\n",
    "for i in ind_sort:\n",
    "    print(vec_rn.kon[i])\n",
    "    print(uid_dict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using the optimizer ##\n",
    "\n",
    "### Define an instance of the optimizer class\n",
    "#### Input Arguments:\n",
    "\n",
    "reaction_network : Input the vectorized rxn network\n",
    "\n",
    "sim_runtime: The runtime of the kinetic simulation. Needs to be same as the time over the experimental reaction data.\n",
    "\n",
    "optim_iterations: No. of iterations to run the optimization. Can start at low values(100) and increase depending upon memory usage.\n",
    "\n",
    "learning_rate = The size of the gradient descent step for updating parameter values. Needs to be atleast (1e-3-1e-1)* min{parameter value}. If learning rate is too high, it can take a longer step and sometimes lead to negative value of parameters which is unphysical. Requires some trial runs to find the best value. \n",
    "\n",
    "device: cpu or gpu\n",
    "\n",
    "method: Choose which pytorch based optimized to use for gradient descent - Adam or RMSprop\n",
    "\n",
    "mom: Only for RMSprop method. Use momentum term during gradient descent. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "vec_rn.reset(reset_params=True)\n",
    "optim = Optimizer(reaction_network=vec_rn,\n",
    "                  sim_runtime=1,\n",
    "                  optim_iterations=10,\n",
    "                  learning_rate=1e-2,\n",
    "                  device='cpu',method=\"RMSprop\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the optimization method\n",
    "\n",
    "#### Input arguments\n",
    "\n",
    "conc_scale, conc_thresh, mod_bool, mod_factor = As defined for the VecSim class. \n",
    "\n",
    "max_thresh: Max. allowed values of parameters being updated. Beyond this maximum a penalty is imposed on the cost function. (Regularization)\n",
    "\n",
    "max_yield: It is a control variable that is used to store the updated parameter values over all iterations for further analysis. The parameter values are stored only if the current yield exceed this max_yield. \n",
    "\n",
    "yield_species: Yield of the species being optimized(node index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reaction Parameters before optimization: \n",
      "[Parameter containing:\n",
      "tensor([5., 5., 5., 5., 5., 5.], dtype=torch.float64, requires_grad=True)]\n",
      "Optimizer State: <bound method Optimizer.state_dict of RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")>\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  81.7\n",
      "Next time:  tensor(1.1231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Yield on sim. iteration 0 was f67.3%.\n",
      "current params: tensor([5., 5., 5., 5., 5., 5.], dtype=torch.float64)\n",
      "Grad:  tensor([-0.0002,  0.0014,  0.0014, -0.0074, -0.0496, -0.0074],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  81.8\n",
      "Next time:  tensor(2.2982, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Yield on sim. iteration 1 was f68.7%.\n",
      "current params: tensor([5.1000, 4.9000, 4.9000, 5.1000, 5.1000, 5.1000], dtype=torch.float64)\n",
      "Grad:  tensor([-0.0124, -0.0084, -0.0131, -0.3562,  0.2452,  0.0839],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  81.8\n",
      "Next time:  tensor(1.0831, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Yield on sim. iteration 2 was f67.9%.\n",
      "current params: tensor([5.1999, 4.9987, 4.9995, 5.2000, 5.0020, 5.0004], dtype=torch.float64)\n",
      "Grad:  tensor([-0.0708, -0.0725, -0.0810,  0.0388,  0.0598,  0.0642],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  81.8\n",
      "Next time:  tensor(1.2512, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Yield on sim. iteration 3 was f66.6%.\n",
      "current params: tensor([5.2984, 5.0980, 5.0982, 5.1891, 4.9786, 4.9396], dtype=torch.float64)\n",
      "Grad:  tensor([ 0.0282,  0.0282,  0.0327, -0.0542, -0.0505, -0.0499],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  81.8\n",
      "Next time:  tensor(1.7377, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Yield on sim. iteration 4 was f68.1%.\n",
      "current params: tensor([5.2618, 5.0618, 5.0610, 5.2042, 4.9981, 4.9825], dtype=torch.float64)\n",
      "Grad:  tensor([-0.8371, -0.8135, -0.8869,  1.4849,  0.9673,  0.0264],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  81.8\n",
      "Next time:  tensor(1.0388, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Yield on sim. iteration 5 was f66.7%.\n",
      "current params: tensor([5.3614, 5.1614, 5.1606, 5.1069, 4.9015, 4.9602], dtype=torch.float64)\n",
      "Grad:  tensor([-0.0021, -0.0006,  0.0011, -0.0283, -0.0182, -0.0163],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  81.8\n",
      "Next time:  tensor(1.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Yield on sim. iteration 6 was f66.7%.\n",
      "current params: tensor([5.3616, 5.1614, 5.1604, 5.1088, 4.9033, 4.9740], dtype=torch.float64)\n",
      "Grad:  tensor([-0.0005,  0.0008,  0.0026, -0.0260, -0.0201, -0.0215],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  81.8\n",
      "Next time:  tensor(1.0181, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Yield on sim. iteration 7 was f66.8%.\n",
      "current params: tensor([5.3617, 5.1613, 5.1601, 5.1105, 4.9053, 4.9918], dtype=torch.float64)\n",
      "Grad:  tensor([ 0.0008,  0.0019,  0.0038, -0.0252, -0.0220, -0.0241],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  81.9\n",
      "Next time:  tensor(1.0173, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Yield on sim. iteration 8 was f66.8%.\n",
      "current params: tensor([5.3616, 5.1611, 5.1597, 5.1122, 4.9075, 5.0115], dtype=torch.float64)\n",
      "Grad:  tensor([ 0.0022,  0.0030,  0.0052, -0.0249, -0.0244, -0.0260],\n",
      "       dtype=torch.float64)\n",
      "Using CPU\n",
      "Start of simulation: memory Used:  81.9\n",
      "Next time:  tensor(1.0154, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Yield on sim. iteration 9 was f66.9%.\n",
      "optimization complete\n",
      "Final params: tensor([5.3616, 5.1611, 5.1597, 5.1122, 4.9075, 5.0115], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<KineticAssembly_AD.vectorized_rxn_net.VectorizedRxnNet at 0x7f7f60c366d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim.rn.update_reaction_net(rn)\n",
    "optim.optimize(conc_scale=1,conc_thresh=1,mod_bool=True,mod_factor=10,max_thresh=1e8,max_yield=0,yield_species=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track the loss function over optim iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "\n",
    "ax.plot(optim.mse_error)\n",
    "\n",
    "ax.tick_params(labelsize='xx-large')\n",
    "\n",
    "ax.set_xlabel(\"Iterations\",fontsize=25)\n",
    "ax.set_ylabel(\"MSE\",fontsize=25)\n",
    "\n",
    "# ax.legend(fontsize='large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_dict = {}\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from reaction_network import gtostr\n",
    "for n in rn.network.nodes():\n",
    "    #print(n)\n",
    "    #print(rn.network.nodes()[n])\n",
    "    for k,v in rn.network[n].items():\n",
    "        uid = v['uid']\n",
    "        r1 = set(gtostr(rn.network.nodes[n]['struct']))\n",
    "        p = set(gtostr(rn.network.nodes[k]['struct']))\n",
    "        r2 = p-r1\n",
    "        reactants = (r1,r2)\n",
    "        uid_val = {'reactants':reactants,'kon':v['k_on'],'score':v['rxn_score'],'koff':v['k_off'],'uid':uid}\n",
    "        if uid not in uid_dict.keys():\n",
    "            uid_dict[uid] = uid_val\n",
    "    print(gtostr(rn.network.nodes[n]['struct']))\n",
    "    #for r_set in rn.get_reactant_sets(n):\n",
    "    #    print(tuple(r_set))\n",
    "    #print(rn.network[n]['struct'])\n",
    "ind_sort = np.argsort(vec_rn.kon.detach().numpy())\n",
    "for i in ind_sort:\n",
    "    print(vec_rn.kon[i])\n",
    "    print(uid_dict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the parameter values\n",
    "\n",
    "### This can be stored in a file for later analysis or used to find the best parameter value depending upon a condition. For e.g. the values that give a minimum error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields= []\n",
    "final_params=[]\n",
    "for i in range(len(optim.final_yields)):\n",
    "    yields.append(optim.final_yields[i].item())\n",
    "#     print(optim.final_solns[i].numpy())\n",
    "    final_params.append(optim.final_solns[i].numpy())\n",
    "\n",
    "sort_indx=np.argsort(np.array(yields))\n",
    "sorted_yields=np.array(yields)#[sort_indx]\n",
    "sorted_params = np.array(final_params)#[sort_indx]\n",
    "\n",
    "\n",
    "print(sorted_params[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can also plot the yield at the sim_runtime over all optim iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optim.plot_yield()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
